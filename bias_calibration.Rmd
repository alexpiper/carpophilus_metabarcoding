---
title: "Bias_estimation"
author: "Alexander Piper"
date: "18/09/2019"
output: html_document
---


```{r setup, include=FALSE}
# Knitr global setup - change eval to true to run code

library(knitr)
knitr::opts_chunk$set(echo = TRUE, eval=TRUE, message=FALSE,error=FALSE, warning=FALSE,fig.show = "hold", fig.keep = "all")
opts_knit$set(root.dir = 'C:/Users/ap0y/Dropbox/workprojects/PHD/Metabarcoding/Dros_metabarcoding')
setwd('C:/Users/ap0y/Dropbox/workprojects/PHD/Metabarcoding/Dros_metabarcoding')
opts_chunk$set(dev = 'png')
```


## Install and load packages
```{r install & Load packages} 

#Install cran packages
.cran_packages <- c("ggplot2","tidyverse","scales","patchwork","vegan","ggpubr","seqinr","viridis")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}

#Install bioconductor packages
.bioc_packages <- c("dada2", "phyloseq", "DECIPHER","Biostrings","ShortRead")
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

#Install github packages
#devtools::install_github("alexpiper/taxreturn")
#devtools::install_github("mikemc/speedyseq")
#devtools::install_github("mikemc/metacal")

#Load all packages
sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)
library(taxreturn)
library(speedyseq)
library(metacal)
```


## Make Phyloseq object

Following taxonomic assignment, the sequence table and taxonomic table are merged into a single phyloseq object alongside the sample info csv.

We then make a plot to evaluate the effectiveness of taxonomic assignment to each rank

```{r create PS, eval = TRUE}
seqtab.nochim <- readRDS("output/rds/seqtab_final_Run2.rds")
tax_plus <- readRDS("output/rds/tax_IdTaxaExact_run2.rds") 

#Load sample information
## ---- samdat ----
samdf <- read.csv("sample_data/Sample_info.csv", header=TRUE) %>%
  filter(!duplicated(SampleID)) %>%
  filter(seqrun==2) %>% # change for other runs
  set_rownames(.$SampleID) %>%
  dplyr::select(c("SampleID","ExtractID","seqrun","replicate","feature","target_subfragment","Trap","pcr_primers","experimental_factor"))
#Display samDF
head(samdf)

## ---- phyloseq ----
ps <- phyloseq(tax_table(tax_plus), sample_data(samdf),
               otu_table(seqtab.nochim, taxa_are_rows = FALSE))

if(nrow(seqtab.nochim) > nrow(sample_data(ps))){warning("Warning: All samples not included in phyloseq object, check sample names match the sample metadata")}

rownames(samdf)[which(!rownames(samdf) %in% rownames(sample_data(ps)))]


#Fraction of reads assigned to each taxonomic rank
sum_reads <- speedyseq::psmelt(ps) %>%
  gather("Rank","Name",rank_names(ps)) %>%
  group_by(Rank) %>% 
  mutate(Name = replace(Name, str_detect(Name, "__"),NA)) %>% # This line turns the "__" we added to lower ranks back to NA's
  summarize(Reads_classified = sum(Abundance * !is.na(Name))) %>%
  mutate(Frac_reads = Reads_classified / sum(sample_sums(ps))) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)

#Fraction of ASV's assigned to each taxonomic rank
sum_otu <- tax_table(ps) %>%
  as("matrix") %>%
  as_tibble(rownames="OTU") %>%
  gather("Rank","Name",rank_names(ps)) %>%
  group_by(Rank) %>%
  mutate(Name = replace(Name, str_detect(Name, "__"),NA)) %>% # This line turns the "__" we added to lower ranks back to NA's
  summarize(OTUs_classified = sum(!is.na(Name))) %>%
  mutate(Frac_OTUs = OTUs_classified / ntaxa(ps)) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)

#Output tables of results

dir.create("output/csv")
dir.create("output/csv/unfiltered/")

##Export raw csv
export <- psmelt(ps)
write.csv(export, file = "output/csv/rawdata.csv")
```




## Process replicates 

This study used 3 Replicates, here we merge them only retaining ASV's that were present in at least 2 different replicates from each sample

```{r merge replicates}
#Handle replicataes
rm_samples <- c("Undetermined")
ps1 <- subset_samples(ps, sample_names(ps) !=rm_samples) # Drop Undetermined reads
ps1 <- prune_samples(sample_sums(ps1)>=20, ps1) # Drop empty samples

# Merge replicates
  ps.merged <- ps1 %>%
    merge_samples(group = "ExtractID")

# keeping only those ASVs that occur in 2 replicates
# Create a matrix of 0s and 1s indicating whether the taxon count should be
# allowed, or should be set to 0.
ps.merged.ok <- ps1 %>%
    transform_sample_counts(function (x) (x > 0) * 1) %>%  #Summarise presence/absense across reps
    merge_samples(group = "ExtractID") %>% #Merge reps
    transform_sample_counts(function (x) (x > 1) * 1) #Only keep those occuring in 2 or more replicates

## Multiply the counts by the 0-1 matrix
newotu <- otu_table(ps.merged) * otu_table(ps.merged.ok)

otu_table(ps.merged) <- otu_table(newotu, taxa_are_rows = FALSE)

#This loses the sample metadata - Need to add it agian
samdf <- read.csv("sample_data/Sample_info.csv", header=TRUE) %>%
  filter(!duplicated(ExtractID)) %>%
  set_rownames(.$ExtractID) %>%
  dplyr::select(c("ExtractID","seqrun","feature","target_subfragment","pcr_primers","experimental_factor","Trap"))

sample_data(ps.merged) <- samdf
ps.merged <- filter_taxa(ps.merged, function(x) mean(x) > 0, TRUE) #Drop missing taxa from table

```


# Estimate bias

As part of the mock community analysis, we wish to determine taxonomic bias by looking at observed vs expected reads. To do this, we load dummy sequence, taxonomy, and sample data tables and create a seperate phyloseq object, which will later be merged

This loads a dummy sequence table, taxonomy table, and sample data table and merges it into the existing phyloseq object

Conducted as per: https://mikemc.github.io/metacal/articles/tutorial.html


```{r Carpophilus bias}
#Subset to only those in mocks, labelled Nitidulidae
ps_bias <- subset_samples(ps.merged, feature %in% c("Nitidulidae")) 


#Rename taxa to match the expected
tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Carpophilus_dimidiatus/nr.dimidiatus")] <- "Carpophilus_nr.dimidiatus"
tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Brachypeplus_Sp1")] <- "Brachypeplus_Sp"
tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Brachypeplus_Sp2")] <- "Brachypeplus_Sp"

#Agglomerate to species level
ps_bias <- tax_glom(ps_bias, taxrank="Species")

#Estimate bias seperately for each primer - we will save the results into seperate lists
primers <- as.character(unique(sample_data(ps_bias)$target_subfragment ))
p_list <- vector("list", length(primers))
names(p_list) = primers

pw_list <- vector("list", length(primers))
names(pw_list) = primers

bias_list<- vector("list", length(primers))
names(bias_list) = primers

i=1
for (i in 1:length(primers)){
  ps_primer <- subset_samples(ps_bias,sample_data(ps_bias)$target_subfragment  == primers[i])
  ps_primer <- filter_taxa(ps_primer, function(x) mean(x) > 0, TRUE) #Drop missing taxa from table
  
sam <- psmelt(ps_bias) %>%
  arrange(Abundance)%>%
  mutate(Taxon = Species)

exp <- read_csv("sample_data/Test_expected_quant.csv") %>%
  gather(Species, Abundance, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  mutate(X1 = str_split_fixed(X1,"_Rep",n=2) %>%
           as_tibble()%>% 
           pull(V1)) %>%
  distinct() %>%
  filter(str_detect(X1,"CM")) %>% 
  filter(str_detect(X1,primers[[i]])) %>%
  drop_na()
colnames(exp) <- c("Sample","Taxon","Actual")

#Join tables 
joint <- sam %>%
  filter(Taxon %in% exp$Taxon) %>%
  #filter(Abundance > 0) %>%
  left_join(exp, by = c("Sample","Taxon")) %>%
  mutate(Actual = replace_na(Actual, 0)) %>%
  mutate(Observed0 = (Abundance + 0.5) * (Actual > 0)) %>%
  mutate(Error = Observed0 / Actual)

#Build error matrix
error_mat <- build_matrix(joint, Sample, Taxon, Error)

#Estimate bias
bias <- center(error_mat, enframe = TRUE) %>%
    dplyr::rename(Bhat = Center)

#Estimate uncertainty in bias estimate
bootreps <- bootrep_center(error_mat) %>%
    dplyr::rename(Bhat = Center)
bootreps.summary <- bootreps %>%
    group_by(Taxon) %>%
    summarize(Gm_mean = gm_mean(Bhat), Gm_se = gm_sd(Bhat))
bias0 <- left_join(bias, bootreps.summary, by = "Taxon")

bias_list[[i]] <- bias0 %>%
  mutate(type=primers[i])

#Plot single bias estimate

gg.bias <- ggplot(bias0, aes(Taxon, y=Gm_mean-1,fill=Taxon)) +
    geom_bar(stat="identity")+
    geom_errorbar(aes(ymin = (Gm_mean-1) - (Gm_se-1), ymax = (Gm_mean-1) + (Gm_se-1), width=0.2)) +
    geom_point(aes(y=Gm_mean-1)) +
    scale_fill_brewer(palette="Spectral")+
    scale_colour_brewer(palette="Spectral") + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0)) + 
  ylab("Bias") +
  ggtitle(primers[i]) +
  expand_limits(y = c(-2, 4)) +
  theme(legend.position = "none")

p_list[[i]] <- gg.bias

#Get pairwise bias in taxon ratios
bias.pw <- bias %>%
    compute_ratios(group_vars = c()) %>%
    mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":"))

#Get pairwise boostrap estimates
bootreps.pw <- bootreps %>%
    compute_ratios(group_vars = ".id")
summary.pw <- bootreps.pw %>%
    group_by(Taxon.x, Taxon.y) %>%
    summarize(Gm_mean = gm_mean(Bhat), Gm_se = gm_sd(Bhat))
bias.pw0 <- left_join(bias.pw, summary.pw, by = c("Taxon.x", "Taxon.y"))

ratios <- joint %>%
    compute_ratios %>%
    mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":")) %>%
    filter(!is.nan(Error), Taxon.x < Taxon.y)
ratios.pred <- bias.pw0 %>%
    mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":")) %>%
    filter(Taxon.x < Taxon.y)

gg.pairwise <- ggplot(ratios, aes(Pair, Error, color = Sample)) +
    geom_hline(yintercept = 1, color = "grey") +
    geom_pointrange(data = ratios.pred, aes(y = Bhat, 
            ymin = Bhat / Gm_se^2, ymax = Bhat * Gm_se^2), 
        color = "black") +
    geom_jitter(width = 0.2) +
    scale_y_log10() +
    ggtitle(primers[i]) +
    coord_flip()

pw_list[[i]] <- gg.pairwise

}

#Plot bias plots together
library(patchwork)

#Plot single bias estimate
Fig1 <- p_list[[1]] + p_list[[2]]

print(Fig1)

#Plot pairwise bias estimates
Fig2 <- pw_list[[1]] / pw_list[[2]]


print(Fig2)
``` 

## Test for significacnce

```{r significance testing}
df <- bind_rows(bias_list[[1]], bias_list[[2]])

head(df)
```


## Session info

```{r session info}
sessionInfo()
```
