---
title: "Carpophilus Metabarcoding"
subtitle: "Statistical analysis"
author: "Alexander Piper"
date: "`r Sys.Date()`"
output:
  html_document:
    highlighter: null
    theme: "flatly"
    code_download: true
    toc: true
    toc_float: 
      collapsed: false
      smooth_scroll: true
    df_print: paged    
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
# Knitr global setup - change eval to true to run code
library(knitr)
knitr::opts_chunk$set(echo = TRUE, eval=FALSE, message=FALSE,error=FALSE, fig.show = "hold", fig.keep = "all")
opts_chunk$set(dev = 'png')
```

# Introduction
This document contains the code required to reproduce the statistical analyses for our manuscript: Piper, Rako, Semeraro, Cogan, Blacket & Cunningham (In prep). The inputs for this workflow are:

* A sequence table of detected amplicon sequence variants (ASVs) and which sample they were detected in
* A taxonomy table containing the taxonomy assigned to each ASV
* A phylogenetic tree of the detected ASVs
* A sample data sheet containing metadata for each sample

These inputs were generated during the [bioinformatic analysis](https://alexpiper.github.io/carpophilus_metabarcoding/bioinformatics.html)

## Load packages

This workflow depends on various R packages to be installed prior to running.

```{r load packages}
#Set required packages
.cran_packages <- c("tidyverse",
                    "tidymodels",
                    "patchwork", 
                    "vegan", 
                    "seqinr",
                    "ape", 
                    "RColorBrewer",
                    "devtools",
                    "data.table",
                    "future",
                    "furrr",
                    "chngpt",
                    "ggnewscale",
                    "ggpubr",
                    "glmnet",
                    "kernlab",
                    "ranger",
                    "magick")
.bioc_packages <- c("dada2",
                    "phyloseq", 
                    "ggtree",
                    "ALDEx2",
                    "Biostrings")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Install and load github packages
devtools::install_github("alexpiper/taxreturn")
library(taxreturn)
devtools::install_github("alexpiper/seqateurs")
library(seqateurs)
devtools::install_github("mikemc/speedyseq")
library(speedyseq)
devtools::install_github("mikemc/metacal")
library(metacal)

#Source themes
source("R/themes.R")
source("R/helper_functions.R")
```

## Make Phyloseq object

```{r create PS, eval = FALSE}
seqtab <- readRDS("output/rds/seqtab_final.rds")

#Reformat sample IDs
rownames(seqtab)  <- rownames(seqtab) %>%
  str_remove("\\..*$") %>%
  str_replace("\\_S[0-9].*\\_...", replacement="_") %>%
  str_replace("_$", "_1") %>%
  str_replace("1in10", "1:10")

tax <- readRDS("output/rds/final_tax.rds") 
seqs <- DNAStringSet(colnames(seqtab))
names(seqs) <- seqs
phy <- read.tree("output/order_constrained_rerooted.nwk")

##### Rename samples that were mixed up in the original sample sheet
rownames(seqtab)  <- rownames(seqtab) %>%
 str_replace_all("CM10-", "CM9REP-") %>%
 str_replace_all("CM11-", "CM10REP-") %>%
 str_replace_all("CM9-", "CM11REP-") %>%
 str_replace_all("CML2-", "CML6REP-")%>%
 str_replace_all("CML3-", "CML2REP-")%>%
 str_replace_all("CML4-", "CML3REP-")%>%
 str_replace_all("CML5-", "CML4REP-")%>%
 str_replace_all("CML6-", "CML5REP-")%>%
 str_replace_all("CT5-", "CT4REP-")%>%
 str_replace_all("CT4-", "CT5REP-") %>%
str_replace_all("REP", "")


# Samdf processing --------------------------------------------------------
samdf <- read.csv("sample_data/sample_info.csv", header=TRUE) %>% 
  mutate(sample_id = case_when(
    fcid=="HLVKYDMXX" ~ paste0(sample_name, "_", amp_rep),
    !fcid=="HLVKYDMXX" ~ paste0(fcid, "_", sample_name, "_", amp_rep)
  )) %>%
  mutate(extract_id = sample_name) %>%
  mutate(sample_name = str_remove(sample_name, "-exp*.$")) %>%
  mutate(sample_name = case_when(
    fcid=="HLVKYDMXX" ~ sample_name,
    !fcid=="HLVKYDMXX" ~ paste0(fcid, "_", sample_name)
  )) %>%
  filter(!(i7_index=="ATCGATCG" & i5_index=="ATCACACG"), #CT11-ex1 duplicated
         !(i7_index=="TCGCTGTT" & i5_index=="ACTCCATC") # CT12-ex1 duplicated
  ) %>%
  mutate(type = case_when(
    str_detect(sample_id, "D[0-9][0-9][0-9]M|D[0-9][0-9][0-9][0-9]M|DM[0-9]")  ~ "DrosMock",
    str_detect(sample_id, "SPD")  ~ "SPD",
    str_detect(sample_id, "ACV")  ~ "ACV",
    str_detect(sample_id, "DC")  ~ "DC",
    str_detect(sample_id, "Sach")  ~ "Sachet",
    str_detect(sample_id, "FF")  ~ "FF",
    str_detect(sample_id, "NTC")  ~ "NTC",
    str_detect(sample_id, "DLarv")  ~ "DrosLarv",
    str_detect(sample_id, "POS|SynMock")  ~ "POS",
    str_detect(sample_id, "extblank|BLANK")  ~ "Extblank",
    str_detect(sample_id, "pcrblank")  ~ "PCRblank",
    str_detect(sample_id, "CT")  ~ "CarpTrap",
    str_detect(sample_id, "CM[0-9]")  ~ "CarpMock",
    str_detect(sample_id, "CML[0-9]")  ~ "CarpLarval"
  )) %>%
  magrittr::set_rownames(.$sample_id)

write_csv(samdf, "sample_data/sample_info2.csv")

#Load sample information
## ---- samdat ----
samdf <- read.csv("sample_data/sample_info2.csv", header=TRUE) %>%
  magrittr::set_rownames(.$sample_id)

## ---- phyloseq ----
ps <- phyloseq(tax_table(tax), 
               sample_data(samdf),
               otu_table(seqtab, taxa_are_rows = FALSE),
               phy_tree(phy),
               refseq(seqs))

if(nrow(seqtab) > nrow(sample_data(ps))){warning("Warning: All samples not included in phyloseq object, check sample names match the sample metadata")}

rownames(samdf)[which(!rownames(sample_data(ps))  %in% rownames(samdf))]
rownames(sample_data(ps))[which(!rownames(samdf)  %in% rownames(sample_data(ps)))]

# Rename all taxa
taxa_names(ps) <- paste0("SV", seq(ntaxa(ps)),"-",tax_table(ps)[,8])

saveRDS(ps, "output/rds/ps_idtaxaExact.rds") 

#Rename synthetic spike ins
tax_table(ps)[,3][which(str_detect(tax_table(ps)[,8], "Synthetic"))] <- "Arthropoda"

# Rename incorrectly named taxa
tax_table(ps)[,8][which(tax_table(ps)[,8]=="Carpophilus dimidiatus/nr.dimidiatus")] <- "Carpophilus truncatus"
tax_table(ps)[,8][which(tax_table(ps)[,8]=="Carpophilus nr.dimidiatus")] <- "Carpophilus truncatus"
tax_table(ps)[,8][which(tax_table(ps)[,8]=="Brachypeplus Sp1")] <- "Brachypeplus Sp"
tax_table(ps)[,8][which(tax_table(ps)[,8]=="Brachypeplus Sp2")] <- "Brachypeplus Sp"

#Subset full run to only Carpophilus samples of interest
ps <- ps %>%
  subset_taxa(
    Phylum == "Arthropoda" &
    !Order == "Synthetic"
    )%>%
  subset_samples(str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]")) %>%
  subset_samples(type %in% c("CarpMock",  "CarpTrap", "CarpLarval")) %>%
  subset_samples(pcr_primers == "fwhF2-fwhR2n") %>%
  subset_samples(fcid %in% c("HLVKYDMXX", "CB3DR")) %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) %>%
  speedyseq::tax_glom(taxrank="Species") # Agglomerate to species

dir.create("output/csv")
dir.create("output/csv/unfiltered/")

# Export raw csv
export <- speedyseq::psmelt(ps) %>%
  filter(Abundance > 0)
write.csv(export, file = "output/csv/rawdata.csv")

# Summary export
seqateurs::summarise_taxa(ps, "Species", "sample_name") %>%
  filter(!str_detect(sample_name, "NTC")) %>%
  spread(key="sample_name", value="totalRA") %>%
  filter(!str_detect(Species, "__")) %>%
  write.csv(file = "output/csv/unfiltered/spp_sum.csv")

seqateurs::summarise_taxa(ps, "Genus", "sample_name") %>%
  spread(key="sample_name", value="totalRA") %>%
  filter(!str_detect(Genus, "__")) %>%
  write.csv(file = "output/csv/unfiltered/gen_sum.csv")

# Species detection summary
speedyseq::psmelt(ps) %>%
  filter(!str_detect(Genus, "__"), Abundance > 0 ) %>%
  mutate(abundance_ra = Abundance) %>%
  group_by(sample_id, fcid) %>%
  mutate_at(vars(abundance_ra), ~ . / sum(., na.rm = TRUE) ) %>%
  ungroup() %>%
  group_by(Species) %>%
  summarise(total_reads = sum(Abundance), mean_ra = mean(abundance_ra, na.rm=TRUE))%>%
  write.csv(file = "output/csv/unfiltered/detection_summary.csv")


# Output fasta of all ASV's - Name each one by abundance + taxonomic assignment
seqateurs::ps_to_fasta(ps, "output/all_taxa.fasta", seqnames = "Species")
```

## Minimum read filtering

Here we will remove any samples with below 1000 reads
```{r minimum reads}
# threshold for read removal
threshold = 1000

#Create rarefaction curve
rare <- otu_table(ps) %>%
  as("matrix") %>%
  rarecurve(step=max(sample_sums(ps))/100) %>%
  purrr::map(function(x){
    b <- as.data.frame(x)
    b <- data.frame(OTU = b[,1], count = rownames(b))
    b$count <- as.numeric(gsub("N", "",  b$count))
    return(b)
  }) %>%
  purrr::set_names(sample_names(ps)[rowSums(otu_table(ps) %>% as("matrix")) > 0]) %>%
  bind_rows(.id="sample_id")

gg.rare <- ggplot(data = rare)+
  geom_line(aes(x = count, y = OTU, group=sample_id), alpha=0.5)+
  geom_point(data = rare %>% 
               group_by(sample_id) %>% 
               top_n(1, count),
             aes(x = count, y = OTU, colour=(count > threshold))) +
  geom_label(data = rare %>% 
               group_by(sample_id) %>% 
               top_n(1, count),
             aes(x = count, y = OTU,label=sample_id, colour=(count > threshold)),
             hjust=-0.05)+
  scale_x_continuous(labels =  scales::scientific_format()) +
  geom_vline(xintercept=threshold, linetype="dashed") +
  labs(colour = "Sample kept?") +
  xlab("Sequence reads") +
  ylab("Observed ASV's")

gg.rare

#Write out figure
pdf(file="fig/rarefaction.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.rare)
try(dev.off(), silent=TRUE)

#Remove all samples under the minimum read threshold 
ps1 <- prune_samples(sample_sums(ps)>=threshold, ps) 
ps1 <- filter_taxa(ps1, function(x) mean(x) > 0, TRUE) #Drop missing taxa from table
message(nsamples(ps) - nsamples(ps1), " Samples and ", ntaxa(ps) - ntaxa(ps1), " taxa under read threshold Dropped")

# Check which were dropped
setdiff(sample_names(ps), sample_names(ps1))
```


### Summary statistics

```{r sum taxa}
exp_samples <- read_csv("sample_data/expected_quant_carpophilus.csv") %>%
  pivot_longer(-sample_name,
               names_to= "taxon",
               values_to= "expected") %>%
  mutate(taxon = str_replace(taxon, pattern=" ",replacement="_"),
         sample_name = str_remove(sample_name, "-exp*.$")) %>%
  dplyr::filter(!is.na(sample_name),
  str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]"),
  expected > 0) %>%
  distinct()

summary_dat <- ps1 %>%
  speedyseq::tax_glom(taxrank = "Species") %>%
  speedyseq::psmelt()  %>%
  filter(Abundance > 0 ) %>%
  dplyr::select(OTU, Sample, Abundance, sample_id, sample_name, extract_id, fcid, rank_names(ps1), type) %>%
  mutate(Genus = case_when(
    str_detect(Genus, "__") ~ as.character(NA),
    TRUE  ~ Species
  )) %>%
  mutate(Species = case_when(
    str_detect(Species, "__") ~ as.character(NA),
    TRUE ~ Species
  )) %>%
  mutate(abundance_ra = Abundance) %>%
  group_by(sample_id, fcid) %>%
  mutate_at(vars(abundance_ra), ~ . / sum(., na.rm = TRUE) ) %>%
  ungroup() %>% 
  mutate(above_thresh = case_when(
    abundance_ra < 1e-4 ~ FALSE,
    TRUE ~ TRUE
    )) %>%
  mutate(mock_spp = case_when(
    str_replace(Species, " ", "_") %in% exp_samples$taxon ~ TRUE,
    TRUE ~ FALSE
  ))

summary_dat%>%
  filter(above_thresh) %>%
  group_by(mock_spp) %>%
  summarise(n_extracts = n_distinct(extract_id), n_samples = n_distinct(sample_id),
            n_asv = n_distinct(OTU), n_spp = n_distinct(Species), n_genus = n_distinct(Genus))

summary_dat %>%
  filter(above_thresh, !str_detect(Species, "__")) %>%
  dplyr::select(Species, Order) %>%
  distinct() %>%
  pull(Order) %>%
  length()
  
  
# N unique species and samples
summary_dat %>%
  summarise(n_extracts = n_distinct(extract_id), n_samples = n_distinct(sample_name), n_reps = n_distinct(sample_id))

# Spread of reads
summary_dat %>%
  group_by(extract_id, fcid) %>%
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  group_by(fcid) %>%
  summarise(mean = mean(Abundance), 
            se = sd(Abundance)/sqrt(length(Abundance)),
            max = max(Abundance),
            min = min(Abundance),
            total = sum(Abundance))

# Spread of ASVs across samples - Add a grouping variable if they were in the mock communities, as well as if they were below 1e-4RA
ps1 %>%
  group_by(extract_id, fcid) %>%
  dplyr::filter(Abundance > 0) %>%
  summarise(counts = n_distinct(OTU)) %>%
  ungroup() %>%
  group_by(fcid) %>%
  summarise(mean = mean(counts), 
            se = sd(counts)/sqrt(length(counts)),
            max = max(counts),
            min = min(counts))

#Fraction of reads assigned to each taxonomic rank
speedyseq::psmelt(ps1) %>%
  gather("Rank","Name", rank_names(ps1)) %>%
  group_by(Rank) %>% 
  mutate(Name = replace(Name, str_detect(Name, "__"), NA)) %>% # This line turns the "__" we added to lower ranks back to NA's
  dplyr::summarise(Reads_classified = sum(Abundance * !is.na(Name))) %>%
  mutate(Frac_reads = Reads_classified / sum(sample_sums(ps1))) %>%
  mutate(Rank = factor(Rank, rank_names(ps1))) %>%
  arrange(Rank)

#Fraction of ASV's assigned to each taxonomic rank
tax_table(ps1) %>%
  as("matrix") %>%
  as_tibble(rownames="OTU") %>%
  gather("Rank","Name",rank_names(ps1)) %>%
  group_by(Rank) %>%
  mutate(Name = replace(Name, str_detect(Name, "__"), NA)) %>% # This line turns the "__" we added to lower ranks back to NA's
  dplyr::summarise(OTUs_classified = sum(!is.na(Name))) %>%
  mutate(Frac_OTUs = OTUs_classified / ntaxa(ps1)) %>%
  mutate(Rank = factor(Rank, rank_names(ps1))) %>%
  arrange(Rank)

# Unique taxa at each rank
speedyseq::psmelt(ps1) %>%
  dplyr::select(rank_names(ps1)) %>%
  pivot_longer(everything(),
               names_to = "Rank",
               values_to = "value") %>%
  mutate(value = case_when(
    str_detect(value, "__") ~ as.character(NA),
    !str_detect(value, "__") ~ value
  )) %>%
  drop_na() %>%
  group_by(Rank) %>%
  summarise_all(list(n_distinct)) %>%
  mutate(Rank = factor(Rank, rank_names(ps1))) %>%
  arrange(Rank)


# Phylogeny of taxa

tree <- ps1 %>%
      speedyseq::tax_glom(taxrank = "Species")%>%
      phy_tree()

tree$tip.label <- tree$tip.label %>%
    str_remove("^.*-") %>%
  str_replace("nr.dimidiatus", "truncatus")

# Check which are missing
unique(summary_dat$Species)[!unique(summary_dat$Species) %in% tree$tip.label]

unique(rownames(p1dat))[!unique(rownames(p1dat)) %in% tree$tip.label]

# Plot tree, with taxon names 
known_taxa <- exp_samples$taxon %>% str_replace("_", " ") %>% unique()

p1dat <- ps1 %>%
    speedyseq::tax_glom(taxrank = "Species") %>%
    speedyseq::psmelt() %>%
    dplyr::select(sample_id, OTU, type, Abundance) %>%
    mutate(OTU = OTU %>% str_remove("^.*-") %>% str_replace("nr.dimidiatus", "truncatus"),
           type = type %>% str_remove("Carp")) %>%
    group_by(sample_id) %>%
    mutate_at(vars(Abundance), ~ . / sum(.)) %>%
    mutate(keep = case_when(
      OTU %in% known_taxa ~ TRUE,
      Abundance > 1e-4 & type == "Trap" ~ TRUE,
      !OTU %in% known_taxa & !type == "Trap"~ FALSE,
      TRUE ~ FALSE
    ))%>%
    filter(keep) %>%
    filter(!OTU == "Opilo whitei") %>%
    drop_na() %>%
    group_by(OTU, type) %>%
    summarise(Abundance = mean(Abundance)) %>%
    distinct() %>%
    pivot_wider(names_from = type,
    values_from = Abundance,
    values_fill = 0) %>%
    filter(!str_detect(OTU, "__")) %>%
    column_to_rownames("OTU")

tree <- drop.tip(tree, tree$tip.label[!tree$tip.label %in% rownames(p1dat)])

circ <- ggtree(tree, layout = "circular", branch.length = 'none', aes(color=Order))

circ_dat <- circ$data %>%
  left_join(speedyseq::psmelt(ps1)  %>%
    mutate(OTU = OTU %>% str_remove("^.*-")  %>% str_replace("nr.dimidiatus", "truncatus")) %>%
    mutate(taxa_kept = case_when(
    Species %in% known_taxa ~ TRUE,
    !Species %in% known_taxa ~ FALSE
    )) %>%
    dplyr::select(label = OTU, Order, taxa_kept) %>%
    distinct()
  )

cols <- colorRampPalette(brewer.pal(8, "Set2"))(length(unique(circ_dat$Order)))
circ <- circ %<+% circ_dat +
    scale_colour_manual(values=cols, na.value="black")

gg.phylo <- gheatmap(circ, p1dat, offset=0, width=.4, color="gray20",
    colnames_angle=95, colnames_offset_y = 0) +
    scale_fill_viridis_c(option="B", name="Abundance", alpha=0.9, trans="log10", label= scales::percent) +
    geom_tiplab(offset=7.2, align=FALSE, size=4)+
    new_scale_colour() +
    geom_tippoint(aes(colour=taxa_kept), size=3)+
    scale_colour_manual(values=c("#d2d2d2", "#1b9e77")) +
    labs(colour = "Morphologically \nrecorded?")

gg.phylo

#Save figure
pdf(file="fig/supplementary/phylo_detections.pdf", width = 8, height = 6, paper="a4r")
  plot(gg.phylo)
try(dev.off(), silent=TRUE)

```

# Taxon filtering

Here we will remove any taxa that were not included in the mock communities

```{r filter taxa}
get_taxa_unique(ps1, "Order")
ps1 # Check the number of taxa prior to removal

tax_to_keep <- exp_samples$taxon %>%
  unique() %>%
  str_replace("_", " ")

tax_to_keep[!tax_to_keep %in% (tax_table(ps1) %>% as("matrix") %>% as.data.frame %>% dplyr::pull(Species))]

ps2 <- ps1 %>%
  subset_taxa(Species %in% tax_to_keep)

# Spread of reads after filtering
ps2 %>%
  speedyseq::psmelt()%>%
  group_by(extract_id, fcid) %>%
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  group_by(fcid) %>%
  summarise(mean = mean(Abundance), 
            se = sd(Abundance)/sqrt(length(Abundance)),
            max = max(Abundance),
            min = min(Abundance),
            total = sum(Abundance))
```

## Success of replicates

Check how many replicated PCR's were successful

```{r rep success }
exp_samples <- read_csv("data/HLVKYDMXX/SampleSheet.csv", skip = 19) %>%
  dplyr::select(extract_id = Sample_Name, sample_name = Sample_Name) %>%
  group_by(extract_id) %>%
  #group_split() %>%
  group_modify(~{
    .x %>%
      dplyr::slice(rep(1:n(), each=3)) %>%
      mutate(amp_rep = row_number()) %>%
      mutate(sample_id = paste0(sample_name, "_", amp_rep))
  }) %>%
  ungroup() %>%
  mutate(sample_name = extract_id %>%
           str_remove("-ex[0-9]$"))%>%
  mutate(type = case_when(
    str_detect(sample_id, "D[0-9][0-9][0-9]M|D[0-9][0-9][0-9][0-9]M|DM[0-9]")  ~ "DrosMock",
    str_detect(sample_id, "SPD")  ~ "SPD",
    str_detect(sample_id, "ACV")  ~ "ACV",
    str_detect(sample_id, "DC")  ~ "DC",
    str_detect(sample_id, "Sach")  ~ "Sachet",
    str_detect(sample_id, "FF")  ~ "FF",
    str_detect(sample_id, "NTC")  ~ "NTC",
    str_detect(sample_id, "DLarv")  ~ "DrosLarv",
    str_detect(sample_id, "POS|SynMock")  ~ "POS",
    str_detect(sample_id, "extblank|BLANK")  ~ "Extblank",
    str_detect(sample_id, "pcrblank")  ~ "PCRblank",
    str_detect(sample_id, "CT")  ~ "CarpTrap",
    str_detect(sample_id, "CM[0-9]")  ~ "CarpMock",
    str_detect(sample_id, "CML[0-9]")  ~ "CarpLarval"
  )) %>%
  filter(type %in% c("CarpMock", "CarpLarval", "CarpTrap"))

# Heatmap of abundance of pcr replicates
rep_data <- exp_samples %>%
  left_join(ps2 %>% 
  speedyseq::psmelt() %>%
    filter(Abundance > 0) %>%
    group_by(sample_name, extract_id, sample_id, amp_rep, fcid, type) %>%
    summarise(Abundance = sum(Abundance), n_spp = n_distinct(Species)) %>%
    ungroup()) %>%
  mutate(extrep = extract_id %>% str_extract("ex.*$")) %>%
  #filter(!(extrep=="ex1" & amp_rep == 2)) %>%
  mutate(amp_rep = factor(amp_rep)) %>%
  mutate(extrep = extrep %>% str_replace("ex", "Extraction Rep ")) %>%
  filter(amp_rep %in% 1:3)

# Summarise of replicate success
rep_data %>%
  ungroup() %>%
  mutate(success = case_when(
    Abundance > 0 ~ TRUE,
    Abundance == 0 | is.na(Abundance) ~ FALSE
  )) %>%
  group_by(type) %>%
  summarise(sum=sum(success), total = n()) %>%
  mutate(proportion = sum / total)

# Summary of sample success
rep_data %>%
  ungroup() %>%
  group_by(sample_name, type) %>%
  summarise(Abundance = sum(Abundance, na.rm = TRUE))%>%
  ungroup() %>%
  mutate(success = case_when(
    Abundance > 0 ~ TRUE,
    Abundance == 0 | is.na(Abundance) ~ FALSE
  )) %>%
  group_by(type) %>%
  summarise(sum=sum(success), total = n()) %>%
  mutate(proportion = sum / total)


gg.repmap <- rep_data %>%
   ggplot(aes(x = amp_rep, y = sample_name, fill = n_spp)) +
  geom_tile()+
  scale_fill_viridis_c()+
  facet_grid(extrep~type, scales="free", space="free", drop=TRUE)+
  base_theme+
  scale_x_discrete(expand=c(0,0))+
  scale_y_discrete(expand=c(0,0))+
  coord_flip()+
  theme(legend.position = "right")+
  labs(x = "PCR Replicate",
       y = NULL,
       fill = "N Species")
gg.repmap

#Save figure
pdf(file="fig/supplementary/replicate_success.pdf", width = 10, height = 8 , paper="a4r")
  plot(gg.repmap)
try(dev.off(), silent=TRUE)
```

## Consistency of bias between samples & repliciates

```{r Consistency between reps}
exp <- read_csv("sample_data/expected_quant_carpophilus.csv") %>%
  pivot_longer(-sample_name,
               names_to= "taxon",
               values_to= "expected") %>%
  mutate(taxon = str_replace(taxon, pattern=" ",replacement="_"),
         sample_name = str_remove(sample_name, "-exp*.$")) %>%
  dplyr::filter(!is.na(sample_name),
  str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]"),
  expected > 0) %>%
  distinct()

#Get obsered
sam <- speedyseq::psmelt(ps2) %>%
  janitor::clean_names() %>%
  filter(!str_detect(species, "__")) %>%#Remove unclassified
  mutate(taxon = species %>% str_replace(" ", "_")) %>%
  dplyr::select(sample_name, extract_id, taxon, abundance, amp_rep, pcr_primers, fcid, material_type = type) %>%
  mutate(sample_name = sample_name %>%
           str_remove_all("BF1-BR1-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-|fwhF2-fwhR2n-") %>%
           str_remove("HLVKYDMXX_") %>%
           str_remove("CB3DR_"),
         sample_id = paste0(fcid, "_", sample_name),
         sample_name = sample_name %>%
           str_remove("-ex[0-9]")) %>%
  mutate(extrep = extract_id %>% str_extract("ex.*$")) %>%
  #filter(!(extrep=="ex1" & amp_rep == 2)) %>%
  mutate(amp_rep = factor(amp_rep)) %>%
  mutate(extrep = extrep %>% str_replace("ex", "Extraction Rep ")) %>%
  filter(amp_rep %in% 1:3)

#Join tables 
joint <- sam %>%
  filter(taxon %in% exp$taxon,
         sample_name %in% exp$sample_name) %>%
  left_join(exp, by = c("sample_name","taxon")) %>%
  dplyr::rename(observed = abundance) %>%
  filter(!is.na(expected))%>%
  mutate(expected = replace_na(expected, 0),
         observed0 = (observed + 0.5) * (expected > 0),
         error = observed0 / expected,
         #error_centre = center_elts(observed0 / expected, na.rm = TRUE),
         ) %>%
  distinct() %>%
  group_by(sample_id) %>%
  mutate(observed.prop=observed, expected.prop=expected) %>%
  mutate_at(vars(observed.prop,  expected.prop), ~ . / sum(.) ) %>% #Convert to proportions
  mutate(sample_size = sum(expected), # Do the same for the ratios?
         observed_abs = observed.prop * sample_size,
         error_abs = observed_abs / expected,
         error_prop = observed.prop / expected.prop,
         rsq_abs = (expected - observed_abs)^2,
         rsq_prop = (expected.prop - observed.prop)^2,
         rprop = expected.prop - observed.prop
         )%>%
  filter(!sample_id=="HLVKYDMXX_CML6")  %>%
  mutate(amp_rep = paste0("PCR Rep ", amp_rep),
         extrep = extrep %>% str_replace("Extraction", "NovaSeq Ext"))

# Error in material types

# Get RMSE
mat_rmse <- joint %>%
  group_by(material_type) %>%
  rmse(truth = expected.prop, estimate = observed.prop) %>%
  dplyr::select(RMSE = .estimate, material_type)


gg.mat_err <- joint  %>%
  left_join(mat_rmse) %>%
  mutate(material_type = material_type %>%
        str_replace("CarpLarval", "Larval Mock") %>%
        str_replace("CarpMock", "Adult Mock") %>% 
        str_replace("CarpTrap", "Adult Trapped") %>%
          factor(levels = c("Adult Trapped", "Larval Mock", "Adult Mock"))) %>%
  mutate(taxon = taxon %>% str_replace("_", " ")) %>%
  ggplot(aes(x = material_type, y = rsq_prop, colour=taxon, group=material_type))+
  geom_boxplot(width =0.9, alpha=0.4, outlier.colour = NA, fill="#d2d2d2", colour="black")+
  geom_point(position=position_jitter(width = 0.15, height=0), alpha=0.6, size=2)+ 
  geom_text(aes(label = paste0("RMSE:",round(RMSE, 2)), y = .3), check_overlap = TRUE, colour="black") +
  scale_colour_brewer(palette = "Paired")+
  scale_y_continuous(trans=pseudo_log_trans(0.01), labels=scales::percent_format(accuracy=1), breaks=c(0, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4))+
  base_theme +
  #facet_grid(~material_type)+
  coord_flip()+
  theme(
    #strip.text = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    panel.grid.minor.x = element_blank(),
    strip.text = element_text(face = "italic"),
    legend.position = "none"
  )+
  labs(y="Squared residual error ",
       x = NULL)

gg.mat_err

# Deviation in taxon specific errors between samples
error_variation <- joint %>% 
  #filter(fcid == "HLVKYDMXX")%>%
  group_by(taxon)%>%
  group_modify(~{
    amp_err <- .x %>%
      group_by(extract_id) %>%
      add_tally()  %>%
      filter(n > 1) %>%
      summarise(error_prop = mean(error_prop),  rmse_prop = sqrt(mean(rsq_prop))) %>%
      mutate(type = "PCR")%>%
      dplyr::select(-extract_id)
    
    ext_err  <- .x %>%
      group_by(extract_id, sample_name, fcid) %>%
      summarise(error_prop = mean(error_prop),  rsq_prop = mean(rsq_prop)) %>%
      ungroup() %>%
      mutate(sample_fcid = paste0(fcid, sample_name)) %>%
      group_by(sample_fcid) %>% 
      add_tally()  %>%
      filter(n > 1) %>%
      summarise(error_prop = mean(error_prop),  rmse_prop = sqrt(mean(rsq_prop))) %>%
      mutate(type = "Extraction") %>%
      dplyr::select(-sample_fcid)
    
    samp_err  <- .x %>%
      mutate(sample_fcid = paste0(fcid, sample_name)) %>%
      group_by(sample_fcid) %>% 
      summarise(error_prop = mean(error_prop), rmse_prop = sqrt(mean(rsq_prop))) %>%
      ungroup() %>%
      mutate(type = "Sample") %>%
      dplyr::select(-sample_fcid)
    
    out <- bind_rows(amp_err, ext_err, samp_err)
    return(out)
  })

gg.err_var <- error_variation %>%
  mutate(taxon = taxon %>% str_replace("_", " ")) %>%
  ggplot(aes(x = type, y = rmse_prop, fill=taxon, group=type))+
  geom_point(position=position_jitter(width = 0.15, height=0), colour="#d2d2d2", alpha=0.8)+
  geom_boxplot(width =0.9, alpha=0.7, outlier.colour = NA)+
  scale_fill_brewer(palette = "Paired")+
  facet_grid(~taxon) +
  scale_y_continuous(trans=pseudo_log_trans(0.01), labels=scales::percent_format(accuracy=1))+
  base_theme +
  theme(
    #strip.text = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    strip.text = element_text(face = "italic"),
    legend.position = "none"
  )+
  labs(y="RMSE",
       x = NULL)

gg.err_var

## Visualise errors in proportions between different replicates
error_rmse <- joint %>%
  group_by(extrep, amp_rep) %>%
  rmse(truth = expected.prop, estimate = observed.prop) %>%
  dplyr::select(RMSE = .estimate, extrep, amp_rep)

error_anorm <- joint %>%
  group_by(material_type) %>%
    summarise(Adist = anorm(observed.prop / expected)) 

gg.error_props <- joint %>% 
  mutate(taxon = taxon %>% str_replace("_", " ")) %>%
  filter(expected > 0) %>%
  #mutate_at(vars(expected.prop, observed.prop), logit) %>%
  left_join(error_rmse) %>%
  left_join(error_anorm) %>%
  mutate(extrep = replace_na(extrep, "MiSeq")) %>%
  ggplot(aes(expected.prop, observed.prop, fill = taxon)) + 
  geom_abline(intercept = 0, slope=1) +
  geom_point(alpha=0.7, shape=21, colour="black", ) +
  geom_text(aes(x=0, y=0.9, label=paste0("RMSE: ",round(RMSE, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  #geom_text(aes(x=-10, y=1, label=paste0("A.dist: ",round(Adist, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  scale_fill_brewer(palette="Paired")+
  facet_grid(extrep~amp_rep)+
  scale_x_continuous(trans = scales::pseudo_log_trans(1e-3), labels=scales::percent, breaks=c(0, 0.025, 0.05, 0.1, 0.25, 0.5, 1), limits=c(0,1))+
  scale_y_continuous(trans = scales::pseudo_log_trans(1e-3), labels=scales::percent, breaks=c(0, 0.025, 0.05, 0.1, 0.25, 0.5, 1), limits=c(0,1))+
  base_theme+
  theme(legend.position="top",
        legend.text = element_text(face="italic"))+
  labs(fill = "Taxon",
       x="Expected proportions",
       y="Observed proportions") 

gg.error_props

#Save figure
pdf(file="fig/supplementary/error_fits_replicates.pdf", width = 10, height = 8 , paper="a4r")
  plot(gg.error_props)
try(dev.off(), silent=TRUE)
```

## Merge replicates 

```{r merge replicates}
# Merge replicates
ps.merged <- ps2 %>%
    merge_samples(group = "sample_name", fun="sum")

#This loses the sample metadata - Need to add it agian
sample_data(ps.merged) <- sample_data(ps2) %>%
  as("data.frame") %>%
  dplyr::filter(!duplicated(sample_name)) %>%
  magrittr::set_rownames(.$sample_name)

```

# Combine expected and observed taxa

```{r make joint}
ps_bias <- ps.merged

#Get Observed
sam <- speedyseq::psmelt(ps_bias) %>%
  janitor::clean_names() %>%
  filter(!str_detect(species, "__")) %>%#Remove unclassified
  mutate(taxon = species %>% str_replace(" ", "_")) %>%
  dplyr::select(sample_name,sample_id, taxon, abundance, pcr_primers, fcid, material_type = type) %>%
  mutate(sample_name = sample_name %>%
           str_remove_all("BF1-BR1-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-|fwhF2-fwhR2n-") %>%
           str_remove("HLVKYDMXX_") %>%
           str_remove("CB3DR_"),
         sample_id = paste0(fcid, "_", sample_name), #Remove this for ps1
         sample_name = sample_name %>%
           str_remove("-ex[0-9]")) 

#Join tables 
joint <- sam %>%
  filter(taxon %in% exp$taxon,
         sample_name %in% exp$sample_name) %>%
  left_join(exp, by = c("sample_name","taxon")) %>%
  dplyr::rename(observed = abundance) %>%
  filter(!is.na(expected))%>%
  mutate(expected = replace_na(expected, 0),
         observed0 = (observed + 0.5) * (expected > 0),
         error = observed0 / expected,
         #error_centre = center_elts(observed0 / expected, na.rm = TRUE),
         ) %>%
  distinct() %>%
  group_by(sample_id) %>%
  mutate(observed.prop=observed0, expected.prop=expected) %>%
  mutate_at(vars(observed.prop,  expected.prop), ~ . / sum(.) ) %>% #Convert to proportions
  mutate(sample_size = sum(expected), # Do the same for the ratios?
         observed_abs = observed.prop * sample_size,
         error_abs = observed_abs / expected,
         error_abs_log = log(error_abs),
         error_prop = observed.prop / expected.prop,
         error_prop_log = log(error_prop),
         error_prop_logit = logit(error_prop),
         res_prop = expected.prop - observed.prop,
         res_abs = expected - observed_abs,
         #error_abs_centre = center_elts(observed_abs / expected, na.rm = TRUE)
         )  %>%
  group_by(sample_id) %>%
  group_modify(~{
    alr_denom <- .x %>% 
      filter(taxon == "Carpophilus_hemipterus") %>% # Set to consistent taxon across all
      pull(error)
    clr_denom <- .x %>%
      pull(error) %>%
      gm_mean()
    .x %>%
      mutate(error_alr = log(error / alr_denom),
             error_clr = log(error / clr_denom))
  }) %>%
  filter(!sample_name=="CML6") #Bad sample

saveRDS(joint, "output/joint.rds")
```


# Visualise errors

```{r visualise errors}
gg.error_types <- joint %>%
  pivot_longer(c(error_alr, error_clr, res_prop, res_abs),
               names_to = "error_type",
               values_to="error_val")  %>%
  mutate(material_type = material_type %>%
        str_replace("CarpLarval", "Larval Mock") %>%
        str_replace("CarpMock", "Adult Mock") %>% 
        str_replace("CarpTrap", "Adult Trapped") %>%
        factor(levels = c("Adult Trapped", "Larval Mock", "Adult Mock"))) %>%
  mutate(taxon = taxon %>% 
           str_replace("_", " ") %>%
           str_replace("Sp$", "sp.")) %>%
  mutate(error_type = error_type %>%
      str_remove("error_") %>%
      str_remove("res_") %>%
      str_replace("prop$", "Proportions") %>%
      str_replace("alr$", "ALR")%>%
      str_replace("clr$", "CLR")%>%
      str_replace("abs$", "Absolute") %>%
      factor(levels = c("Proportions", "Absolute", "ALR", "CLR"))) %>%
  ungroup()%>%
  mutate(uid = row_number()) %>%
  ggplot(aes(x = taxon, y = error_val, colour=taxon, group=uid))+
  geom_linerange(aes(ymin=0, ymax = error_val, xmax=taxon, xmin=taxon), position=position_dodge(width = 0.4), alpha=0.6, colour="#d2d2d2")+
  geom_hline(yintercept = 0, colour="black", size=1)+
  geom_point(position=position_dodge(width = 0.4), alpha=0.8, size=1.5)+
  scale_colour_brewer(palette = "Paired")+
  #scale_x_discrete(position="top")+
  base_theme +
  facet_grid(material_type~error_type, scales="free", space="free_y", drop=TRUE)+
  coord_flip()+
  theme(
    #strip.text = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    panel.grid.minor.x = element_blank(),
    legend.position = "none",
    axis.text.y = element_text(face="italic",)
  )+
  labs(y="Error",
       x = NULL)

gg.error_types

# Images for multifig
gg.mock_adult <- ggplot() +
  background_image(image_read("images/carpophilus_mock3.jpg")) + 
  coord_fixed()

gg.mock_larval <- ggplot() +
  background_image(image_read("images/Carpophilus_larval1.jpg")) + 
  coord_fixed()

gg.trap_adult <- ggplot() +
  background_image(image_read("images/carpophilus_trap5.jpg")) + 
  coord_fixed()


photo_stack <- gg.mock_adult / gg.mock_larval / gg.trap_adult


#Fig2a <- photo_stack - gg.error_types + plot_layout(widths = c(1,3))
Fig2a <- gg.error_types - photo_stack + plot_layout(widths = c(5,1))

Fig2 <-  Fig2a / gg.err_var + plot_layout(heights = c(3,1)) + plot_annotation(tag_levels = "A")

Fig2

#Save figure
pdf(file="fig/Fig2_error_consistency.pdf", width = 11, height = 8 , paper="a4r")
  plot(Fig2)
try(dev.off(), silent=TRUE)

  
# Visualise the error in all pairwise ratios
gg.pw_error_rat <- joint %>%
  filter(expected > 0) %>%
  dplyr::mutate(Taxon = taxon %>%
                  str_replace("^.+_", paste0(str_extract(taxon, "."), "_"))) %>% #Shorten genus names
  metacal::compute_ratios(group_vars = c("sample_id", "fcid", "material_type")) %>%
  filter(!is.na(expected)) %>%
  filter(!Taxon.x == Taxon.y) %>%
  mutate(pair = paste(Taxon.x, Taxon.y, sep = ":")) %>% 
  ggplot(aes(pair, error, colour=Taxon.x)) +
  geom_jitter(alpha=0.7) +
  geom_hline(yintercept = 1) +
  scale_y_log10() +
  facet_grid(material_type~fcid)+
  theme_bw()+
    scale_color_brewer(palette="Spectral")+
    theme(legend.position = "none",
          axis.text.x = element_text(angle=45, hjust=1)) +
  labs(x = "Taxon ratios",
       y = "Error in taxon ratios")
```

# Train bias models

```{r splits}
# Make training / testing splits  ------------------------------------------------------------
set.seed(666)

# Get 100 different random seeds
seeds <- sample(1:10000, 2, replace = FALSE)
s=1

split_list <- vector("list", length=length(seeds))
for (s in 1:length(seeds)){
  set.seed(seeds[s])
  
  joint_split <- joint  %>%
    ungroup() %>%
    dplyr::select(sample_name, material_type) %>%
    distinct() %>%
    initial_split(strata = material_type, prop = .8)
  
  # Training set
  joint_train <- joint %>%
    dplyr::select(-error) %>%
    filter(sample_name %in% training(joint_split)$sample_name) %>%
    ungroup()%>%
    pivot_longer(starts_with("error"),
                 names_to="error_type",
                 values_to="error") %>%
    mutate(observed.prop =case_when(
      error_type == "error_prop_logit" ~ logit(observed.prop),
      error_type == "error_prop_log" ~ log(observed.prop),
      error_type == "error_abs_log" ~ log(observed_abs),
      TRUE ~ observed.prop
      ),
      expected.prop = case_when(
      error_type == "error_prop_logit" ~ logit(expected.prop),
      error_type == "error_prop_log" ~ log(expected.prop),
      error_type == "error_abs_log" ~ log(expected),
      TRUE ~ expected.prop
      ))%>%
    filter(expected > 0) %>%
    group_by(error_type) %>%
    nest()%>%
    dplyr::rename(train=data)

  
  # Testing set
  joint_test <- joint %>%
    dplyr::select(-error) %>%
    filter(sample_name %in% testing(joint_split)$sample_name) %>%
    ungroup()%>%
    pivot_longer(starts_with("error"),
                 names_to="error_type",
                 values_to="error")%>%
    mutate(observed.prop =case_when(
      error_type == "error_prop_logit" ~ logit(observed.prop),
      error_type == "error_prop_log" ~ log(observed.prop),
      error_type == "error_abs_log" ~ log(observed_abs),
      TRUE ~ observed.prop
      ),
      expected.prop = case_when(
      error_type == "error_prop_logit" ~ logit(expected.prop),
      error_type == "error_prop_log" ~ log(expected.prop),
      error_type == "error_abs_log" ~ log(expected),
      TRUE ~ expected.prop
      ))%>%
    filter(expected > 0) %>%
    group_by(error_type) %>%
    nest() %>%
    dplyr::rename(test=data)
  
  # Create Cross validation folds for model tuning 
  train_cv <- joint_train %>%
    mutate(cv = purrr::map(train, function(x){
      x %>%
        group_vfold_cv(v = 5, group = sample_id) #Ensures samples are kept together
    })) %>%
    dplyr::select(-train)

  
  split_list[[s]] <- joint_train %>%
    left_join(joint_test, by="error_type") %>%
    left_join(train_cv, by="error_type")%>%
    mutate(seed = seeds[s])
    
}

all_equal(split_list[[1]]$test[[1]], split_list[[2]]$test[[1]])

#
models_to_fit <- c("lm", "lasso", "rf", "xgboost", "svm", "metacal", "uncorrected")

splits <- split_list %>%
  purrr::map(function(x){
    x %>% dplyr::slice(rep(1:n(), each = length(models_to_fit))) %>%
      mutate(model_type = models_to_fit)
  }) %>%
  bind_rows() %>%
  #filter(error_type %in% c("error_prop", "error_clr", "error_alr", "error_abs")) %>%
  ungroup()

# Preprocessing  ------------------------------------------------------------

# Recipe for fitting model including fcid + material_type
bias_recipe <- 
  recipe(formula = error ~ 0 + taxon + fcid + material_type, data = splits$train[[1]]) %>% 
  step_string2factor(fcid, material_type, taxon) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes(), one_hot=TRUE) %>% 
  step_zv(all_predictors())
  #step_normalize(-all_nominal()) 

#Recipe for fitting model to proportions
prop_recipe <- recipe(formula =  expected.prop ~ 0 + observed.prop + taxon + fcid + material_type, data = splits$train[[1]]) %>% 
  #step_string2factor(one_of(fcid, material_type)) %>% 
  step_string2factor(taxon) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes(), one_hot=TRUE) %>% 
  step_zv(all_predictors())  %>%
  step_normalize(observed.prop, expected.prop) %>%
  step_naomit(all_predictors())


# Define model function  ------------------------------------------------------------
modelling_func <- function(train, test, cv, error_type, model_type, val_err = TRUE){
  if (error_type  %in% c("error_alr", "error_clr")){
    type <- "ratio"
  } else if(!error_type  %in% c("error_alr", "error_clr")){
    type <- "prop"
  }
  print(error_type)
  
  #Create model specification for each different type
  if(model_type == "lm"){
    model_spec <- 
      linear_reg() %>% 
      set_mode("regression") %>% 
      set_engine("lm")
  } else if (model_type == "lasso"){
    model_spec <- 
      linear_reg(penalty = tune(), mixture = tune()) %>% 
      set_mode("regression") %>% 
      set_engine("glmnet") %>%
      set_args(family="gaussian")
  } else if (model_type == "rf"){
    model_spec <- 
      rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
      set_mode("regression") %>% 
      set_engine("ranger", importance = "impurity")
  } else if (model_type == "xgboost"){
    model_spec <- 
      boost_tree(
        trees = 1000, 
        tree_depth = tune(), min_n = tune(), 
        loss_reduction = tune(),                     ## first three: model complexity
        sample_size = tune(), mtry = tune(),         ## randomness
        learn_rate = tune(),                         ## step size
      ) %>% 
      set_mode("regression") %>% 
      set_engine("xgboost") 
  } else if (model_type == "svm"){
    model_spec <- 
      svm_poly(cost = tune(), degree = tune(), scale_factor = tune(), margin = tune()) %>% 
      set_mode("regression") %>% 
      set_engine("kernlab") 
  } else if (model_type == "metacal"){
    if(error_type == "error_alr"){
      denom <- "Carpophilus_hemipterus"
    } else {
      denom <- "all"
    }
    model_obj <- metacal_spec(train, denom=denom, out_scale = "log")
    
    pred_train <- train %>%
      left_join(model_obj, by="taxon") %>%
      dplyr::select(.pred)
    
    pred_test <- test %>%
      left_join(model_obj, by="taxon") %>%
      dplyr::select(.pred)
    
    if(val_err){
      cv_error <- cv %>%
        mutate(.metrics = purrr::map(splits, function(x){
          cv_train <- x %>%
            analysis() %>%
            metacal_spec(denom=denom, out_scale="linear")
          x %>%
            assessment()%>%
            left_join(cv_train, by="taxon") %>%
            mutate(error_type = error_type,
                   estimated = .pred,
                   observed.prop = case_when(
                     error_type == "error_abs" ~ exp(observed.prop),
                     error_type  == "error_prop" ~ expit(observed.prop),
                     TRUE ~ observed.prop),
                   expected.prop = case_when(
                     error_type == "error_abs" ~ exp(expected.prop),
                     error_type  == "error_prop" ~ expit(expected.prop),
                     TRUE ~ expected.prop),
                   predicted = case_when(
                     error_type %in% c("error_prop", "error_abs") ~ estimated,
                     TRUE ~ expected.prop * estimated)
            ) %>%
            group_by(sample_id) %>%
            mutate_at(vars(predicted, observed.prop, expected.prop), ~ . / sum(.) ) %>%
            ungroup()  %>% 
            rmse(truth = expected.prop, estimate = predicted)
        }))%>% 
        unnest(.metrics) %>% 
        dplyr::select(fold= id, RMSE = .estimate)
    } else (cv_error <- NULL)
    
    out <- tibble(model_obj = list(model_obj),
                  pred_train = list(pred_train),
                  pred_test = list(pred_test),
                  cv_error = list(cv_error),
                  tune_res = NULL)
    return(out)
  } else if (model_type == "uncorrected"){
    model_obj <- train %>%
      dplyr::select(taxon) %>%
      distinct() %>%
      mutate(.pred = 0)
    pred_train <- train %>%
      left_join(model_obj, by="taxon") %>%
      dplyr::select(.pred)
    
    pred_test <- test %>%
      left_join(model_obj, by="taxon") %>%
      dplyr::select(.pred)
    
    if(val_err){
      cv_error <- cv %>%
        mutate(.metrics = purrr::map(splits, function(x){
          x %>%
            assessment()%>%
            rmse(truth = expected.prop, estimate = observed.prop)
        }))%>% 
        unnest(.metrics) %>% 
        dplyr::select(fold= id, RMSE = .estimate)
    } else (cv_error <- NULL)
    
    out <- tibble(model_obj = list(model_obj),
                  pred_train = list(pred_train),
                  pred_test = list(pred_test),
                  cv_error = list(cv_error),
                  tune_res = NULL
    )
    return(out)
  }
  
  # Create workflow
  if(type == "ratio"){
    # Tune ratio workflow
    model_workflow <- 
      workflow() %>% 
      add_recipe(bias_recipe) %>% 
      add_model(model_spec) 
  } else if(type == "prop"){
    # Tune proporiton workflow
    model_workflow <- 
      workflow() %>% 
      add_recipe(prop_recipe) %>%  #Proportions recipe
      add_model(model_spec) 
  } else (stop("type must be 'ratio' or 'prop' "))
  
  # Tune model if required
  if(!model_type %in% c("lm")){
    #Tune grid using a latin hypercube design
    model_tune <- tune_grid(model_workflow, resamples = cv, grid = 40)
    model_workflow <- finalize_workflow(model_workflow, model_tune %>% select_best("rmse"))
    tune_res <- collect_metrics(model_tune)
    
  }else {
    tune_res <- NULL
  }
  
  # Train on training set
  model_obj <- fit(model_workflow, data=train)
  
  # Predict training set
  pred_train <- safe_predict(model_obj, train)
  
  # Predict test set
  pred_test <- safe_predict(model_obj, test)
  
  # Get CV error
  if(val_err){
    cv_error <- fit_resamples(model_workflow,  resamples = cv) %>% 
      unnest(.metrics) %>% 
      filter(.metric == "rmse") %>%
      dplyr::select(fold= id, RMSE = .estimate)
  } else (cv_error <- NULL)
  
  out <- tibble(model_obj = list(model_obj),
                pred_train = list(pred_train),
                pred_test = list(pred_test),
                cv_error = list(cv_error),
                tune_res = list(tune_res))
  return(out)
}

# Fit modelling function  ------------------------------------------------------------

# Create multiprocess session
cores <- 2
future::plan(future::multiprocess, workers = cores)

fits_all <- splits %>%
  mutate(
    fits = furrr::future_pmap(list(train, test, cv, error_type, model_type), modelling_func)
  ) %>% 
  unnest(fits)

# write out fits_all
#saveRDS(fits_all, "output/fits_all.rds")

# Close multiprocess
future::plan(sequential)
```


# Evaluate all model fits

Here we compare the accuracy of the bias estimation procedure by looking at the Root Mean Square Error (RMSE) between the observed relative abundances from sequencing, and the predicted relative abundances (Expected * Bias estimate) from each model.

To determine the models predictive ability to new data, we also determine these metrics for a seperate testing set of samples that the model was not trained on.


```{r evaluate fits}
## OPTIONAL: Download pre-trained models
fits_all <- readRDS(url("https://zenodo.org/record/5370132/files/fits_all.rds?download=1"), options(timeout = 5*60))

# Get fits for training set
all_fits_train <- fits_all %>%
  unnest(pred_train, train) %>%
  dplyr::select(!where(is.list))%>%
  ungroup() %>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre",
                      "error_abs_centre", "error_abs_alr", "error_abs_clr",
                      "error_prop_log", "error_abs_log") ~ exp(.pred),
    error_type %in% c( "error_prop_logit") ~ expit(.pred),
    model_type == "metacal" ~ exp(.pred),
    TRUE ~ .pred
  ),
  observed.prop = case_when(
    error_type %in% c("error_abs_log", "error_prop_log") ~ exp(observed.prop),
    error_type %in% c("error_prop_logit") ~ expit(observed.prop),
    TRUE ~ observed.prop),
  expected.prop = case_when(
    error_type %in% c("error_abs_log", "error_prop_log") ~ exp(expected.prop),
    error_type %in% c("error_prop_logit") ~ expit(expected.prop),
    TRUE ~ expected.prop),
  predicted = case_when(
    error_type %in% c("error_prop", "error_abs", "error_abs_log", "error_prop_log", "error_prop_logit") & !model_type == "uncorrected" ~ estimated,
    model_type == "uncorrected" ~ observed.prop,
    TRUE ~ expected.prop * estimated),
  calibrated = case_when(
    error_type %in% c("error_prop", "error_abs", "error_abs_log", "error_prop_log", "error_prop_logit") & !model_type == "uncorrected"~ estimated,
    model_type == "uncorrected" ~ observed.prop,
    TRUE ~ observed.prop / estimated)
  ) %>%
  group_by(sample_id, error_type, model_type, seed) %>%
  mutate_at(vars(predicted, calibrated, observed.prop, expected.prop), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
 # mutate(residual = calibrated / expected.prop) %>%
  mutate(residual = expected.prop - calibrated,
         rsq = residual^2) %>%
  dplyr::filter(expected > 0)


# Get fits for testing set
all_fits_test <- fits_all %>%
  unnest(pred_test, test) %>% 
  dplyr::select(!where(is.list))%>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre",
                      "error_abs_centre", "error_abs_alr", "error_abs_clr",
                      "error_prop_log", "error_abs_log") ~ exp(.pred),
    model_type == "metacal" ~ exp(.pred),
    error_type %in% c( "error_prop_logit") ~ expit(.pred),
    TRUE ~ .pred
  ),
  observed.prop = case_when(
    error_type %in% c("error_abs_log", "error_prop_log") ~ exp(observed.prop),
    error_type %in% c("error_prop_logit") ~ expit(observed.prop),
    TRUE ~ observed.prop),
  expected.prop = case_when(
    error_type %in% c("error_abs_log", "error_prop_log") ~ exp(expected.prop),
    error_type %in% c("error_prop_logit") ~ expit(expected.prop),
    TRUE ~ expected.prop),
  predicted = case_when(
    error_type %in% c("error_prop", "error_abs", "error_abs_log", "error_prop_log", "error_prop_logit") & !model_type == "uncorrected" ~ estimated,
    model_type == "uncorrected" ~ observed.prop,
    TRUE ~ expected.prop * estimated),
  calibrated = case_when(
    error_type %in% c("error_prop", "error_abs", "error_abs_log", "error_prop_log", "error_prop_logit") & !model_type == "uncorrected"~ estimated,
    model_type == "uncorrected" ~ observed.prop,
    TRUE ~ observed.prop / estimated)
  ) %>%
  group_by(sample_id, error_type, model_type, seed) %>%
  mutate_at(vars(predicted, calibrated, observed.prop, expected.prop), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  #mutate(residual = calibrated / expected.prop) %>%
  mutate(residual = expected.prop - calibrated,
         rsq = residual^2) %>%
  dplyr::filter(expected > 0)

```

# Model comparison

```{r model comparison}
# Relative Abundances
fits <- all_fits_train %>%
  mutate(train = "Training set") %>%
  bind_rows(all_fits_test %>%
    mutate(train = "Test set")) %>%
  dplyr::select(model = model_type,seed, taxon, material_type, sample_name, sample_id, fcid, expected, expected.prop, observed, observed.prop, predicted, estimated, train, calibrated, residual, rsq,  error_type ,sample_size) %>%
  filter(!error_type == "error_abs_log") %>%
  mutate(model = model %>%
           str_replace("keras", "Neural Network") %>%
           str_replace("rf", "Random Forest") %>%
           str_replace("^lm$", "Linear Regression") %>%
           str_replace("xgboost", "XGBOOST") %>%
           str_replace("lasso", "LASSO Regression") %>%
           str_replace("uncorrected", "Uncorrected")%>%
           str_replace("svm", "SVM"),
         error_type = error_type %>%
      str_remove("error_") %>%
      str_replace("prop$", "Proportions") %>%
      str_replace("prop_log$", "Log")%>%
      str_replace("prop_logit$", "Logit")%>%
      str_replace("alr$", "ALR")%>%
      str_replace("clr$", "CLR")%>%
      str_replace("abs$", "Absolute"))

# Absolute abundances 
abs_fits <- all_fits_train %>%
  mutate(train = "Training set") %>%
  bind_rows(all_fits_test %>%
    mutate(train = "Test set")) %>%
  dplyr::select(model = model_type, seed, taxon, material_type, sample_name, sample_id, fcid, expected, expected.prop, observed, observed.prop, predicted, estimated, calibrated, residual, rsq,  train, error_type, sample_size) %>%
  mutate(predicted_abs = predicted * sample_size,
         observed_abs = observed.prop * sample_size,
         calibrated_abs = calibrated * sample_size)%>%
  filter(!error_type == "error_abs_log") %>%
  mutate(model = model %>%
           str_replace("keras", "Neural Network") %>%
           str_replace("rf", "Random Forest") %>%
           str_replace("^lm$", "Linear Regression") %>%
           str_replace("xgboost", "XGBOOST") %>%
           str_replace("lasso", "LASSO Regression") %>%
           str_replace("uncorrected", "Uncorrected")%>%
           str_replace("svm", "SVM"),
         error_type = error_type %>%
      str_remove("error_") %>%
      str_replace("prop$", "Proportions") %>%
      str_replace("prop_log$", "Log")%>%
      str_replace("prop_logit$", "Logit")%>%
      str_replace("alr$", "ALR")%>%
      str_replace("clr$", "CLR")%>%
      str_replace("abs$", "Absolute"))


# RMSE Between models
## Assess significant differences
model_rmse <- fits %>%
  mutate(type = "Relative") %>%
  filter(!(model == "metacal" & !error_type %in% c("ALR", "CLR"))) %>%
  bind_rows(
    abs_fits %>%
    mutate(type = "Absolute")) %>%
  group_by(model, error_type, type, train, seed) %>%
  #summarise(RMSE = nrmse_func(truth = calibrated, estimate = expected.prop, type = "sd"))  %>%
  rmse(truth = calibrated, estimate = expected.prop) %>%
  mutate(RMSE = .estimate)

# Compare to baseline linear regression model
t_tests <- compare_means(RMSE ~ model, data = model_rmse,
              group.by = c("train", "error_type", "type"), ref.group = "Linear Regression",
              method = "t.test", p.adjust.method = "hochberg")
#Write out comparisons
write_csv(t_tests, "output/model_comparison.csv")

gg.rmse <- model_rmse  %>%
  left_join(t_tests %>% dplyr::select(train, error_type, type, model = group2, p.adj, p.signif))  %>%
  filter(train == "Test set") %>%
  filter(!(model == "metacal" & !error_type %in% c("ALR", "CLR"))) %>%
 # dplyr::filter(error_type %in% c("error_prop", "error_abs", "error_clr", "error_alr")) %>%
  mutate(
    error_type = error_type %>%  factor(levels = c(
        "Proportions",
        "Log",
        "Logit",
        "ALR",
        "CLR",
        "Absolute"
      )),
    model = factor(model, levels = c(
      "XGBOOST",
      "Random Forest",
      "SVM",
      "LASSO Regression",
      "Linear Regression",
      "metacal", 
      "Uncorrected")),
    train = factor(train, levels=c("Training set", "Test set")),
    type = factor(type, levels = c("Relative", "Absolute"))) %>%
  ggplot(aes(x = model, y=RMSE, fill=model))+
  geom_point(position=position_jitter(width = 0.15, height=0),size=1, colour="#d2d2d2", alpha=0.8)+
  geom_boxplot(width =0.8, alpha=0.6, outlier.colour = NA)+
  geom_text(aes(y=0.4, x = model, label = p.signif), check_overlap = TRUE)+
  scale_fill_brewer(palette="Set2")+
  facet_grid(error_type~type, drop = TRUE, scales="free_y", space="free")+ 
  coord_flip() +
  base_theme +
  scale_y_continuous(labels = scales::percent_format(accuracy=1))+
  theme(legend.position = "none",
        panel.grid = element_blank())+
  labs(y = "RMSE",
       x = "Model Type",
       fill = "Transformation")

gg.rmse

pdf(file="fig/Fig3_model_comparison.pdf", width = 8, height = 8, paper="a4")
  plot(gg.rmse)
try(dev.off(), silent=TRUE)

```


## Check residuals & Plot RF fits

```{r outliers}
# Plot residuals by sample
fits %>%
  ggplot(aes(x  = sample_id, y = rsq)) +
  geom_col() + 
  facet_grid(model~.) +
  base_theme

# Look at residuals by taxa 
fits %>%
  group_by(error_type, model, taxon, seed) %>%
  rmse(truth = calibrated, estimate = expected.prop) %>%
  mutate(RMSE = .estimate) %>%
  ggplot(aes(x = taxon, y = RMSE, colour=taxon)) + 
  geom_point(position=position_jitter(width = 0.15, height=0), colour="#d2d2d2", alpha=0.8)+
  geom_boxplot(width =0.9, alpha=0.6, outlier.colour = NA)+
  scale_color_brewer(palette="Paired")+
  facet_grid(error_type ~ model) + 
  base_theme 
  
# Look for just Random forest
rf_dat <- fits %>%
  filter(error_type == "Proportions", model == "Random Forest") %>%
  mutate(material_type = material_type %>%
           str_replace("CarpLarval", "Larval Mock") %>%
           str_replace("CarpMock", "Adult Mock") %>% 
           str_replace("CarpTrap", "Adult Trapped")) %>%
  mutate(taxon = taxon %>% 
           str_replace("_", " ") %>%
           str_replace("Sp$", "sp.")) %>%
  group_by(taxon, seed, material_type) %>%
  rmse(truth = calibrated, estimate = expected.prop) %>%
  mutate(RMSE = .estimate) 


#ANOVA
compare_means(RMSE ~ taxon, data = rf_dat, group.by = "material_type", method = "anova")

#T-tests
t_tests <- compare_means(RMSE ~ taxon, data = rf_dat,
              group.by = "material_type",
              method = "t.test", p.adjust.method = "hochberg")

gg.rf_taxon_res <- rf_dat  %>%
  #left_join(t_tests %>% dplyr::select(train, error_type, type, model = group2, p.adj, p.signif))  %>%
  ggplot(aes(x = taxon, y = RMSE, fill=taxon)) + 
  geom_point(position=position_jitter(width = 0.2, height=0), colour="#d2d2d2", alpha=0.8)+
  geom_boxplot(width =0.7, alpha=0.6, outlier.colour = NA)+
  facet_grid(~material_type, drop=TRUE,scales="free", space="free" )+
  scale_fill_brewer(palette="Paired")+
  scale_y_continuous(labels = scales::percent_format(accuracy=1)) +
  base_theme +
  theme(axis.text.x = element_text(face = "italic"))
  
gg.rf_taxon_res  
```


## Relative abundances

```{r evaluate models}
# Get RMSE
model_rmse <- fits %>%
  group_by(model, error_type,  train) %>%
  rmse(truth = calibrated, estimate = expected.prop) %>%
  dplyr::select(RMSE = .estimate, model, error_type, train)

model_anorm <- fits %>%
  group_by(model, error_type, train) %>%
    summarise(Adist = anorm(calibrated / expected.prop)) 

# Visualise fits to data
gg.train_preds <- fits %>%
  left_join(model_rmse) %>%
  left_join(model_anorm) %>%
  distinct() %>%
  filter(train == "Training set") %>%
  filter(!(model == "metacal" & !error_type %in% c("ALR", "CLR"))) %>%
  mutate(error_type = error_type %>%
      factor(levels = c(
        "Proportions",
        "Log",
        "Logit",
        "ALR",
        "CLR",
        "Absolute"
      )),
    model = model %>% 
      str_replace("Regression", "Reg") %>%
      factor(levels = c(
        "Uncorrected",
        "metacal", 
        "Linear Reg",
        "LASSO Reg",
        "SVM",
        "Random Forest",
        "XGBOOST"
      ))) %>%
  ggplot(aes(calibrated, expected.prop)) +
  stat_density_2d_filled(geom = "polygon", aes(fill=..level..))+
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  geom_text(aes(x=0, y=.7, label=paste0("RMSE: ",round(RMSE, 2))),
            check_overlap = TRUE, inherit.aes = FALSE, hjust = 0, colour="yellow")+
  facet_grid(error_type~model) +
  base_theme+
  scale_x_continuous(trans = scales::pseudo_log_trans(1e-2), labels=scales::percent,
                       breaks=c(0.025, 0.1, 0.25, 0.5, 1), limits=c(0,1), expand = c(0,0))+
  scale_y_continuous(trans = scales::pseudo_log_trans(1e-2),
                     labels=scales::percent, breaks=c(0.025, 0.05, 0.1, 0.25, 0.5, 1), limits=c(0,1), expand = c(0,0))+
  scale_fill_viridis_d()+
  coord_fixed()+
  theme(panel.grid = element_line(size = rel(1)),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none",
        legend.text = element_text(face="italic")) +
    labs(x = "Calibrated relative abundance", 
        y = "Expected relative abundance",
        fill = "Sample type", 
        colour= NULL,
        title= "Training set")

#gg.train_preds

# Visualise fits to data
gg.test_preds <- fits %>%
  left_join(model_rmse) %>%
  left_join(model_anorm) %>%
  filter(train == "Test set") %>%
  filter(!(model == "metacal" & !error_type %in% c("ALR", "CLR"))) %>%
  filter(!error_type == "error_abs_log") %>%
  mutate(error_type = error_type %>%
      factor(levels = c(
        "Proportions",
        "Log",
        "Logit",
        "ALR",
        "CLR",
        "Absolute"
      )),
    model = model %>% 
      str_replace("Regression", "Reg") %>%
      factor(levels = c(
        "Uncorrected",
        "metacal", 
        "Linear Reg",
        "LASSO Reg",
        "SVM",
        "Random Forest",
        "XGBOOST"
      ))) %>%
  ggplot(aes(calibrated, expected.prop)) +
  stat_density_2d_filled(geom = "polygon", aes(fill=..level..))+
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  geom_text(aes(x=0, y=.7, label=paste0("RMSE: ",round(RMSE, 2))),
            check_overlap = TRUE, inherit.aes = FALSE, hjust = 0, colour="yellow")+
  facet_grid(error_type~model) +
  base_theme+
  scale_x_continuous(trans = scales::pseudo_log_trans(1e-2), labels=scales::percent,
                       breaks=c(0.025, 0.1, 0.25, 0.5, 1), limits=c(0,1), expand = c(0,0))+
  scale_y_continuous(trans = scales::pseudo_log_trans(1e-2),
                     labels=scales::percent, breaks=c(0.025, 0.05, 0.1, 0.25, 0.5, 1), limits=c(0,1), expand = c(0,0))+
  scale_fill_viridis_d()+
  coord_fixed()+
  theme(panel.grid = element_line(size = rel(1)),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none",
        legend.text = element_text(face="italic")) +
    labs(x = "Calibrated relative abundance", 
        y = "Expected relative abundance",
        fill = "Sample type", 
        colour= NULL,
        title= "Test set")

#gg.test_preds

#Save figure
pdf(file="fig/supplementary/RA_bias_fits.pdf", width = 8, height = 11 , paper="a4")
  plot(gg.train_preds)
  plot(gg.test_preds)
try(dev.off(), silent=TRUE)
```

## Absolute abundances

```{r absolute abundance predictions}
# Get RMSE
model_rmse <- abs_fits %>%
  group_by(model, error_type,  train) %>%
  rmse(truth = expected, estimate = calibrated_abs) %>%
  dplyr::select(RMSE = .estimate, model, error_type, train)

model_anorm <- abs_fits %>%
  group_by(model, error_type, train) %>%
    summarise(Adist = anorm(expected / calibrated_abs)) 

# Visualise fits to data
gg.train_abs <- abs_fits %>%
  left_join(model_rmse) %>%
  left_join(model_anorm) %>%
  distinct()%>%
  filter(train == "Training set") %>%
  filter(!(model == "metacal" & !error_type %in% c("ALR", "CLR"))) %>%
  filter(!error_type == "error_abs_log") %>%
mutate(error_type = error_type %>%
      factor(levels = c(
        "Proportions",
        "Log",
        "Logit",
        "ALR",
        "CLR",
        "Absolute"
      )),
    model = model %>% 
      str_replace("Regression", "Reg") %>%
      factor(levels = c(
        "Uncorrected",
        "metacal", 
        "Linear Reg",
        "LASSO Reg",
        "SVM",
        "Random Forest",
        "XGBOOST"
      ))) %>%
  ggplot(aes(calibrated_abs, expected)) +
  stat_density_2d_filled(geom = "polygon", aes(fill=..level..))+
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  geom_text(aes(x=0, y=200, label=paste0("RMSE: ",round(RMSE, 2))),
            check_overlap = TRUE, inherit.aes = FALSE, hjust = 0, colour="yellow")+
  scale_x_continuous(trans= scales::pseudo_log_trans(1.5), breaks=c(5, 25, 100, 300), 
                     limits=c(0,300), expand = c(0,0))+
  scale_y_continuous(trans= scales::pseudo_log_trans(1.5), breaks=c(5, 25, 100, 300),
                     limits=c(0,300), expand = c(0,0))+
  facet_grid(error_type~model) +
    base_theme+
  scale_fill_viridis_d()+
  coord_fixed()+
  theme(panel.grid = element_line(size = rel(1)),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
    labs(x = "Calibrated absolute abundance (individuals)", 
        y = "Expected absolute abundance (individuals)",
        fill = "Sample type", 
        colour= NULL,
        title= "Training set")

#gg.train_abs

# Test set absolute
gg.test_abs <- abs_fits %>%
  left_join(model_rmse) %>%
  left_join(model_anorm) %>%
  distinct()%>%
  filter(train == "Test set") %>%
  filter(!(model == "metacal" & !error_type %in% c("ALR", "CLR"))) %>%
  filter(!error_type == "error_abs_log") %>%
  mutate(error_type = error_type %>%
      factor(levels = c(
        "Proportions",
        "Log",
        "Logit",
        "ALR",
        "CLR",
        "Absolute"
      )),
    model = model %>% 
      str_replace("Regression", "Reg") %>%
      factor(levels = c(
        "Uncorrected",
        "metacal", 
        "Linear Reg",
        "LASSO Reg",
        "SVM",
        "Random Forest",
        "XGBOOST"
      ))) %>%
  ggplot(aes(calibrated_abs, expected)) +
  stat_density_2d_filled(geom = "polygon", aes(fill=..level..))+
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  geom_text(aes(x=0, y=200, label=paste0("RMSE: ",round(RMSE, 2))),
            check_overlap = TRUE, inherit.aes = FALSE, hjust = 0, colour="yellow")+
  scale_x_continuous(trans= scales::pseudo_log_trans(1.5), breaks=c(5, 25, 100, 300), 
                     limits=c(0,300), expand = c(0,0))+
  scale_y_continuous(trans= scales::pseudo_log_trans(1.5), breaks=c(5, 25, 100, 300),
                     limits=c(0,300), expand = c(0,0))+
  facet_grid(error_type~model) +
    base_theme+
  scale_fill_viridis_d()+
  coord_fixed()+
  theme(panel.grid = element_line(size = rel(1)),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
    labs(x = "Calibrated absolute abundance (individuals)", 
        y = "Expected absolute abundance (individuals)",
        fill = "Sample type", 
        colour= NULL,
        title= "Test set")

#gg.test_abs

#Save figure
pdf(file="fig/supplementary/abs_bias_fits.pdf", width = 8, height = 11 , paper="a4")
  plot(gg.train_abs)
  plot(gg.test_abs)
try(dev.off(), silent=TRUE)
```

# Fit final model

Fit the final random forest model to the dataset

```{r Final model}
# Could do bar plots, faceted by whether they are in the training set or not
# Maybe next to it a pre-post correction dot plot
joint <- readRDS("output/joint.rds")

set.seed(666)
joint_split <- joint %>%
 ungroup() %>%
 dplyr::select(sample_name, material_type) %>%
 distinct() %>%
 initial_split(strata = material_type)

# Training set
joint_train <- joint %>%
 dplyr::select(-error) %>%
 filter(sample_name %in% training(joint_split)$sample_name) %>%
 ungroup()%>%
 pivot_longer(starts_with("error"),
              names_to="error_type",
              values_to="error")  %>%
  filter(error_type == "error_prop") %>%
  mutate(observed.prop = log(observed_abs),
         expected.prop = log(expected))

# Testing set
joint_test <- joint %>%
 dplyr::select(-error) %>%
 filter(sample_name %in% testing(joint_split)$sample_name)%>%
 ungroup()%>%
 pivot_longer(starts_with("error"),
              names_to="error_type",
              values_to="error")  %>%
  filter(error_type == "error_prop") %>%
  mutate(observed.prop = log(observed_abs),
         expected.prop = log(expected))


train_cv <- joint_train %>%
      group_vfold_cv(v = 10, group = sample_id)

prop_recipe <- recipe(formula =  expected.prop ~ 0 + observed.prop + taxon + fcid + material_type, data = joint_train) %>% 
  #step_string2factor(one_of(fcid, material_type)) %>% 
  step_string2factor(taxon) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes(), one_hot=TRUE) %>% 
  step_zv(all_predictors())  %>%
  step_naomit(all_predictors())


ranger_spec <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_mode("regression") %>% 
  set_engine("ranger", importance = "impurity") 

#Proporiton workflow
ranger_workflow_prop <- 
  workflow() %>% 
  add_recipe(prop_recipe) %>% 
  add_model(ranger_spec) 

ranger_tune <- tune_grid(ranger_workflow_prop, resamples = train_cv, grid = 20)

autoplot(ranger_tune , metric = "rmse") 

ranger_workflow_prop <- finalize_workflow(ranger_workflow_prop, ranger_tune %>%
  select_best("rmse"))

final_fit <- joint_train %>%
  filter(error_type == "error_prop") %>%
  filter(expected > 0) %>%
  group_by(error_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(error_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  left_join(group_keys(.) %>%
            tidyr::unite("group_names", everything(), sep="-", remove=FALSE)) %>%
  mutate(
    model_obj = purrr::map(train, ~safe_fit(ranger_workflow_prop, data=.x)),
    pred_train = purrr::map2(model_obj, train, ~safe_predict(.x, .y)),
    pred_test = purrr::map2(model_obj, test, ~safe_predict(.x, .y)),
    vip = purrr::map2(model_obj, group_names,~{
      if(!is(.x, "data.frame")){
        .x %>%
        pull_workflow_fit() %>%
        vip::vip()+
        labs(title=.y %>% str_remove("error_"))
      } else{
        return(NULL)
      }
      
    })
  )

# Plot model variable importance
wrap_plots(final_fit$vip)

#results
final_results_train <- final_fit %>%
  unnest(pred_train, train) %>% 
  dplyr::select(!where(is.list))%>%
  mutate(
  estimated  = exp(.pred),
  observed.prop = exp(observed.prop),
  expected.prop = exp(expected.prop),
  predicted = estimated,
  calibrated = estimated,
  residual = observed.prop / predicted
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted, calibrated, observed.prop, expected.prop), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

final_results_train %>%
  group_by(material_type, fcid) %>%
  rmse(truth = observed.prop, estimate = predicted)

# Results test set
final_results_test <- final_fit %>%
  unnest(pred_test, test) %>% 
  dplyr::select(!where(is.list))%>%
  mutate(
  estimated  = exp(.pred),
  observed.prop = exp(observed.prop),
  expected.prop = exp(expected.prop),
  predicted = estimated,
  calibrated = estimated,
  residual = observed.prop / predicted
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted, calibrated, observed.prop, expected.prop), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

final_results_test %>%
  group_by(material_type, fcid) %>%
  rmse(truth = observed.prop, estimate = predicted)

```


# Final model calibration

Calibrate all measurements using the final Random Forest model

```{r final bars}
final_results_all <- final_results_train %>%
  mutate(train = "Training set") %>%
  bind_rows(final_results_test %>%
    mutate(train = "Test set"))

# Add RMSE to the left 
final_results_rmse <- final_results_all %>%
    mutate(calibrated = calibrated * sample_size) %>%
    mutate(taxon = taxon %>% str_replace("_", " ")) %>%
    dplyr::mutate(Actual = expected) %>%
    dplyr::rename(Observed = observed_abs,
                  Calibrated = calibrated) %>%
      pivot_longer(c("Actual", "Observed", "Calibrated"),
                 names_to = "type",
                 values_to = "abundance") %>%
  group_by(train, type) %>%
  rmse(truth = expected, estimate = abundance) %>%
  dplyr::select(train, type, RMSE = .estimate)

# Calibrated abs
gg.calbars_abs <- final_results_all  %>%
    mutate(calibrated = calibrated * sample_size) %>%
    mutate(taxon = taxon %>% str_replace("_", " ")) %>%
    dplyr::rename(Actual = expected,
                  Observed = observed_abs,
                  Calibrated = calibrated) %>%
    pivot_longer(c("Actual", "Observed", "Calibrated"),
                 names_to = "type",
                 values_to = "abundance") %>%
    left_join(final_results_rmse) %>%
    mutate(type = factor(type, c("Actual","Observed", "Calibrated")),
           train = factor(train, levels=c("Training set", "Test set"))) %>%
  ggplot(aes(sample_id, abundance, fill = taxon)) +
    geom_col() +
    geom_text(aes(x = 1, y = 450, label = paste0("RMSE:", round(RMSE, 2))), check_overlap = TRUE, hjust=0) + 
    facet_grid(type~train, drop=TRUE, scales = "free", space="free") +
    base_theme +
    theme(legend.position = "right",
          legend.text = element_text(face="italic"),
          panel.grid = element_blank())+
    scale_fill_brewer(palette = "Paired") +
  labs(x = NULL,
       y = "Total individuals",
       fill = "Taxon")

gg.calbars_abs

#Save figure
pdf(file="fig/Fig4_calibrated_bars.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.calbars_abs)
try(dev.off(), silent=TRUE)
  
# Supplementary - just calibrated relative abundances
gg.calbars_ra <- final_results_all  %>%
    dplyr::rename(Actual = expected.prop,
                  Observed = observed.prop,
                  Calibrated = calibrated) %>%
    pivot_longer(c("Actual", "Observed", "Calibrated"),
                 names_to = "type",
                 values_to = "abundance") %>%
    mutate(type = factor(type, c("Actual","Observed", "Calibrated")),
           train = factor(train, levels=c("Training set", "Test set"))) %>%
  ggplot(aes(sample_id, abundance, fill = taxon)) +
    geom_col() +
    facet_grid(type~train, drop=TRUE, scales = "free", space="free") +
    base_theme +
    theme(legend.position = "right",
          legend.text = element_text(face="italic"),
          panel.grid = element_blank())+
    scale_fill_brewer(palette = "Paired") +
  scale_y_continuous(labels = scales::percent)+
  labs(x = NULL,
       y = "Total individuals",
       fill = "Taxon")

gg.calbars_ra

pdf(file="fig/supplementary/calibrated_relative_bars.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.calbars_ra)
try(dev.off(), silent=TRUE)
```

## PCA

See the effect of calibration on the clustering of samples

```{r pca}
# Calibrated abs
pca_dat <- final_results_all  %>%
    mutate(calibrated = calibrated * sample_size) %>%
    mutate(taxon = taxon %>% str_replace("_", " ")) %>%
    dplyr::rename(Actual = expected,
                  Observed = observed_abs,
                  Calibrated = calibrated,
                  Actual_prop = expected.prop,
                  Observed_prop = observed.prop) %>%
    mutate(Calibrated_prop = Calibrated) %>%
    group_by(sample_id, train) %>% 
    mutate_at(vars(Calibrated_prop), ~ . / sum(., na.rm=TRUE) ) %>%
    ungroup() %>%
    pivot_longer(c("Actual", "Observed", "Calibrated", "Actual_prop", "Observed_prop", "Calibrated_prop"),
                 names_to = "type",
                 values_to = "abundance") %>%
    mutate(sample_id = paste0(train, "-", type,"-", sample_id)) %>%
    dplyr::select(sample_id, taxon, abundance) %>%
    pivot_wider(names_from = taxon,
               values_from = abundance,
               values_fill = 0) %>%
    column_to_rownames("sample_id")%>%
    dplyr::select(where(~ !(sum(.)==0))) %>%
    as.matrix() %>%
    zCompositions::cmultRepl(method="BL", output="p-counts") %>%
    as.matrix() %>%
    clr() %>%
    vegdist(method="euclidean") %>%
    as.matrix() %>%
    prcomp() 
    
# Var explained
var_exp <- pca_dat %>%
  tidy(matrix="eigenvalues") %>%
  mutate(names = paste0("PC", PC, " (", round(percent,2), "%)"))

cols <- colorRampPalette(brewer.pal(11, "Paired"))(length(unique(final_results_all$sample_id)))

gg.pca <- pca_dat %>%
    augment() %>%
    rename_all(~str_remove(.x, ".fitted")) %>%
    dplyr::select(sample_id = .rownames, paste0("PC",1:5)) %>%
    tidyr::separate(sample_id, into=c("train", "type", "sample_id"), sep="-") %>%
    mutate(prop = case_when(
      str_detect(type, "_prop") ~ "Relative",
      !str_detect(type, "_prop") ~ "Absolute"
    )) %>%
    mutate(type = type %>% str_remove("_prop")) %>%
    ggplot(aes(PC1, PC2, colour=sample_id, shape=type, group=sample_id)) +  #colour=paste0(location, year)
    geom_point(size = 3, alpha=0.8) +
    geom_line()+
    geom_hline(yintercept=0, lty=2, colour="grey20")+
    geom_vline(xintercept = 0, lty=2, colour="grey20")+
    base_theme+
    facet_grid(prop~train) +
    cowplot::background_grid()  +
    theme(legend.position = "bottom")+
    scale_color_manual(values = cols) +
  scale_shape_manual(values=c(3, 16, 1))+
    labs(x = var_exp %>% filter(PC == 1) %>% pull(names),
         y= var_exp %>% filter(PC == 2) %>% pull(names),
         shape = NULL) + 
  guides(colour=FALSE) +
  coord_equal()
    
gg.pca

#Save figure
pdf(file="fig/Fig5_PCA.pdf", width = 8, height = 6 , paper="a4r")
  plot(gg.pca)
try(dev.off(), silent=TRUE)
  
```


# Jacknife RMSE estimates

See how bias estimates change with reduced number of training samples

```{r jacknife}
ranger_workflow_prop2 <- 
  workflow() %>% 
  add_recipe(prop_recipe) %>% 
  add_model(ranger_spec) 

ranger_workflow_prop2 <- finalize_workflow(ranger_workflow_prop2, tibble(
  mtry=5, min_n=2
))

# Bootstrapped Standard errors with number of control samples
samples <- unique(joint_train$sample_id)

boot_df <- joint_train %>%
  filter(error_type == "error_prop") %>%
  filter(expected > 0)

jacknifes <- seq(1,length(samples),1) %>%
  purrr::map_df(function(x){
    boots <- rep(x, 100) #How many resamples at each size? 
    names(boots) <- paste0("boot.",seq(1,length(boots),1))
    out <- purrr::map2_df(boots, names(boots), function(y,z){
        subsamp <- sample(samples, y, replace = TRUE)
        boot_df %>% 
          filter(sample_id %in% subsamp) %>%
          mutate(id = z,
                 size=y)
      })
  }) %>%
  group_by(id,size) %>%
  nest() %>%
  dplyr::rename(train = data) %>%
  bind_cols(joint_test %>%
    filter(error_type == "error_prop") %>%
      nest(everything()))%>%
  dplyr::rename(test = data) 

# using safe predict function to stop it failing when variables arent available
fit_jacknifes <- jacknifes %>%
  filter(size > 3) %>%
  ungroup() %>%
  #dplyr::sample_n(3) %>%
  mutate(
    fits = purrr::map2(train, test, function(x,y){
      # Filter to only taxa shared in both
      test <- x %>% 
        filter(taxon %in% unique(y$taxon), fcid %in% unique(y$fcid))
      train <- y %>% 
        filter(taxon %in% unique(x$taxon), fcid %in% unique(x$fcid))
      # Train on training set
      model_obj <- fit(ranger_workflow_prop2, data=train)
      # return data + predictions
      pred_train <- bind_cols(train, safe_predict(model_obj, train))
      pred_test <- bind_cols(test, safe_predict(model_obj, test))
      tibble(
        model_obj = list(model_obj),
        pred_train = list(pred_train),
        pred_test = list(pred_test))
    }))  %>%
  unnest(fits) %>%
  group_by(size) %>%
  mutate(n_boots = n())

saveRDS(fit_jacknifes, "output/jacknifes.rds")

## OPTIONAL: Download pre-fit jacknife models
fit_jacknifes <- readRDS(url("https://zenodo.org/record/5370132/files/jacknifes.rds?download=1"), options(timeout = 5*60))

jacknife_results <- fit_jacknifes %>%
  unnest(pred_test)%>%
  dplyr::select(!where(is.list))%>%
  mutate(
  estimated  = exp(.pred),
  observed.prop = expit(observed.prop),
  expected.prop = expit(expected.prop),
  predicted = estimated,
  calibrated = estimated,
  residual = observed.prop / predicted
  ) %>%
  group_by(sample_id, error_type, id, size) %>%
  mutate_at(vars(predicted, calibrated, observed.prop, expected.prop), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

gg.jacknife_box <- jacknife_results %>%
  mutate(taxon = taxon %>% 
           str_replace("_", " ") %>%
           str_replace("Sp$", "sp.") %>%
           str_replace("nr.dimidiatus", "truncatus")) %>%
  group_by(size, id, taxon) %>%
  rmse(truth = observed.prop, estimate = predicted) %>%
  ggplot(aes(x = size, y = .estimate, group=size, fill=taxon)) +
  geom_point(position=position_jitter(width = 0.10, height=0), colour="#d2d2d2", alpha=0.8)+
  geom_boxplot(width =0.8, lwd=0.5, alpha=0.6, outlier.colour = NA)+
  scale_fill_brewer(palette="Paired") +
  scale_y_continuous(labels=scales::percent_format(accuracy = 1)) +
  base_theme +
  theme(strip.text = element_text(face="italic"))+
  facet_wrap(~taxon, ncol=1)+
  labs(x = "Number of training samples",
       y = "RMSE")

gg.jacknife_box

fig4 <- gg.rf_taxon_res - gg.jacknife_box + plot_layout(widths = c(2,1)) + plot_annotation(tag_levels = "A")

fig4

#Save figure
pdf(file="fig/Fig4_residual_summary.pdf", width = 11, height = 8 , paper="a4r")
  plot(fig4)
try(dev.off(), silent=TRUE)

```