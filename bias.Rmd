---
title: "Metabarcoding bias"
output: html_document
editor_options: 
  chunk_output_type: console
---
# Introduction

## Analysis structure

Part 1 - Cleanup & Filtering

Part 1 - Comparison of 4 primers for bias

Part 2 - Evaluation of different bias modellign strategies

- naive mean on proportions approach
- Metacal center function
  - proj
  - gm
  - rss
- lm on compositional vectors
- lm on expected / observed
- lm with CLR in advance?
- glmnet: multinomial regression with regularization (ie Lasso model)
- nnet::multinomial neural network regression
- multinomial regression with random effects
- Poisson regression with random effects
- Bayesian multinomial logistic normal models
  - Stan
  - Pibble from stray package
  
Look at spike in control

Pick the model that reduces the residual mean standard error (RMSE) the most

Should be able to do this within a tidymodels framework with bootsrapping

## Load packages
```{r setup}
#Set required packages
.cran_packages <- c("tidyverse",
                    "tidymodels",
                    "patchwork", 
                    "vegan", 
                    "seqinr",
                    "ape", 
                    "RColorBrewer",
                    "devtools",
                    "data.table")
.bioc_packages <- c("dada2",
                    "phyloseq", 
                    "ALDEx2",
                    "Biostrings")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/taxreturn")
devtools::install_github("mikemc/speedyseq")
devtools::install_github('ggloor/CoDaSeq/CoDaSeq')
devtools::install_github("mikemc/metacal")

library(taxreturn)
library(speedyseq)
library(CoDaSeq)
library(metacal)

# Create directories
if(!dir.exists("data")){dir.create("data", recursive = TRUE)}
if(!dir.exists("reference")){dir.create("reference", recursive = TRUE)}
if(!dir.exists("output/logs")){dir.create("output/logs", recursive = TRUE)}
if(!dir.exists("output/csv")){dir.create("output/csv", recursive = TRUE)}
if(!dir.exists("output/rds")){dir.create("output/rds", recursive = TRUE)}
if(!dir.exists("sample_data")){dir.create("sample_data", recursive = TRUE)}
```

## Define themes

```{R theme}
library(ggthemes)
base_theme <- theme_tufte() + 
    theme(
        text = element_text(size=9, family = ""),
        strip.text = element_text(size=9, family = ""),
        # axis.text = element_text(size=8, family = ""),
        legend.position = "none"
        )

```

## Make Phyloseq object


```{r create PS, eval = FALSE}
## Just subset to the last run
seqtab <- readRDS("output/rds/seqtab_final.rds")

# Add FCID to run 1 samples
rownames(seqtab)[!str_detect(rownames(seqtab), "Rep") ] <- paste0("CB3DR_", rownames(seqtab)[!str_detect(rownames(seqtab), "Rep") ])

# Add FCID to run2 samples
rownames(seqtab)[str_detect(rownames(seqtab), "Rep") & 
                   !str_detect(rownames(seqtab), "HLVKYDMXX") & 
                   !str_detect(rownames(seqtab), "DL|CL")] <- paste0("CK3HD_", rownames(seqtab)[str_detect(rownames(seqtab), "Rep") & 
                   !str_detect(rownames(seqtab), "HLVKYDMXX") & 
                   !str_detect(rownames(seqtab), "DL|CL")])

  
# Add FCID to run 3 samples
rownames(seqtab)[str_detect(rownames(seqtab), "Rep") & 
                   !str_detect(rownames(seqtab), "HLVKYDMXX") & 
                   str_detect(rownames(seqtab), "DL|CL")] <- paste0("CJKFJ_", rownames(seqtab)[str_detect(rownames(seqtab), "Rep") & 
                   !str_detect(rownames(seqtab), "HLVKYDMXX") & 
                   str_detect(rownames(seqtab), "DL|CL")])

#Reformat sample IDs
rownames(seqtab)  <- rownames(seqtab) %>%
  str_remove("\\..*$") %>%
  str_replace("\\_S[0-9].*\\_...", replacement="_") %>%
  str_replace("_$", "_1") %>%
  str_replace("1in10", "1:10")

tax <- readRDS("output/rds/tax_IdTaxaExact.rds") 
seqs <- DNAStringSet(colnames(seqtab))
names(seqs) <- seqs
phy <- readRDS("output/rds/phytree.rds")$tree

##### Rename problematic samples
#Could do this with the new dplyr functionality
rownames(seqtab)  <- rownames(seqtab) %>%
 str_replace_all("D250M1-", "D250M4REP-") %>% # Works
 str_replace_all("D250M4-", "D250M2REP-") %>% # Works
 str_replace_all("D250M5-", "D250M3REP-") %>% #FAILED library
 str_replace_all("D250M3-", "D250M1REP-") %>% #FP suzukii - low reads
 str_replace_all("D250M2-", "D250M5REP-") %>% #Works
 str_replace_all("D500M1-", "D500M4REP-") %>% #Works 
 str_replace_all("D500M4-", "D500M1REP-") %>% #FP Suzukii
 str_replace_all("D500M5-", "D500M2REP-") %>% #Works
 str_replace_all("D500M3-", "D500M3REP-") %>% #Works but low reads for Suz + Biarmipes 
 str_replace_all("D500M2-", "D500M5REP-") %>% #Works
 str_replace_all("D1000M1-", "D1000M3REP-") %>% #Works
 str_replace_all("D1000M4-", "D1000M1REP-") %>% #Works
 str_replace_all("D1000M5-", "D1000M2REP-") %>% #Works
 str_replace_all("D1000M3-", "D1000M5REP-") %>% #Works
 str_replace_all("D1000M2-", "D1000M4REP-") %>% #Works
 str_replace_all("CM10-", "CM9REP-") %>%
 str_replace_all("CM11-", "CM10REP-") %>%
 str_replace_all("CM9-", "CM11REP-") %>%
 str_replace_all("CML2-", "CML6REP-")%>%
 str_replace_all("CML3-", "CML2REP-")%>%
 str_replace_all("CML4-", "CML3REP-")%>%
 str_replace_all("CML5-", "CML4REP-")%>%
 str_replace_all("CML6-", "CML5REP-")%>%
 str_replace_all("CT5-", "CT4REP-")%>%
 str_replace_all("CT4-", "CT5REP-") %>%
str_replace_all("REP", "")

#Load sample information
## ---- samdat ----
samdf <- read.csv("sample_data/sample_info.csv", header=TRUE) %>% 
  janitor::clean_names() %>%
  mutate(sample_id = case_when(
    fcid=="HLVKYDMXX" ~ paste0(sample_name, "_", replicate),
    !fcid=="HLVKYDMXX" ~ paste0(fcid, "_", sample_name, "_", replicate)
  ))  %>%
  filter(!(index=="ATCGATCG" & index2=="ATCACACG"), #CT11-ex1 duplicated
         !(index=="TCGCTGTT" & index2=="ACTCCATC") # CT12-ex1 duplicated
         ) %>%
  filter(!fcid=="CK3HD") %>%
  mutate(type = case_when(
    str_detect(sample_id, "D[0-9][0-9][0-9]M|D[0-9][0-9][0-9][0-9]M|DM[0-9]")  ~ "DrosMock",
    str_detect(sample_id, "SPD")  ~ "SPD",
    str_detect(sample_id, "ACV")  ~ "ACV",
    str_detect(sample_id, "DC")  ~ "DC",
    str_detect(sample_id, "Sach")  ~ "Sachet",
    str_detect(sample_id, "FF")  ~ "FF",
    str_detect(sample_id, "NTC")  ~ "NTC",
    str_detect(sample_id, "DLarv")  ~ "DrosLarv",
    str_detect(sample_id, "POS|SynMock")  ~ "POS",
    str_detect(sample_id, "extblank|BLANK")  ~ "Extblank",
    str_detect(sample_id, "pcrblank")  ~ "PCRblank",
    str_detect(sample_id, "CT")  ~ "CarpTrap",
    str_detect(sample_id, "CM[0-9]")  ~ "CarpMock",
    str_detect(sample_id, "CML[0-9]")  ~ "CarpLarval"
  )) %>%
  mutate(target_subfragment = case_when(
    str_detect(fprimer, "GGDACWGGWTGAACWGTWTAYCCHCC") & str_detect(rprimer, "GTRATWGCHCCDGCTARWACWGG") ~ "fwhF2-fwhR2n",
    str_detect(fprimer, "ACWGGWTGRACWGTNTAYCC") & str_detect(rprimer, "ARYATDGTRATDGCHCCDGC") ~ "BF1-BR1",
    str_detect(fprimer, "GGDRCWGGWTGAACWGTWTAYCCNCC") & str_detect(rprimer, "TATDGTRATDGCHCCNGC") ~ "SauronS878-HexCOIR4",
    str_detect(fprimer, "GGDACWGGWTGAACWGTWTAYCCHCC") & str_detect(rprimer, "TATDGTRATDGCHCCNGC") ~ "fwhF2-HexCOIR4",
  )) %>%
  magrittr::set_rownames(.$sample_id)

# Will probably need to rename the seqtabs and append the flowcell number onto the samples before they are merged

## ---- phyloseq ----
ps <- phyloseq(tax_table(tax), 
               sample_data(samdf),
               otu_table(seqtab, taxa_are_rows = FALSE),
               phy_tree(phy),
               refseq(seqs))

if(nrow(seqtab) > nrow(sample_data(ps))){warning("Warning: All samples not included in phyloseq object, check sample names match the sample metadata")}

rownames(samdf)[which(!rownames(sample_data(ps))  %in% rownames(samdf))]
rownames(sample_data(ps))[which(!rownames(samdf)  %in% rownames(sample_data(ps)))]

# Rename all taxa
taxa_names(ps) <- paste0("SV", seq(ntaxa(ps)),"-",tax_table(ps)[,7])

saveRDS(ps, "output/rds/ps_idtaxaExact.rds") 

#Rename synthetic orders
tax_table(ps)[,2][which(str_detect(tax_table(ps)[,7], "Synthetic"))] <- "Arthropoda"

#Subset to carpophilus
ps <- ps %>%
  subset_samples(str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]")
  ) %>%
  subset_taxa(Phylum == "Arthropoda") %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) 
dir.create("output/csv")
dir.create("output/csv/unfiltered/")

##Export raw csv
export <- speedyseq::psmelt(ps) %>%
  filter(Abundance > 0)
write.csv(export, file = "output/csv/rawdata.csv")

#Summary export
seqateurs::summarise_taxa(ps, "Species", "sample_name") %>%
  filter(str_detect(sample_name, "NTC")) %>%
  #filter(str_detect(Species, "Drosophila|Scaptodrosophila")) %>%
  spread(key="sample_name", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/spp_sum.csv")

seqateurs::summarise_taxa(ps, "Genus", "sample_name") %>%
  spread(key="sample_name", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/gen_sum.csv")

##Output fasta of all ASV's - Name each one by abundance + taxonomic assignment
seqateurs::ps_to_fasta(ps, "output/all_taxa.fasta")
```


### Summary statistics

```{r sum taxa}
# N unique species and samples
speedyseq::psmelt(ps) %>%
  summarise(n_extracts = n_distinct(sample_name), n_samples = n_distinct(sample_name))

# Spread of reads
speedyseq::psmelt(ps) %>%
  group_by(sample_name) %>%
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  summarise(mean = mean(Abundance), 
            se = sd(Abundance)/sqrt(length(Abundance)),
            max = max(Abundance),
            min = min(Abundance))

# Spread of ASVs
speedyseq::psmelt(ps) %>%
  group_by(sample_name) %>%
  dplyr::filter(Abundance > 0) %>%
  summarise(counts = n_distinct(OTU)) %>%
  ungroup() %>%
  summarise(mean = mean(counts), 
            se = sd(counts)/sqrt(length(counts)),
            max = max(counts),
            min = min(counts))

#Fraction of reads assigned to each taxonomic rank
speedyseq::psmelt(ps) %>%
  gather("Rank","Name", rank_names(ps)) %>%
  group_by(Rank) %>% 
  mutate(Name = replace(Name, str_detect(Name, "__"), NA)) %>% # This line turns the "__" we added to lower ranks back to NA's
  dplyr::summarise(Reads_classified = sum(Abundance * !is.na(Name))) %>%
  mutate(Frac_reads = Reads_classified / sum(sample_sums(ps))) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)

#Fraction of ASV's assigned to each taxonomic rank
tax_table(ps) %>%
  as("matrix") %>%
  as_tibble(rownames="OTU") %>%
  gather("Rank","Name",rank_names(ps)) %>%
  group_by(Rank) %>%
  mutate(Name = replace(Name, str_detect(Name, "__"), NA)) %>% # This line turns the "__" we added to lower ranks back to NA's
  dplyr::summarise(OTUs_classified = sum(!is.na(Name))) %>%
  mutate(Frac_OTUs = OTUs_classified / ntaxa(ps)) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)

# Unique taxa at each rank
speedyseq::psmelt(ps) %>%
  dplyr::select(rank_names(ps)) %>%
  pivot_longer(everything(),
               names_to = "Rank",
               values_to = "value") %>%
  mutate(value = case_when(
    str_detect(value, "__") ~ as.character(NA),
    !str_detect(value, "__") ~ value
  )) %>%
  drop_na() %>%
  group_by(Rank) %>%
  summarise_all(list(n_distinct)) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)
```

## Taxon filtering

```{R taxon filt}
get_taxa_unique(ps, "Order")

ps # Check the number of taxa prior to removal
ps0 <- ps %>%
  subset_taxa(
    Phylum == "Arthropoda" & 
    Class %in% c("Insecta", "Arachnida", "Collembola")
  )
ps # Confirm that the taxa were removed
get_taxa_unique(ps0, "Phylum")
get_taxa_unique(ps0, "Class")
get_taxa_unique(ps0, "Order")
```


## Merge replicates 

```{r merge replicates}
# Merge replicates
ps.merged <- ps0 %>%
    merge_samples(group = "sample_name", fun="sum")

#This loses the sample metadata - Need to add it agian
sample_data(ps.merged) <- sample_data(ps0) %>%
  as("data.frame") %>%
  dplyr::filter(!duplicated(sample_name)) %>%
  magrittr::set_rownames(.$sample_name)

ps1 <- ps.merged
```


# Get expected and observed across all runs

Subset to just fwhF2-fwhR2n

```{r primer comparison}
ps_bias <- ps1 %>%
  subset_samples(type %in% c("CarpMock",  "CarpTrap", "CarpLarval")) %>%
  subset_samples(fcid %in% c("HLVKYDMXX", "CB3DR")) %>%
  subset_samples(target_subfragment == "fwhF2-fwhR2n") %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) 

tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Carpophilus_dimidiatus/nr.dimidiatus")] <- "Carpophilus_nr.dimidiatus"
tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Brachypeplus_Sp1")] <- "Brachypeplus_Sp"
tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Brachypeplus_Sp2")] <- "Brachypeplus_Sp"
ps_bias <- speedyseq::tax_glom(ps_bias, taxrank="Species")

exp <- read_csv("sample_data/expected_quant_carpophilus.csv") %>%
  dplyr::rename(sample_name = X1) %>%
  pivot_longer(-sample_name,
               names_to= "taxon",
               values_to= "expected") %>%
  mutate(taxon = str_replace(taxon, pattern=" ",replacement="_"),
         sample_name = str_remove(sample_name, "-exp*.$")) %>%
  dplyr::filter(!is.na(sample_name),
  str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]"),
  expected > 0) %>%
  distinct()

#plot expected
exp %>% 
  group_by(sample_name) %>%
  mutate_at(vars(expected), ~ . / sum(.) ) %>% #Convert to proportions
  ggplot(aes(x=sample_name, y=expected, fill=taxon)) +
  geom_col(position="stack") + 
  scale_fill_brewer(palette="Spectral") +
  theme(legend.position = "bottom") +
  labs(x = "Sample Name", y= "Expected relative abundance")

#Get obsered
sam <- speedyseq::psmelt(ps_bias) %>%
  janitor::clean_names() %>%
  mutate(taxon = species) %>%
  filter(!str_detect(genus, "__")) %>%#Remove unclassified
  dplyr::select(sample_name, taxon, abundance, target_subfragment, fcid, material_type = type) %>%
  mutate(sample_name = sample_name %>%
           str_remove_all("BF1-BR1-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-|fwhF2-fwhR2n-") %>%
           str_remove("HLVKYDMXX_"),
         sample_id = paste0(fcid, "_", sample_name),
         sample_name = sample_name %>%
           str_remove("-ex[0-9]")) 

#Join tables 
joint <- sam %>%
  filter(taxon %in% exp$taxon,
         sample_name %in% exp$sample_name) %>%
  left_join(exp, by = c("sample_name","taxon")) %>%
  dplyr::rename(observed = abundance) %>%
  mutate(expected = replace_na(expected, 0),
         observed0 = (observed + 0.5) * (expected > 0),
         error = observed0 / expected) %>%
  distinct() %>%
  group_by(sample_id) %>%
  mutate(observed.prop=observed, expected.prop=expected) %>%
  mutate_at(vars(observed.prop,  expected.prop), ~ . / sum(.) ) %>% #Convert to proportions
  ungroup()
```

#Visualise errors

```{r visualise errors}
## Visualise errors in proportions
joint %>% 
  filter(expected > 0) %>%
  mutate_at(vars(expected.prop, observed.prop), logit) %>%
  ggplot(aes(expected.prop, observed.prop, color = taxon)) + 
  geom_abline(intercept = 0, slope=1) +
  geom_jitter(alpha=0.7) +
  scale_color_brewer(palette="Spectral")+
  facet_grid(material_type~fcid)+
  theme_bw()+
  labs(title = "Observed vs. expected proportions (log-odds)",
       color = "Taxon",
       x="Expected",
       y="Observed") 

# Visualise the error in all pairwise ratios
joint %>%
  filter(expected > 0) %>%
  dplyr::mutate(Taxon = taxon %>%
                  str_replace("^.+_", paste0(str_extract(taxon, "."), "_"))) %>% #Shorten genus names
    compute_ratios(group_vars = c("sample_id", "fcid", "material_type")) %>%
    filter(!is.na(expected)) %>%
    mutate(pair = paste(Taxon.x, Taxon.y, sep = ":")) %>% 
  ggplot(aes(pair, error, colour=sample_id)) +
  geom_jitter(alpha=0.7) +
  geom_hline(yintercept = 1) +
  scale_y_log10() +
  facet_grid(material_type~fcid)+
  theme_bw()+
    theme(legend.position = "none",
          axis.text.x = element_text(angle=45, hjust=1)) +
  labs(x = "Taxon ratios",
       y = "Error in taxon ratios")

```

# Estimate bias

## Split data into training and testing


```{r splits}
set.seed(666)

#Sample splits
joint_split <- joint %>%
  group_by(sample_id) %>%
  summarise(ntaxa=n()) %>%
  initial_split(strata=ntaxa)


joint_train <- joint %>%
  filter(sample_id %in% training(joint_split)$sample_id)
joint_test <- joint %>%
  filter(sample_id %in% testing(joint_split)$sample_id)

table(joint_train$sample_id %in% joint_test$sample_id)
table(joint_test$sample_id %in% joint_train$sample_id)
```


## Mean proportions

Here we estimate bias as the arithmetic mean of the error in proportions

NOTE: i wonder how this would look if i took the geometric rather than arithmetic mean?

```{r mean proportions}
# Compare these fits!  
fit_prop <- joint_train %>%
  filter(expected > 0) %>%
  mutate(error = observed.prop / expected.prop) %>%
  group_by(material_type, taxon) %>%
  summarise(.pred = mean(error))

#results
prop_results_train <- joint_train %>%
  left_join(fit_prop) %>%
 # dplyr::select(material_type, sample_id, fcid, expected, observed.prop, .pred) %>%
  mutate(
    predicted = expected * .pred, 
    observed = observed.prop,
    estimated = .pred
  )%>%
  group_by(sample_id) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  dplyr::filter(expected > 0)

prop_results_train %>%
  group_by(material_type) %>%
  rmse(truth = observed, estimate = predicted)

prop_results_test <- joint_test %>%
  left_join(fit_prop) %>%
  #dplyr::select(material_type, sample_id, fcid, expected, observed.prop, .pred) %>%
  mutate(
    predicted = expected * .pred, 
    observed = observed.prop
  )%>%
  dplyr::rename(estimated=.pred) %>%
  group_by(sample_id) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  dplyr::filter(expected > 0)

prop_results_test %>%
  group_by(material_type) %>%
  rmse(truth = observed, estimate = predicted)

```


## Fitting models to proportions

Here we estimate bias using a simple linear regression model, as well as a random forest regression of the expected and observerd proportions. 

The model is fit seperately to each taxon and material type.

The model is then evaluated seperately on the testing and training datasets

```{r simple lm}
# LM
lm_spec <- linear_reg() %>%
  set_engine(engine = "lm")%>%
        step_center(all_numeric()) %>%
        step_scale(all_numeric()) %>%
        step_dummy(all_nominal())

lm_spec

fit_lm <- joint_train %>%
  filter(expected > 0) %>%
  group_by(taxon, material_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(taxon, material_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  mutate(lm_obj = map(train, ~fit(lm_spec, observed.prop ~ 0 + expected.prop, data = .)),
           pred_train = map2(lm_obj, train, function(.model, .data) predict(.model, .data)),
           pred_test = map2(lm_obj, test, function(.model, .data) predict(.model, .data)),
           coef_info = map(lm_obj, tidy)
    ) %>%
  unnest(coef_info)

# RF
rf_spec <- rand_forest(mode = "regression") %>%
  set_engine("ranger") %>%
        step_center(all_numeric()) %>%
        step_scale(all_numeric()) %>%
        step_dummy(all_nominal())
rf_spec

fit_rf <- joint_train %>%
  filter(expected > 0) %>%
  group_by(taxon, material_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(taxon, material_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  mutate(rf_obj = map(train, ~fit(rf_spec, observed.prop ~ 0 + expected.prop, data = .)),
           pred_train = map2(rf_obj, train, function(.model, .data) predict(.model, .data)),
           pred_test = map2(rf_obj, test, function(.model, .data) predict(.model, .data))
    ) 

#results train set
lm_results_train <- fit_lm %>%
  unnest(pred_train, train) %>%
  mutate(
    observed = observed.prop,
    model = "lm"
  ) %>%
  bind_rows(fit_rf %>%
    unnest(pred_train, train) %>%
    mutate(
      observed = observed.prop,
      model = "rf"
    ))%>%
  mutate(predicted = .pred)%>% 
    dplyr::select(!where(is.list))

lm_results_train %>%
  group_by(model, material_type) %>%
  rmse(truth = observed, estimate = predicted)

# Results test set
lm_results_test <- fit_lm %>%
  unnest(pred_test, test) %>%
  mutate(
    observed = observed.prop,
    model = "lm"
  ) %>%
  bind_rows(fit_rf %>%
    unnest(pred_test, test) %>%
    mutate(
      observed = observed.prop,
      model = "rf"
    )) %>%
  mutate(predicted = .pred)%>% 
    dplyr::select(!where(is.list))

lm_results_test %>%
  group_by(model, material_type) %>%
  rmse(truth = observed, estimate = predicted)

# Visualise
lm_results_test %>%
  mutate(train = "testing") %>%
  bind_rows(lm_results_train %>%
    mutate(train = "training")) %>%
  ggplot(aes(logit(predicted), logit(observed), colour = model)) +
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  base_theme+
  geom_rangeframe(colour="black")+
  geom_point(alpha = 0.5) +
  facet_wrap(~train) +
  theme(legend.position = "bottom")+
  labs(
    x = "logit(Predicted)",
    y = "logit(Observed)",
    colour = "Type of model"
  )

```

## Fitting models to compositional vectors

Here we fit a simple linear model and random forest regression on the compositional difference between Observed and Expected counts. The compositional error vectors are first geometrically centered, then taxon is used as a predictor.

```{R compositional regressions}
fit_complm <- joint_train %>%
  filter(expected > 0) %>%
  group_by(material_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(material_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  mutate(lm_obj = map(train, ~fit(lm_spec, center_elts(observed0 / expected) ~ 0 + taxon, data = .)),
           pred_train = map2(lm_obj, train, function(.model, .data) predict(.model, .data)),
           pred_test = map2(lm_obj, test, function(.model, .data) predict(.model, .data)),
           coef_info = map(lm_obj, tidy)
    )

# RF
fit_comprf <- joint_train %>%
  filter(expected > 0) %>%
  group_by(material_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(material_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  mutate(rf_obj = map(train, ~fit(rf_spec, center_elts(observed0 / expected) ~ 0 + taxon, data = .)),
           pred_train = map2(rf_obj, train, function(.model, .data) predict(.model, .data)),
           pred_test = map2(rf_obj, test, function(.model, .data) predict(.model, .data))
    ) 

#results
comp_results_train <- fit_complm %>%
  unnest(pred_train, train) %>%
  mutate(
    predicted = expected * .pred, 
    observed = observed.prop,
    estimated = .pred,
    model = "lm"
  ) %>%
  bind_rows(fit_comprf %>%
    unnest(pred_train, train) %>%
    mutate(
      predicted = expected * .pred, 
      observed = observed.prop,
      estimated = .pred,
      model = "rf"
    )) %>%
  group_by(sample_id, model) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  dplyr::filter(expected > 0)%>% 
    dplyr::select(!where(is.list))

comp_results_train %>%
  group_by(model, material_type) %>%
  rmse(truth = observed, estimate = predicted)

# Results test set
comp_results_test <- fit_complm %>%
  unnest(pred_test, test) %>%
  mutate(
    predicted = expected * .pred, 
    observed = observed.prop,
    model = "lm"
  ) %>%
  bind_rows(fit_comprf %>%
    unnest(pred_test, test) %>%
    mutate(
      predicted = expected * .pred, 
      observed = observed.prop,
      model = "rf"
    )) %>%
  group_by(sample_id, model) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  dplyr::filter(expected > 0)%>% 
    dplyr::select(!where(is.list))

comp_results_test %>%
  group_by(model, material_type) %>%
  rmse(truth = observed, estimate = predicted)

# Visualise
comp_results_test %>%
  mutate(train = "testing") %>%
  bind_rows(comp_results_train %>%
    mutate(train = "training")) %>%
  ggplot(aes(logit(predicted), logit(observed), colour = model)) +
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  base_theme+
  geom_rangeframe(colour="black")+
  geom_point(alpha = 0.5) +
  facet_wrap(~train) +
  theme(legend.position = "bottom")+
  labs(
    x = "logit(Predicted)",
    y = "logit(Observed)",
    colour = "Type of model"
  )
```

## Fitting models to CLR transformed vectors

Here we fit a simple linear model and random forest regression to centred log ratio transformed error vectors, using taxon as the predictor

```{r clr}
# Fit to 
fit_clrlm <- joint_train %>%
    filter(expected > 0) %>%
  group_by(sample_id) %>%
  mutate(clr_error = clr(observed0 /expected)) %>%
  ungroup() %>%
  group_by(material_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(material_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  mutate(lm_obj = map(train, ~fit(lm_spec,clr_error ~ 0 + taxon, data = .)),
           pred_train = map2(lm_obj, train, function(.model, .data) predict(.model, .data)),
           pred_test = map2(lm_obj, test, function(.model, .data) predict(.model, .data)),
           coef_info = map(lm_obj, tidy)
    ) 

# RF
fit_clrrf <- joint_train  %>%
  filter(expected > 0) %>%
  group_by(sample_id) %>%
  mutate(clr_error = clr(observed0 /expected)) %>%
  ungroup() %>%
  group_by(material_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(material_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  mutate(rf_obj = map(train, ~fit(rf_spec, clr_error ~ 0 + taxon, data = .)),
           pred_train = map2(rf_obj, train, function(.model, .data) predict(.model, .data)),
           pred_test = map2(rf_obj, test, function(.model, .data) predict(.model, .data))
    ) 

#results
clr_results_train <- fit_clrlm %>%
  unnest(pred_train, train) %>%
  mutate(
    predicted = expected * exp(.pred), 
    observed = observed.prop,
    estimated = exp(.pred),
    model = "lm"
  ) %>%
  bind_rows(fit_clrrf %>%
    unnest(pred_train, train) %>%
    mutate(
      predicted = expected * exp(.pred), 
      observed = observed.prop,
      estimated = exp(.pred),
      model = "rf"
    )) %>%
  group_by(sample_id, model) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  dplyr::filter(expected > 0)%>% 
    dplyr::select(!where(is.list))

clr_results_train %>%
  group_by(model, material_type) %>%
  rmse(truth = observed, estimate = predicted)

# Results test set
clr_results_test <- fit_clrlm %>%
  unnest(pred_test, test) %>%
  mutate(
    predicted = expected * exp(.pred), 
    observed = observed.prop,
    model = "lm"
  ) %>%
  bind_rows(fit_clrrf %>%
    unnest(pred_test, test) %>%
    mutate(
      predicted = expected * exp(.pred), 
      observed = observed.prop,
      model = "rf"
    )) %>%
  group_by(sample_id, model) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  dplyr::filter(expected > 0)%>% 
    dplyr::select(!where(is.list))

clr_results_test %>%
  group_by(model, material_type) %>%
  rmse(truth = observed, estimate = predicted)

# Visualise
clr_results_test %>%
  mutate(train = "testing") %>%
  bind_rows(clr_results_train %>%
    mutate(train = "training")) %>%
  ggplot(aes(logit(predicted), logit(observed), colour = model)) +
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  base_theme+
  geom_rangeframe(colour="black")+
  geom_point(alpha = 0.5) +
  facet_wrap(~train) +
  theme(legend.position = "bottom")+
  labs(
    x = "logit(Predicted)",
    y = "logit(Observed)",
    colour = "Type of model"
  )

```


## metacal

Here we use the bias estimation approach of *McLaren, M. R., Willis, A. D., & Callahan, B. J. (2019). Consistent and correctable bias in metagenomic sequencing experiments. Elife, 8.* This approach treats the abundances and errors as compositional vectors and estimates the bias as the geometric center of these bias vectors. 

This is a compositionally appropriate alternative to taking the arithmetic mean of errors in proportions as above.

```{r metacal}
fit_metacal <- joint_train %>%
    group_by(material_type) %>%
    nest() %>%
  dplyr::rename(train=data) %>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(material_type) %>%
  nest() %>%
    dplyr::rename(test=data)) %>%
    mutate(
        fit = map(train, function(x){
        err_mat <- x %>%
          dplyr::select(sample_id, taxon, error) %>%
          pivot_wider(id_cols= sample_id,
                      names_from = "taxon",
                      values_from = "error",
                      values_fill = list(error=NaN)) %>%
          column_to_rownames("sample_id") %>%
          as.matrix() 
        rows_to_keep <- rowSums(err_mat, na.rm=TRUE) > 0
        cols_to_keep <- colSums(err_mat, na.rm=TRUE) > 0
        err_mat <- err_mat[rows_to_keep, cols_to_keep]
        #Fit different metacal centering methods
        center(err_mat, method="proj", enframe=TRUE) %>%
        magrittr::set_colnames(c("taxon", ".pred"))
        })) %>%
    unnest(fit) 

#results
metacal_results_train <- joint_train %>%
  left_join(fit_metacal) %>%
  mutate(
    predicted = expected * .pred, 
    observed = observed.prop,
    estimated = .pred
  )%>%
  group_by(sample_id) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  dplyr::filter(expected > 0) %>% 
    dplyr::select(!where(is.list))

metacal_results_train %>%
  group_by(material_type) %>%
  rmse(truth = observed, estimate = predicted)

metacal_results_test <- joint_test %>%
  left_join(fit_metacal) %>%
  mutate(
    predicted = expected * .pred, 
    observed = observed.prop
  )%>%
  group_by(sample_id) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  dplyr::filter(expected > 0)%>% 
    dplyr::select(!where(is.list))

metacal_results_test %>%
  group_by(material_type) %>%
  rmse(truth = observed, estimate = predicted)

# Visualise
metacal_results_test %>%
  mutate(train = "testing") %>%
  bind_rows(metacal_results_train %>%
    mutate(train = "training")) %>%
  ggplot(aes(logit(predicted), logit(observed))) +
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  base_theme+
  geom_rangeframe(colour="black")+
  geom_point(alpha = 0.5) +
  facet_wrap(~train) +
  theme(legend.position = "bottom")+
  labs(
    x = "logit(Predicted)",
    y = "logit(Observed)"
  )

```


# Evaluate all model fits

Here we compare the accuracy of the bias estimation procedure by looking at the Root Mean Square Error (RMSE) between the observed relative abundances from sequencing, and the predicted relative abundances (Expected * Bias estimate) from each model.

To determine the models predictive ability to new data, we also determine these metrics for a seperate testing set of samples that the model was not trained on.

```{r evaluate models}
all_fits_train <- do.call("list",                         mget(grep("results_train",names(.GlobalEnv),value=TRUE))) %>%
  bind_rows(.id="model2") 

all_fits_test <- do.call("list",                     mget(grep("results_test",names(.GlobalEnv),value=TRUE))) %>%
  bind_rows(.id="model2") 

fits <- all_fits_train %>%
  mutate(train = "Training set") %>%
  bind_rows(all_fits_test %>%
    mutate(train = "Test set")) %>%
  mutate(model2 = model2 %>%
           str_remove("_results.*$") %>%
           paste0(model) %>%
           str_remove("NA")) %>%
  dplyr::select(model=model2, taxon, material_type, sample_name, sample_id, fcid, expected, expected.prop, observed, predicted, estimated, train, observed.prop) 

# Get RMSE
error <- fits %>%
  group_by(model, material_type, train) %>%
  rmse(truth = observed, estimate = predicted) #could also do somethign  else here

# plot rmse
error %>%
  ggplot(aes(x=model, y=.estimate, fill=model)) +
  geom_col() +
  base_theme+
  geom_rangeframe() +
  facet_grid(material_type~train) +
  scale_fill_brewer(palette="Paired") +
  theme(axis.text.x = element_text(angle=45, hjust = 1))

# Visualise fits to data
fits %>%
  ggplot(aes(logit(predicted), logit(observed), colour = sample_id)) +
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  base_theme+
  geom_rangeframe(colour="black")+
  geom_point(alpha = 0.5) +
  coord_fixed() + 
  facet_grid(train~model) +
  #theme(legend.position = "bottom")+
  labs(x = "log-odds(Predicted proportion)", 
    y = "log-odds(Observed proportion)",
    colour = "Sample",
    title="Bias model fits") 

```

## How well do the estimated bias recover the true composition

The opposite side of the coin to the above comparison is determining how well the estimated bias from each model can be used to calibrate the sequenced samples and thus recover the true composition.

```{r calibration}
cal <- fits %>%
    ungroup() %>%
    dplyr::mutate(calibrated = observed.prop / estimated) %>%
    group_by(sample_id, model) %>%
    mutate_at(vars(calibrated), ~ . / sum(., na.rm=TRUE) )  %>%
    ungroup() 


ggplot(cal, aes(x=taxon, y= odds(calibrated) / odds(expected.prop))) +
    geom_hline(yintercept=1, alpha=0.8)+
  geom_jitter(aes(x=taxon, y= odds(observed.prop) / odds(expected.prop)), colour="grey80", alpha=0.7, width = 0.1, height = 0)+
    geom_jitter(aes(colour = taxon),alpha=0.7, width = 0.1, height = 0) +
    geom_rangeframe(color = "black") + 
    scale_y_log10() + 
    base_theme+
    scale_colour_brewer(palette = "Spectral") +
    facet_grid(material_type ~ model) +
    labs(x = "Taxon", 
        y = "Odds calbirated / expected",
        colour = "Taxon",
        shape = "Primer pair") +
    coord_flip() +
    theme(
        panel.spacing.x = unit(1, "lines"),
        legend.position = "bottom")

```

# NExt:

Bootstrap errors

Reduction in errors as function of samples used to estiamte?




# Old metacal analyis
```{r metacal2}

#Get predictions and SE
bias.metacal <- joint %>%
    left_join(bias, by = c("target_subfragment", "material_type", "taxon")) %>%
    mutate(
        res_proj = error / est_proj,
        res_gm = error / est_gm,
        res_rss = error / est_rss,
        pred_proj = expected * est_proj, #Remember these predictions are from the EXPECTED
        pred_gm = expected * est_gm,
        pred_rss = expected * est_rss
    ) %>%
  left_join(bootreps %>%
    group_by(target_subfragment, material_type, taxon) %>%
    summarise(gm_mean = gm_mean(bias), gm_se = gm_sd(bias)) %>%
    ungroup, by = c("target_subfragment", "material_type", "taxon") )


#Bootstrapped estimate of bias
bootreps <- joint_train %>%
  dplyr::group_by(target_subfragment, material_type) %>%
    nest() %>%
    mutate(
        bootreps = map(data, function(x){
        err_mat <- x %>%
          dplyr::select(sample_id, taxon, error) %>%
          pivot_wider(id_cols= sample_id,
                      names_from = "taxon",
                      values_from = "error",
                      values_fill = list(error=NaN)) %>%
          column_to_rownames("sample_id") %>%
          as.matrix() 
        rows_to_keep <- rowSums(err_mat, na.rm=TRUE) > 0
        cols_to_keep <- colSums(err_mat, na.rm=TRUE) > 0
        err_mat <- err_mat[rows_to_keep, cols_to_keep]
        bootrep_center(err_mat,
                       R = 1e3,
                       dist="dirichlet",
                       method = "proj")
        
        })) %>%
    unnest(bootreps) %>%
    dplyr::rename(taxon=Taxon,
                  bias = Center)

#Get predictions and SE
bias.metacal <- joint %>%
    left_join(bias, by = c("target_subfragment", "material_type", "taxon")) %>%
    mutate(
        res_proj = error / est_proj,
        res_gm = error / est_gm,
        res_rss = error / est_rss,
        pred_proj = expected * est_proj, #Remember these predictions are from the EXPECTED
        pred_gm = expected * est_gm,
        pred_rss = expected * est_rss
    ) %>%
  left_join(bootreps %>%
    group_by(target_subfragment, material_type, taxon) %>%
    summarise(gm_mean = gm_mean(bias), gm_se = gm_sd(bias)) %>%
    ungroup, by = c("target_subfragment", "material_type", "taxon") )

# Plot bootstraps
library(ggridges)
gg.boot <- ggplot(bootreps, aes(x = bias-1, y = taxon, fill=taxon)) +
    geom_density_ridges(scale = 4) + 
    geom_vline(xintercept = 0, color = "grey80", size=1) +
  facet_grid(material_type~target_subfragment) +
  scale_y_discrete(expand = c(0.01, 0)) +   # will generally have to set the `expand` option
  scale_x_continuous(expand = c(0, 0), limits=c(-1, 4)) + 
  scale_fill_brewer(palette = "Spectral") + 
  labs(x = "Efficiancy / Geometric mean",
       x = "Taxon",
       fill ="Taxon") 

gg.boot

## Calculate SE as control samples increase - just do for the highest number group
err_mat <- joint %>%
    filter(target_subfragment == "fwhF2-fwhR2n", material_type == "CarpMock") %>%
          dplyr::select(sample_id, taxon, error) %>%
          pivot_wider(id_cols= sample_id,
                      names_from = "taxon",
                      values_from = "error") %>%
          column_to_rownames("sample_id") %>%
          as.matrix() 
rows_to_keep <- rowSums(err_mat, na.rm=TRUE) > 0
cols_to_keep <- colSums(err_mat, na.rm=TRUE) > 0
err_mat <- err_mat[rows_to_keep, cols_to_keep]

N <- 1:20
names(N) <- N
reps <- map_dfr(N, ~bootrep_center(err_mat, 
                                   R = 1e3,
                                   dist = "multinomial",
        N = ., method = "proj"),
    .id = "N") %>%
    dplyr::rename(taxon = Taxon,
                  Bhat = Center)

reps.summary <- reps %>%
    group_by(N, taxon) %>%
    summarize(gm_mean = gm_mean(Bhat), gm_se = gm_sd(Bhat))

gg.se <- ggplot(reps.summary, aes(x= as.numeric(N), y=gm_se, color = taxon)) +
    geom_line(aes(group = taxon), size=1) +
    geom_point() +
    scale_color_brewer(palette="Spectral") +
    labs(x = "Number of controls", y = "Geometric standard error", 
        title = "Standard error vs. number of control samples", 
        color = "Taxon")
gg.se
```




## Bootstrapped seperate regression models

Fit a bootstrapped linear model on both proportions and CLR transformed counts

```{r bootstrapped}
lm_dat <- joint %>%
  filter(expected > 0) %>%
  group_by(sample_name) %>%
  mutate(clr_observed = clr(observed0),
         clr_expected = clr(expected)) %>%
  ungroup() %>%
  group_by(taxon, target_subfragment, material_type)

group_name <- group_keys(lm_dat) %>%
  unite(col="name", everything(), sep=";") %>%
  pull(name)
lm_dat <- lm_dat %>%
  group_split() %>%
  set_names(group_name)

set.seed(606)
boots <- purrr::map(lm_dat, bootstraps, times=100, apparant=TRUE)

# Fit model to bootstraps
boot_models <- boots %>% 
  purrr::map(function(x){ 
    x <- x %>%
      mutate(
        fit_clr = map(splits,~lm(clr_observed ~ 0 + expected, data = .)),
        fit_lm = map(splits, ~  lm(observed ~ 0 + expected, data = .)),
        coef_clr = map(fit_clr, tidy),
        coef_lm = map(fit_lm, tidy),
        aug_clr = map(fit_clr, augment),
        aug_lm = map(fit_lm, augment)
        )
    
    }) 

# Get coefficients
boot_coefs <- boot_models %>% 
  purrr::map(function(x){ 
    x <- x %>%
   pivot_longer(c("coef_clr","coef_lm"), 
          names_to="model",
          values_to = "coef_info")%>%
      unnest(coef_info)
  }) %>%
  bind_rows(.id="name") %>%
  tidyr::separate(name, into=c("taxon", "target_subfragment", "material_type"), sep=";")


# Calculate CIs using percentile method
bias.lmboot <- boot_models %>%
  purrr::map(function(x){
    bind_rows(int_pctl(x, coef_clr) %>% mutate(model = "clrboot"),
              int_pctl(x, coef_lm) %>% mutate(model = "lmboot"))
              }) %>%
  bind_rows(.id="name") %>%
  tidyr::separate(name, into=c("taxon", "target_subfragment", "material_type"), sep=";") %>%
  mutate(se = (.upper - .lower) / 3.92)  #3,92 for 95% CIs

bias.lmboot 
ggplot(boot_coefs, aes(x=estimate, fill=taxon, group=taxon)) +
  geom_histogram(binwidth = 0.1, alpha=0.5) +
  facet_grid(target_subfragment ~ material_type, scales = "free") +
  #geom_vline(aes(xintercept = .estimate), data = bias.lmboot, col = "red") +
  #geom_vline(aes(xintercept = .lower), data = bias.lmboot, col = "blue") +
  #geom_vline(aes(xintercept = .upper), data = bias.lmboot, col = "blue") +
  labs(x = "Estimate",
       y = "Bootstraps",
       fill="Taxon")

# Plot fits
boot_aug <- boot_models %>% 
  purrr::map(function(x){ 
    x %>%
   pivot_longer(c("aug_clr","aug_lm"), 
          names_to="model",
          values_to = "augmented")%>%
      unnest(augmented)
    }) %>%
  bind_rows(.id="name") %>%
  tidyr::separate(name, into=c("taxon", "target_subfragment", "material_type" ), sep=";") 

ggplot(boot_aug %>% filter(model == "aug_lm"), aes(x=expected, y=observed, colour=taxon)) +
  geom_line(aes(y = .fitted, group = id), alpha = .2) +
  geom_point() +
  #geom_line(data=bias.clrboot, aes(y=.estimate),col= "black", inherit.aes = FALSE) +
  facet_grid(target_subfragment ~taxon, scales = "free") +
  theme(legend.position = "none")

ggplot(boot_aug %>% filter(model == "aug_clr"), aes(x=clr_expected, y=clr_observed, colour=taxon)) +
  geom_line(aes(y = .fitted, group = id), alpha = .2) +
  geom_point() +
  #geom_line(data=bias.clrboot, aes(y=.estimate),col= "black", inherit.aes = FALSE) +
  facet_grid(target_subfragment ~taxon, scales = "free") +
  theme(legend.position = "none")

```

## Compositional linear regression

really need to understand how mike mclaren formulates his generalised bias regression model from :
https://mikemc.github.io/presentations/lab-meetings/20191004/Rmd/slides.html#15

Is he just doing a log ratio regression on the errors?

ie lm(Error ~ 0 + expected, data = .)

```{r compositional regression}
# Example log ratio regression from https://www.r-bloggers.com/logratio-regression-a-simple-way-to-model-compositional-data/

data(ArcticLake)
df <- as.data.frame(ArcticLake)
#With the D-dimension outcome [p_1, p_2…p_D], we can derive a [D-1]-dimension outcome [log(p_2 / p_1)…log(p_D / p_1)] and then estimate a multivariate regression based on the new outcome.

#This is taking the log ratio (ALR) to sand first - to CLR this would take the ratio against rowmean?
lm(cbind(log(silt / sand), log(clay / sand)) ~ depth, data = df)

#see what the model matrix looks like
model.matrix(cbind(log(silt / sand), log(clay / sand)) ~ depth, data = df)

model.matrix(cbind(silt, clay) ~ depth, data = df)

#Since log(x / y) = log(x) – log(y), we can also estimate the model with log(sand) as an offset term.
lm(cbind(log(silt), log(clay)) ~ depth + offset(log(sand)), data = df)

model.matrix(cbind(log(silt), log(clay)) ~ depth + offset(log(sand)), data = df)
#Alternatively, we can also use the comp.reg function in the Compositional package.
Compositional::comp.reg(as.matrix(df[, 1:3]), df[, 4])

# Test using offset
complm <- joint %>%
  filter(expected > 0) %>%
  #dplyr::select(sample_id, taxon, observed0)
  group_by(material_type, target_subfragment)  %>%
    nest() %>%
    mutate(fit = map(data, ~lm(log(error) ~ 0 + taxon, data = .))
    ) 

%>%
  pivot_longer(c("fit_clr","fit_lm"), 
               names_to="model",
               values_to = "fit") %>%
  mutate(tidied = map(fit, broom::tidy),
         aug = map(fit, broom::augment)) %>%
  unnest(tidied, aug, data) %>%
  dplyr::select(taxon, target_subfragment, material_type, sample_name, model, estimate, std.error, clr_observed, expected, .fitted) 


complm <- joint %>%
  filter(expected > 0) %>%
  #dplyr::select(sample_id, taxon, observed0)
  group_by(material_type, target_subfragment)  %>%
  nest() %>%
  mutate(matrix = map(data, function(x){
    x %>%
      pivot_wider(id_cols= sample_id,
                      names_from = "taxon",
                      values_from = "observed0") %>%
      column_to_rownames("sample_id") %>%
      as.matrix} ))

```


