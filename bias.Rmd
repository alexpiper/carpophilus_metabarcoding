---
title: "Metabarcoding bias"
output: html_document
editor_options: 
  chunk_output_type: console
---
# Introduction

## Analysis structure

Part 1 - Cleanup & Filtering

Part 1 - Comparison of 4 primers for bias

Part 2 - Evaluation of different bias modellign strategies

- naive mean on proportions approach
- Metacal center function
  - proj
  - gm
  - rss
- lm on compositional vectors
- lm on expected / observed
- lm with CLR in advance?
- glmnet: multinomial regression with regularization (ie Lasso model)
- nnet::multinomial neural network regression
- multinomial regression with random effects
- Poisson regression with random effects
- Bayesian multinomial logistic normal models
  - Stan
  - Pibble from stray package
  
Look at spike in control

Pick the model that reduces the residual mean standard error (RMSE) the most

Should be able to do this within a tidymodels framework with bootsrapping

## Load packages
```{r setup}
#Set required packages
.cran_packages <- c("tidyverse",
                    "tidymodels",
                    "patchwork", 
                    "vegan", 
                    "seqinr",
                    "ape", 
                    "RColorBrewer",
                    "devtools",
                    "data.table")
.bioc_packages <- c("dada2",
                    "phyloseq", 
                    "ALDEx2",
                    "Biostrings")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/taxreturn")
devtools::install_github("mikemc/speedyseq")
devtools::install_github('ggloor/CoDaSeq/CoDaSeq')
devtools::install_github("mikemc/metacal")

library(taxreturn)
library(speedyseq)
library(CoDaSeq)
library(metacal)

#Source themes
source('R/themes.R')

#Create safe predict function
safe_predict <- function(model,data){
  if(is.null(data) | is(model, "data.frame") ){
    return(NULL)
  }
    predict(model, data)
}

```

## Make Phyloseq object


```{r create PS, eval = FALSE}
seqtab <- readRDS("output/rds/seqtab_final.rds")

#Reformat sample IDs
rownames(seqtab)  <- rownames(seqtab) %>%
  str_remove("\\..*$") %>%
  str_replace("\\_S[0-9].*\\_...", replacement="_") %>%
  str_replace("_$", "_1") %>%
  str_replace("1in10", "1:10")

tax <- readRDS("output/rds/final_tax.rds") 
seqs <- DNAStringSet(colnames(seqtab))
names(seqs) <- seqs
phy <- read.tree("output/ultrametric_tree_order_constrained.nwk")

##### Rename problematic samples
#Could do this with the new dplyr functionality
rownames(seqtab)  <- rownames(seqtab) %>%
 str_replace_all("D250M1-", "D250M4REP-") %>% # Works
 str_replace_all("D250M4-", "D250M2REP-") %>% # Works
 str_replace_all("D250M5-", "D250M3REP-") %>% #FAILED library
 str_replace_all("D250M3-", "D250M1REP-") %>% #FP suzukii - low reads
 str_replace_all("D250M2-", "D250M5REP-") %>% #Works
 str_replace_all("D500M1-", "D500M4REP-") %>% #Works 
 str_replace_all("D500M4-", "D500M1REP-") %>% #FP Suzukii
 str_replace_all("D500M5-", "D500M2REP-") %>% #Works
 str_replace_all("D500M3-", "D500M3REP-") %>% #Works but low reads for Suz + Biarmipes 
 str_replace_all("D500M2-", "D500M5REP-") %>% #Works
 str_replace_all("D1000M1-", "D1000M3REP-") %>% #Works
 str_replace_all("D1000M4-", "D1000M1REP-") %>% #Works
 str_replace_all("D1000M5-", "D1000M2REP-") %>% #Works
 str_replace_all("D1000M3-", "D1000M5REP-") %>% #Works
 str_replace_all("D1000M2-", "D1000M4REP-") %>% #Works
 str_replace_all("CM10-", "CM9REP-") %>%
 str_replace_all("CM11-", "CM10REP-") %>%
 str_replace_all("CM9-", "CM11REP-") %>%
 str_replace_all("CML2-", "CML6REP-")%>%
 str_replace_all("CML3-", "CML2REP-")%>%
 str_replace_all("CML4-", "CML3REP-")%>%
 str_replace_all("CML5-", "CML4REP-")%>%
 str_replace_all("CML6-", "CML5REP-")%>%
 str_replace_all("CT5-", "CT4REP-")%>%
 str_replace_all("CT4-", "CT5REP-") %>%
str_replace_all("REP", "")


# Samdf processing --------------------------------------------------------

samdf <- read.csv("sample_data/sample_info.csv", header=TRUE) %>% 
  mutate(sample_id = case_when(
    fcid=="HLVKYDMXX" ~ paste0(sample_name, "_", amp_rep),
    !fcid=="HLVKYDMXX" ~ paste0(fcid, "_", sample_name, "_", amp_rep)
  )) %>%
  mutate(extract_id = sample_name) %>%
  mutate(sample_name = str_remove(sample_name, "-exp*.$")) %>%
  mutate(sample_name = case_when(
    fcid=="HLVKYDMXX" ~ sample_name,
    !fcid=="HLVKYDMXX" ~ paste0(fcid, "_", sample_name)
  )) %>%
  filter(!(i7_index=="ATCGATCG" & i5_index=="ATCACACG"), #CT11-ex1 duplicated
         !(i7_index=="TCGCTGTT" & i5_index=="ACTCCATC") # CT12-ex1 duplicated
  ) %>%
  mutate(type = case_when(
    str_detect(sample_id, "D[0-9][0-9][0-9]M|D[0-9][0-9][0-9][0-9]M|DM[0-9]")  ~ "DrosMock",
    str_detect(sample_id, "SPD")  ~ "SPD",
    str_detect(sample_id, "ACV")  ~ "ACV",
    str_detect(sample_id, "DC")  ~ "DC",
    str_detect(sample_id, "Sach")  ~ "Sachet",
    str_detect(sample_id, "FF")  ~ "FF",
    str_detect(sample_id, "NTC")  ~ "NTC",
    str_detect(sample_id, "DLarv")  ~ "DrosLarv",
    str_detect(sample_id, "POS|SynMock")  ~ "POS",
    str_detect(sample_id, "extblank|BLANK")  ~ "Extblank",
    str_detect(sample_id, "pcrblank")  ~ "PCRblank",
    str_detect(sample_id, "CT")  ~ "CarpTrap",
    str_detect(sample_id, "CM[0-9]")  ~ "CarpMock",
    str_detect(sample_id, "CML[0-9]")  ~ "CarpLarval"
  )) %>%
  magrittr::set_rownames(.$sample_id)

write_csv(samdf, "sample_data/sample_info2.csv")

#Load sample information
## ---- samdat ----
samdf <- read.csv("sample_data/sample_info2.csv", header=TRUE) %>%
  magrittr::set_rownames(.$sample_id)

# Will probably need to rename the seqtabs and append the flowcell number onto the samples before they are merged

## ---- phyloseq ----
ps <- phyloseq(tax_table(tax), 
               sample_data(samdf),
               otu_table(seqtab, taxa_are_rows = FALSE),
               phy_tree(phy),
               refseq(seqs))

if(nrow(seqtab) > nrow(sample_data(ps))){warning("Warning: All samples not included in phyloseq object, check sample names match the sample metadata")}

rownames(samdf)[which(!rownames(sample_data(ps))  %in% rownames(samdf))]
rownames(sample_data(ps))[which(!rownames(samdf)  %in% rownames(sample_data(ps)))]

# Rename all taxa
taxa_names(ps) <- paste0("SV", seq(ntaxa(ps)),"-",tax_table(ps)[,8])

saveRDS(ps, "output/rds/ps_idtaxaExact.rds") 

#Rename synthetic orders
tax_table(ps)[,2][which(str_detect(tax_table(ps)[,8], "Synthetic"))] <- "Arthropoda"

#Subsetto Carpophilus
ps <- ps %>%
  subset_samples(str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]")
  ) %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) 
dir.create("output/csv")
dir.create("output/csv/unfiltered/")

##Export raw csv
export <- speedyseq::psmelt(ps) %>%
  filter(Abundance > 0)
write.csv(export, file = "output/csv/rawdata.csv")

#Summary export
seqateurs::summarise_taxa(ps, "Species", "sample_name") %>%
  filter(!str_detect(sample_name, "NTC")) %>%
  spread(key="sample_name", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/spp_sum.csv")

seqateurs::summarise_taxa(ps, "Genus", "sample_name") %>%
  spread(key="sample_name", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/gen_sum.csv")

##Output fasta of all ASV's - Name each one by abundance + taxonomic assignment
seqateurs::ps_to_fasta(ps, "output/all_taxa.fasta")
```


### Summary statistics

```{r sum taxa}
# N unique species and samples
speedyseq::psmelt(ps) %>%
  summarise(n_extracts = n_distinct(sample_name), n_samples = n_distinct(sample_name))

# Spread of reads
speedyseq::psmelt(ps) %>%
  group_by(sample_name) %>%
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  summarise(mean = mean(Abundance), 
            se = sd(Abundance)/sqrt(length(Abundance)),
            max = max(Abundance),
            min = min(Abundance))

# Spread of ASVs
speedyseq::psmelt(ps) %>%
  group_by(sample_name) %>%
  dplyr::filter(Abundance > 0) %>%
  summarise(counts = n_distinct(OTU)) %>%
  ungroup() %>%
  summarise(mean = mean(counts), 
            se = sd(counts)/sqrt(length(counts)),
            max = max(counts),
            min = min(counts))

#Fraction of reads assigned to each taxonomic rank
speedyseq::psmelt(ps) %>%
  gather("Rank","Name", rank_names(ps)) %>%
  group_by(Rank) %>% 
  mutate(Name = replace(Name, str_detect(Name, "__"), NA)) %>% # This line turns the "__" we added to lower ranks back to NA's
  dplyr::summarise(Reads_classified = sum(Abundance * !is.na(Name))) %>%
  mutate(Frac_reads = Reads_classified / sum(sample_sums(ps))) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)

#Fraction of ASV's assigned to each taxonomic rank
tax_table(ps) %>%
  as("matrix") %>%
  as_tibble(rownames="OTU") %>%
  gather("Rank","Name",rank_names(ps)) %>%
  group_by(Rank) %>%
  mutate(Name = replace(Name, str_detect(Name, "__"), NA)) %>% # This line turns the "__" we added to lower ranks back to NA's
  dplyr::summarise(OTUs_classified = sum(!is.na(Name))) %>%
  mutate(Frac_OTUs = OTUs_classified / ntaxa(ps)) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)

# Unique taxa at each rank
speedyseq::psmelt(ps) %>%
  dplyr::select(rank_names(ps)) %>%
  pivot_longer(everything(),
               names_to = "Rank",
               values_to = "value") %>%
  mutate(value = case_when(
    str_detect(value, "__") ~ as.character(NA),
    !str_detect(value, "__") ~ value
  )) %>%
  drop_na() %>%
  group_by(Rank) %>%
  summarise_all(list(n_distinct)) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)
```

## Taxon filtering

```{R taxon filt}
get_taxa_unique(ps, "Order")

ps # Check the number of taxa prior to removal
ps0 <- ps %>%
  subset_taxa(
    Phylum == "Arthropoda" & 
    Class %in% c("Insecta", "Arachnida", "Collembola")
  )
ps # Confirm that the taxa were removed
get_taxa_unique(ps0, "Phylum")
get_taxa_unique(ps0, "Class")
get_taxa_unique(ps0, "Order")
```


## Merge replicates 

```{r merge replicates}
# Merge replicates
ps.merged <- ps0 %>%
    merge_samples(group = "sample_name", fun="sum")

#This loses the sample metadata - Need to add it agian
sample_data(ps.merged) <- sample_data(ps0) %>%
  as("data.frame") %>%
  dplyr::filter(!duplicated(sample_name)) %>%
  magrittr::set_rownames(.$sample_name)

ps1 <- ps.merged
```


# Get expected and observed across all runs


```{r make joint}
ps_bias <- ps1 %>%
  subset_samples(type %in% c("CarpMock",  "CarpTrap", "CarpLarval")) %>%
  subset_samples(fcid %in% c("HLVKYDMXX", "CB3DR")) %>%
  subset_samples(pcr_primers == "fwhF2-fwhR2n") %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) 

tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Carpophilus_dimidiatus/nr.dimidiatus")] <- "Carpophilus_nr.dimidiatus"
tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Brachypeplus_Sp1")] <- "Brachypeplus_Sp"
tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Brachypeplus_Sp2")] <- "Brachypeplus_Sp"
ps_bias <- speedyseq::tax_glom(ps_bias, taxrank="Species")

exp <- read_csv("sample_data/expected_quant_carpophilus.csv") %>%
  dplyr::rename(sample_name = X1) %>%
  pivot_longer(-sample_name,
               names_to= "taxon",
               values_to= "expected") %>%
  mutate(taxon = str_replace(taxon, pattern=" ",replacement="_"),
         sample_name = str_remove(sample_name, "-exp*.$")) %>%
  dplyr::filter(!is.na(sample_name),
  str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]"),
  expected > 0) %>%
  distinct()

#plot expected
exp %>% 
  group_by(sample_name) %>%
  mutate_at(vars(expected), ~ . / sum(.) ) %>% #Convert to proportions
  ggplot(aes(x=sample_name, y=expected, fill=taxon)) +
  geom_col(position="stack") + 
  scale_fill_brewer(palette="Spectral") +
  theme(legend.position = "bottom") +
  base_theme+
  labs(x = "Sample Name", y= "Expected relative abundance")

#Get obsered
sam <- speedyseq::psmelt(ps_bias) %>%
  janitor::clean_names() %>%
  filter(!str_detect(species, "__")) %>%#Remove unclassified
  mutate(taxon = species %>% str_replace(" ", "_")) %>%
  dplyr::select(sample_name, taxon, abundance, pcr_primers, fcid, material_type = type) %>%
  mutate(sample_name = sample_name %>%
           str_remove_all("BF1-BR1-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-|fwhF2-fwhR2n-") %>%
           str_remove("HLVKYDMXX_") %>%
           str_remove("CB3DR_"),
         sample_id = paste0(fcid, "_", sample_name),
         sample_name = sample_name %>%
           str_remove("-ex[0-9]")) 

#Join tables 
joint <- sam %>%
  filter(taxon %in% exp$taxon,
         sample_name %in% exp$sample_name) %>%
  left_join(exp, by = c("sample_name","taxon")) %>%
  dplyr::rename(observed = abundance) %>%
  filter(!is.na(expected))%>%
  mutate(expected = replace_na(expected, 0),
         observed0 = (observed + 0.5) * (expected > 0),
         error = observed0 / expected,
        # error_centre = center_elts(observed0 / expected, na.rm = TRUE),
         ) %>%
  distinct() %>%
  group_by(sample_id) %>%
  mutate(observed.prop=observed, expected.prop=expected) %>%
  mutate_at(vars(observed.prop,  expected.prop), ~ . / sum(.) ) %>% #Convert to proportions
  mutate(sample_size = sum(expected), # Do the same for the ratios?
         observed_abs = observed.prop * sample_size,
         error_abs = observed_abs / expected,
         error_prop = observed.prop / expected.prop
         #error_abs_centre = center_elts(observed_abs / expected, na.rm = TRUE)
         )  %>%
  group_by(sample_id) %>%
  group_modify(~{
    alr_denom <- .x %>% 
      filter(taxon == "Carpophilus_hemipterus") %>% # Set to consistent taxon across all
      pull(error)
    clr_denom <- .x %>%
      pull(error) %>%
      gm_mean()
    .x %>%
      mutate(error_alr = log(error / alr_denom),
             error_clr = log(error / clr_denom))
  }) %>%
  group_modify(~{
    alr_denom <- .x %>% 
      filter(taxon == "Carpophilus_hemipterus") %>% # Set to consistent taxon across all
      pull(error_abs)
    clr_denom <- .x %>%
      pull(error_abs) %>%
      gm_mean()
    .x %>%
      mutate(error_abs_alr = log(error_abs / alr_denom),
             error_abs_clr = log(error_abs / clr_denom))
  })

```

#Visualise errors

```{r visualise errors}
# Original errors
error_rmse <- joint %>%
  group_by(material_type) %>%
  rmse(truth = logit(expected.prop), estimate = logit(observed.prop)) %>%
  dplyr::select(RMSE = .estimate, material_type)

error_anorm <- joint %>%
  group_by(material_type) %>%
    summarise(Adist = anorm(observed.prop / expected)) 

## Visualise errors in proportions
gg.error_props <- joint %>% 
  filter(expected > 0) %>%
  mutate_at(vars(expected.prop, observed.prop), logit) %>%
  left_join(error_rmse) %>%
  left_join(error_anorm) %>%
  ggplot(aes(expected.prop, observed.prop, fill = taxon)) + 
  geom_abline(intercept = 0, slope=1) +
  geom_jitter(alpha=0.7, shape=21, colour="black", ) +
  geom_text(aes(x=-10, y=3, label=paste0("RMSE: ",round(RMSE, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  geom_text(aes(x=-10, y=1, label=paste0("A.dist: ",round(Adist, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  scale_fill_brewer(palette="Paired")+
  facet_grid(material_type~fcid)+
    coord_fixed() + 
  theme_bw()+
  labs(fill = "Taxon",
       x="Expected proportions (log-odds)",
       y="Observed proportions (log-odds)") 

gg.error_props

## Visualise errors in abs
gg.error_abs <- joint %>% 
  filter(expected > 0) %>%
  ggplot(aes(expected, observed_abs, color = taxon)) + 
  geom_abline(intercept = 0, slope=1) +
  geom_jitter(alpha=0.7) +
  scale_color_brewer(palette="Spectral")+
  facet_grid(material_type~fcid)+
  theme_bw()+
  labs(title = "Observed vs. expected absolute abundances",
       color = "Taxon",
       x="Expected Individuals",
       y="Observed Individuals") 

# Visualise the error in all pairwise ratios
gg.error_rat <- joint %>%
  filter(expected > 0) %>%
  dplyr::mutate(Taxon = taxon %>%
                  str_replace("^.+_", paste0(str_extract(taxon, "."), "_"))) %>% #Shorten genus names
  metacal::compute_ratios(group_vars = c("sample_id", "fcid", "material_type")) %>%
  filter(!is.na(expected)) %>%
  filter(!Taxon.x == Taxon.y) %>%
  mutate(pair = paste(Taxon.x, Taxon.y, sep = ":")) %>% 
  ggplot(aes(pair, error, colour=Taxon.x)) +
  geom_jitter(alpha=0.7) +
  geom_hline(yintercept = 1) +
  scale_y_log10() +
  facet_grid(material_type~fcid)+
  theme_bw()+
    scale_color_brewer(palette="Spectral")+
    theme(legend.position = "none",
          axis.text.x = element_text(angle=45, hjust=1)) +
  labs(x = "Taxon ratios",
       y = "Error in taxon ratios")


#Save figure
pdf(file="fig/errors.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.error_props)
  plot(gg.error_abs)
  plot(gg.error_rat)
try(dev.off(), silent=TRUE)
```

# Compare bias models


## Split data into training and testing

```{r splits}
set.seed(666)


#Sample splits
joint_split <- joint %>%
  ungroup() %>%
  dplyr::select(sample_id, material_type) %>%
  distinct() %>%
  initial_split(strata = material_type)

# Training set
joint_train <- joint %>%
  dplyr::select(-error) %>%
  #dplyr::rename(error_rat = error) %>%
  filter(sample_id %in% training(joint_split)$sample_id) %>%
  ungroup()%>%
  pivot_longer(starts_with("error"),
               names_to="error_type",
               values_to="error")

# Testing set
joint_test <- joint %>%
  dplyr::select(-error) %>%
  #dplyr::rename(error_rat = error) %>%
  filter(sample_id %in% testing(joint_split)$sample_id)%>%
  ungroup()%>%
  pivot_longer(starts_with("error"),
               names_to="error_type",
               values_to="error")

# Check for data bleeding
table(joint_train$sample_id %in% joint_test$sample_id)
table(joint_test$sample_id %in% joint_train$sample_id)

# Create Cross validation folds for model tuning 
train_cv <- joint_train %>%
    mutate(strata = paste0(taxon, "_", material_type)) %>%
    vfold_cv(v = 10, strata = strata )

#Note - there is no real difference in results when tuning separately on each type of error - because they are all ratios
#Only real difference is its slower
```

## Uncorrected errors 

```{r uncorrected errors}
uncorrected_results_train <- joint_train %>%
  mutate(
  predicted = observed.prop,
  calibrated = observed.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

uncorrected_results_test <- joint_test %>%
  mutate(
  predicted = observed.prop,
  calibrated = observed.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

```

## Preprocessing recipes

```{r preprocess}
# Recipe for fitting model including fcid + material_type
bias_recipe <- 
  recipe(formula = error ~ 0 + taxon + fcid + material_type, data = joint_train) %>% 
  step_string2factor(fcid, material_type, taxon) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes(), one_hot=TRUE) %>% 
  step_zv(all_predictors())
  #step_normalize(-all_nominal()) 

# Recipe for fitting separate models to fcid + material_type. 
bias_recipe_separate <- 
  recipe(formula = error ~ 0 + taxon, data = joint_train) %>% 
  #step_string2factor(one_of(fcid, material_type)) %>% 
  step_string2factor(taxon) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes(), one_hot=TRUE) %>% 
  step_zv(all_predictors()) #%>% 
  #step_normalize(-all_nominal()) 

#Recipe for fitting model to proportions
prop_recipe <- 
  recipe(formula = observed.prop ~ 0 + expected.prop + taxon + fcid + material_type, data = joint_train) %>% 
  #step_string2factor(one_of(fcid, material_type)) %>% 
  step_string2factor(taxon) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes(), one_hot=TRUE) %>% 
  step_zv(all_predictors()) 

prop_recipe_separate <- 
  recipe(formula = observed.prop ~ 0 + expected.prop + taxon , data = joint_train) %>% 
  #step_string2factor(one_of(fcid, material_type)) %>% 
  step_string2factor(taxon) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes(), one_hot=TRUE) %>% 
  step_zv(all_predictors()) 

```


## Simple LM on proportions

```{r simple lm}
# Specify LM
lm_spec <- linear_reg() %>%
  set_engine(engine = "lm")
lm_spec

fit_lm <- joint_train %>%
  filter(expected > 0) %>%
  group_by(material_type, fcid) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(material_type, fcid) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  mutate(model_obj = map(train, ~fit(lm_spec, expected.prop ~ 0 + observed.prop + taxon, data = .)),
         pred_train = purrr::map2(model_obj, train, ~safe_predict(.x, .y)),
         pred_test = purrr::map2(model_obj, test, ~safe_predict(.x, .y)),
         coef_info = purrr::map(model_obj, tidy)
    ) 
#results
lm_results_train <- fit_lm %>%
  unnest(pred_train, train) %>%
  dplyr::select(!where(is.list))%>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre", "error_abs_centre", "error_abs_alr", "error_abs_clr","error_log", "errora_abs_log") ~ exp(.pred),
    TRUE ~ .pred
  ),
  predicted = expected.prop * estimated, 
  calibrated = observed.prop / estimated, 
  observed = observed.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted,calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0) %>%
  mutate(residuals = expected.prop / calibrated)

lm_results_train %>%
  group_by(material_type) %>%
  rmse(truth = observed.prop, estimate = predicted)

# Results test set
lm_results_test <- fit_complm %>%
  unnest(pred_test, test) %>%
  dplyr::select(!where(is.list))%>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre", "error_abs_centre", "error_abs_alr", "error_abs_clr","error_log", "errora_abs_log") ~ exp(.pred),
    TRUE ~ .pred
  ),
  predicted = expected.prop * estimated, 
  calibrated = observed.prop / estimated, 
  observed = observed.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted,calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

lm_results_test %>%
  group_by(error_type) %>%
  rmse(truth = observed, estimate = predicted)


# Move the method of using coefficients from proportions to the other model types as well

# Results
lm_results_train <-  fit_lm %>%
  unnest(train) %>%
  left_join(fit_lm %>% 
              unnest(coef_info) %>% 
              dplyr::select(taxon, estimated = estimate, material_type, fcid)) %>% 
  dplyr::filter(expected > 0) %>%
  mutate(
    predicted = expected.prop * estimated,
    calibrated = observed.prop / estimated
    )  %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted, calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  dplyr::filter(expected > 0)%>% 
    dplyr::select(!where(is.list))

lm_results_train %>%
  group_by(material_type) %>%
  rmse(truth = observed.prop, estimate = predicted)


# Results test set
lm_results_test <-  fit_lm %>%
  unnest(test) %>%
  left_join(fit_lm %>% 
              unnest(coef_info) %>% 
              dplyr::select(taxon, estimated = estimate, material_type, fcid)) %>% 
  dplyr::filter(expected > 0) %>%
  mutate(
    predicted = expected.prop * estimated,
    calibrated = observed.prop / estimated
    )  %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted, calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  dplyr::filter(expected > 0)%>% 
    dplyr::select(!where(is.list))

lm_results_test %>%
  group_by(material_type) %>%
  rmse(truth = observed.prop, estimate = predicted)

```

## CompLM
Estimating bias is complicated by the compositional nature of metabarcoding measurements. Because only relative abundances are measured, the measurement of a sample (s) only provides information about the efficiencies of the taxa in the sample relative to each other.

Here we fit a simple linear model on the compositional difference between Observed and Expected counts. The compositional error vectors are first geometrically centered, then taxon is used as a predictor.

```{r complm}
lm_spec <- 
  linear_reg() %>% 
  set_mode("regression") %>% 
  set_engine("lm")

#Ratios workflow
lm_workflow_rat <- 
  workflow() %>% 
  add_recipe(bias_recipe_separate) %>% 
  add_model(lm_spec)

# Proportions workflow
lm_workflow_prop <- 
  workflow() %>% 
  add_recipe(prop_recipe_separate) %>% 
  add_model(lm_spec)

# Fit model to ratios and proportions
fit_complm <- joint_train %>%
  filter(expected > 0) %>%
  group_by(error_type, fcid, material_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(error_type, fcid, material_type ) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  bind_cols(group_keys(.) %>%
              tidyr::unite("group_names", everything(), sep="-")) %>%
  mutate(
    model_obj = purrr::map2(train, error_type, function(x,y ){
      
      if (!y =="error_prop"){
        fit(lm_workflow_rat, data=x)
      } else if(error_type == "error_prop"){
        model_fit <- fit(lm_workflow_prop, data=x)
        # predict a fake table with all values at 1 to get taxon correction factors
        crossing(taxon = unique(x$taxon),
                           fcid = unique(x$fcid),
                           material_type = unique(x$material_type))%>%
          mutate(expected.prop = 1) %>%
          bind_cols(safe_predict(model_fit, new_df)) %>%
          dplyr::select(-expected.prop)%>%
          dplyr::select(taxon, .pred)
      }
    }),
    pred_train = purrr::map2(model_obj, train, function(x,y ){
      if(is.null(y)){
        return(NULL)
      }
      # predict ratios
      if(!is(x, "data.frame")){
        safe_predict(x, y)
      }else if( is(x, "data.frame")){ 
        # predict 
      y %>%
        left_join(x)
      }
    }),
    pred_test = purrr::map2(model_obj, test, function(x,y ){
      if(is.null(y)){
        return(NULL)
      }
      # predict ratios
      if(!is(x, "data.frame")){
        safe_predict(x, y)
      }else if( is(x, "data.frame")){ 
        # predict 
      y %>%
        left_join(x)
      }
    }),
    vip = purrr::map2(model_obj, group_names,~{
      if(!is(.x, "data.frame")){
        .x %>%
        pull_workflow_fit() %>%
        vip::vip()+
        labs(title=.y %>% str_remove("error_"))
      } else{
        return(NULL)
      }
      
    })
  )


# Plot model variable importance
wrap_plots(fit_complm %>%
             filter(!error_type=="error_prop") %>%
             pull(vip))

#results
complm_results_train <- fit_complm %>%
  unnest(pred_train, train) %>%
  dplyr::select(!where(is.list))%>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre", "error_abs_centre", "error_abs_alr", "error_abs_clr","error_log", "errora_abs_log") ~ exp(.pred),
    TRUE ~ .pred
  ),
  predicted = expected.prop * estimated, 
  calibrated = observed.prop / estimated, 
  observed = observed.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted,calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0) %>%
  mutate(residuals = expected.prop / calibrated)

complm_results_train %>%
  group_by(error_type) %>%
  rmse(truth = observed, estimate = predicted)

# Results test set
complm_results_test <- fit_complm %>%
  unnest(pred_test, test) %>%
  dplyr::select(!where(is.list))%>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre", "error_abs_centre", "error_abs_alr", "error_abs_clr","error_log", "errora_abs_log") ~ exp(.pred),
    TRUE ~ .pred
  ),
  predicted = expected.prop * estimated, 
  calibrated = observed.prop / estimated, 
  observed = observed.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted,calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

complm_results_test %>%
  group_by(error_type) %>%
  rmse(truth = observed, estimate = predicted)

complm_results_test %>%
  ggplot(aes(logit(predicted), logit(observed.prop), fill = taxon)) + 
  geom_abline(intercept = 0, slope=1) +
  geom_jitter(alpha=0.7, shape=21, colour="black", ) +
  scale_fill_brewer(palette="Paired")+
  facet_grid(error_type~material_type)+
  theme_bw()+
  labs(fill = "Taxon",
       x="Predicted proportions (log-odds)",
       y="Observed proportions (log-odds)") 
```


## LASSO

```{r LASSO}
glmnet_spec <- 
    linear_reg(penalty = tune(), mixture = tune()) %>% 
    set_mode("regression") %>% 
    set_engine("glmnet") %>%
    set_args(family="gaussian")
  
# Tune ratio workflow
glmnet_workflow_rat <- 
    workflow() %>% 
    add_recipe(bias_recipe_separate) %>% 
    add_model(glmnet_spec) 
  
glmnet_grid <- tidyr::crossing(penalty = 10^seq(-6, -1, length.out = 20), mixture = c(0.05, 
    0.2, 0.4, 0.6, 0.8, 1)) 

glmnet_tune <- tune_grid(glmnet_workflow_rat, resamples = train_cv, grid = glmnet_grid)

 autoplot(glmnet_tune , metric = "rmse") +
  scale_x_log10()

glmnet_workflow_rat <- finalize_workflow(glmnet_workflow_rat, glmnet_tune %>%
  select_best("rmse"))

fit_compglm <- joint_train %>%
  filter(expected > 0) %>%
  filter(!error_type=="error_prop") %>%
  group_by(error_type, fcid, material_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(error_type, fcid, material_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  bind_cols(group_keys(.) %>%
              tidyr::unite("group_names", everything(), sep="-")) %>%
  mutate(model_obj = purrr::map(train, ~fit(glmnet_workflow, data=.)),
         pred_train = purrr::map2(model_obj, train, ~safe_predict(.x, .y)),
         pred_test = purrr::map2(model_obj, test,  ~safe_predict(.x, .y)),
         vip = purrr::map2(model_obj, group_names,~{
           .x %>%
             pull_workflow_fit() %>%
             vip::vip()+
             labs(title=.y %>% str_remove("error_"))
         })
    )



 # Plot model variable importance
wrap_plots(fit_complm %>%
             filter(!error_type=="error_prop") %>%
             pull(vip))


# Plot model variable importance
wrap_plots(fit_compglm$vip)

#results
compglm_results_train <- fit_compglm %>%
  unnest(pred_train, train) %>%
  dplyr::select(!where(is.list))%>%
  ungroup() %>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre", "error_abs_centre", "error_abs_alr", "error_abs_clr","error_log", "errora_abs_log") ~ exp(.pred),
    TRUE ~ .pred
  ),
  predicted = expected.prop * estimated, 
  calibrated = observed.prop / estimated
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted,calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  mutate(residual = calibrated / expected.prop) %>%
  dplyr::filter(expected > 0)

compglm_results_train %>%
  group_by(error_type) %>%
  rmse(truth = observed.prop, estimate = predicted)

# Results test set
compglm_results_test <- fit_compglm %>%
  unnest(pred_test, test) %>% 
  dplyr::select(!where(is.list))%>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre", "error_abs_centre", "error_abs_alr", "error_abs_clr","error_log", "errora_abs_log") ~ exp(.pred),
    TRUE ~ .pred
  ),
  predicted = expected.prop * estimated, 
  calibrated = observed.prop / estimated,
  residual = calibrated / expected.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted,calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

compglm_results_test %>%
  group_by(error_type) %>%
  rmse(truth = observed.prop, estimate = predicted)

compglm_results_train %>%
  ggplot(aes(logit(predicted), logit(observed.prop), fill = taxon)) + 
  geom_abline(intercept = 0, slope=1) +
  geom_jitter(alpha=0.7, shape=21, colour="black", ) +
  scale_fill_brewer(palette="Paired")+
  facet_grid(error_type~material_type)+
  theme_bw()+
  labs(fill = "Taxon",
       x="Predicted proportions (log-odds)",
       y="Observed proportions (log-odds)") 
```

## Random Forest

```{r RF}
ranger_spec <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_mode("regression") %>% 
  set_engine("ranger", importance = "impurity") 

ranger_workflow <- 
  workflow() %>% 
  add_recipe(bias_recipe) %>% 
  add_model(ranger_spec) 

doParallel::registerDoParallel(cores=2)
set.seed(666)
ranger_tune <- tune_grid(ranger_workflow, resamples = train_cv, grid = 20)

autoplot(ranger_tune , metric = "rmse") 

best_rf <- ranger_tune %>%
  select_best("rmse")

ranger_workflow <- finalize_workflow(ranger_workflow, ranger_tune %>%
  select_best("rmse"))

fit_rf <- joint_train %>%
  filter(expected > 0) %>%
  group_by(error_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(error_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  bind_cols(group_keys(.) %>%
              tidyr::unite("group_names", everything(), sep="-")) %>%
  mutate(model_obj = purrr::map(train, ~fit(ranger_workflow, data=.)),
         pred_train = purrr::map2(model_obj, train, ~safe_predict(.x, .y)),
         pred_test = purrr::map2(model_obj, test,  ~safe_predict(.x, .y)),
         vip = purrr::map2(model_obj, group_names,~{
           .x %>%
             pull_workflow_fit() %>%
             vip::vip()+
             labs(title=.y %>% str_remove("error_"))
         })
    )

# Plot model variable importance
wrap_plots(fit_rf$vip)

#results
rf_results_train <- fit_rf %>%
  unnest(pred_train, train) %>% 
  dplyr::select(!where(is.list))%>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre", "error_abs_centre", "error_abs_alr", "error_abs_clr","error_log", "errora_abs_log") ~ exp(.pred),
    TRUE ~ .pred
  ),
  predicted = expected.prop * estimated, 
  calibrated = observed.prop / estimated, 
  observed = observed.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted,calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

rf_results_train %>%
  group_by(error_type) %>%
  rmse(truth = observed.prop, estimate = predicted)

# Results test set
rf_results_test <- fit_rf %>%
  unnest(pred_test, test) %>%
  dplyr::select(!where(is.list))%>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre", "error_abs_centre", "error_abs_alr", "error_abs_clr","error_log", "errora_abs_log") ~ exp(.pred),
    TRUE ~ .pred
  ),
  predicted = expected.prop * estimated, 
  calibrated = observed.prop / estimated, 
  observed = observed.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted,calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

rf_results_test %>%
  group_by(error_type) %>%
  rmse(truth = observed, estimate = predicted)

rf_results_test %>%
  ggplot(aes(logit(predicted), logit(observed.prop), fill = taxon)) + 
  geom_abline(intercept = 0, slope=1) +
  geom_jitter(alpha=0.7, shape=21, colour="black", ) +
  scale_fill_brewer(palette="Paired")+
  facet_grid(error_type~material_type)+
  theme_bw()+
  labs(fill = "Taxon",
       x="Predicted proportions (log-odds)",
       y="Observed proportions (log-odds)") 

```


## XGBOOST

```{r XGBOOST}
xgboost_spec <- 
  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), 
    loss_reduction = tune(), sample_size = tune()) %>% 
  set_mode("regression") %>% 
  set_engine("xgboost") 

xgboost_workflow <- 
  workflow() %>% 
  add_recipe(bias_recipe) %>% 
  add_model(xgboost_spec) 

doParallel::registerDoParallel(cores=2)
set.seed(666)
xgboost_tune <-
  tune_grid(xgboost_workflow, resamples = train_cv, grid =20)

autoplot(xgboost_tune , metric = "rmse") 

xgboost_workflow <- finalize_workflow(xgboost_workflow, xgboost_tune %>%
  select_best("rmse"))

fit_xg <- joint_train %>%
  filter(expected > 0) %>%
  group_by(error_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(error_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  bind_cols(group_keys(.) %>%
              tidyr::unite("group_names", everything(), sep="-")) %>%
  mutate(model_obj = purrr::map(train, ~fit(xgboost_workflow, data=.)),
         pred_train = purrr::map2(model_obj, train, ~safe_predict(.x, .y)),
         pred_test = purrr::map2(model_obj, test,  ~safe_predict(.x, .y)),
         vip = purrr::map2(model_obj, group_names,~{
           .x %>%
             pull_workflow_fit() %>%
             vip::vip()+
             labs(title=.y %>% str_remove("error_"))
         })
    )

# Plot model variable importance
wrap_plots(fit_xg$vip)

#results
xg_results_train <- fit_xg %>%
  unnest(pred_train, train) %>%
  dplyr::select(!where(is.list))%>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre", "error_abs_centre", "error_abs_alr", "error_abs_clr","error_log", "errora_abs_log") ~ exp(.pred),
    TRUE ~ .pred
  ),
  predicted = expected.prop * estimated, 
  calibrated = observed.prop / estimated, 
  observed = observed.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted,calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

xg_results_train %>%
  group_by(error_type) %>%
  rmse(truth = observed, estimate = predicted)

# Results test set
xg_results_test <- fit_xg %>%
  unnest(pred_test, test) %>%
  dplyr::select(!where(is.list))%>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre", "error_abs_centre", "error_abs_alr", "error_abs_clr","error_log", "errora_abs_log") ~ exp(.pred),
    TRUE ~ .pred
  ),
  predicted = expected.prop * estimated, 
  calibrated = observed.prop / estimated, 
  observed = observed.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted,calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

xg_results_test %>%
  group_by(error_type) %>%
  rmse(truth = observed, estimate = predicted)

xg_results_train %>%
  ggplot(aes(logit(predicted), logit(observed.prop), fill = taxon)) + 
  geom_abline(intercept = 0, slope=1) +
  geom_jitter(alpha=0.7, shape=21, colour="black", ) +
  scale_fill_brewer(palette="Paired")+
  facet_grid(error_type~material_type)+
  theme_bw()+
  labs(fill = "Taxon",
       x="Predicted proportions (log-odds)",
       y="Observed proportions (log-odds)") 

```

## Neural Network

These models dont seem to be estimating taxon specific slopes??? maybe biased for some

```{r Neural network}
keras_spec <- 
  linear_reg(mixture=tune(),penalty = tune()) %>% 
  set_mode("regression") %>% 
  set_engine("keras",verbose = 0) 

keras_workflow <- 
  workflow() %>% 
  add_recipe(bias_recipe) %>% 
  add_model(keras_spec) 

set.seed(666)
keras_tune <-
  tune_grid(keras_workflow, resamples = train_cv, grid =20)

autoplot(keras_tune , metric = "rmse") 

keras_workflow <- finalize_workflow(keras_workflow, keras_tune%>%
  select_best("rmse"))

fit_keras <- joint_train %>%
  filter(expected > 0) %>%
  group_by(error_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(error_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  bind_cols(group_keys(.) %>%
              tidyr::unite("group_names", everything(), sep="-")) %>%
  mutate(model_obj = purrr::map(train, ~fit(keras_workflow, data=.)),
         pred_train = purrr::map2(model_obj, train, ~safe_predict(.x, .y)),
         pred_test = purrr::map2(model_obj, test,  ~safe_predict(.x, .y)),
         vip = purrr::map2(model_obj, group_names,~{
           .x %>%
             pull_workflow_fit() %>%
             vip::vip()+
             labs(title=.y %>% str_remove("error_"))
         })
    )

# Plot model variable importance
wrap_plots(fit_xg$vip)


#results
keras_results_train <- fit_keras %>%
  unnest(pred_train, train) %>%
  dplyr::select(!where(is.list))%>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre", "error_abs_centre", "error_abs_alr", "error_abs_clr","error_log", "errora_abs_log") ~ exp(.pred),
    TRUE ~ .pred
  ),
  predicted = expected.prop * estimated, 
  calibrated = observed.prop / estimated, 
  observed = observed.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted,calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

keras_results_train %>%
  group_by(material_type) %>%
  rmse(truth = observed, estimate = predicted)

# Results test set
keras_results_test <- fit_keras %>%
  unnest(pred_test, test) %>%
  dplyr::select(!where(is.list))%>%
  mutate(estimated = case_when(
    error_type %in% c("error_alr", "error_clr", "error_centre", "error_abs_centre", "error_abs_alr", "error_abs_clr","error_log", "errora_abs_log") ~ exp(.pred),
    TRUE ~ .pred
  ),
  predicted = expected.prop * estimated, 
  calibrated = observed.prop / estimated, 
  observed = observed.prop
  ) %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted,calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  ungroup() %>%
  dplyr::filter(expected > 0)

keras_results_test %>%
  group_by(material_type) %>%
  rmse(truth = observed, estimate = predicted)

keras_results_test %>%
  ggplot(aes(logit(predicted), logit(observed.prop), fill = taxon)) + 
  geom_abline(intercept = 0, slope=1) +
  geom_jitter(alpha=0.7, shape=21, colour="black", ) +
  scale_fill_brewer(palette="Paired")+
  facet_grid(error_type~material_type)+
  theme_bw()+
  labs(fill = "Taxon",
       x="Predicted proportions (log-odds)",
       y="Observed proportions (log-odds)") 
```

## metacal

Here we use the bias estimation approach of *McLaren, M. R., Willis, A. D., & Callahan, B. J. (2019). Consistent and correctable bias in metagenomic sequencing experiments. Elife, 8.* This approach treats the abundances and errors as compositional vectors and estimates the bias as the geometric center of these bias vectors. 


```{r metacal}
# This is a modified version of the metacal::center function using the "proj" method
# This has been modified to auto detect the input scale and work better with the tidymodels workflow
# Original code from https://github.com/mikemc/metacal/blob/master/R/compositional-mean.R
# Method from vandenBoogaart2006; also described in vandenBoogaart2013 and at
# https://core.ac.uk/download/pdf/132548286.pdf (Bren2008)

metacal_spec <- function(x, denom="all", in_scale = NULL, out_scale="linear"){
  
  #input checks
  if(!is(x, "data.frame")){return(NULL)}    
  if(!denom %in% c("all", unique(x$taxon))){
    stop("denom must either be all, or a taxon name")
  }
  
  #Transform x to matrix
   mat <- x %>%
          dplyr::select(sample_id, taxon, error)%>%
          pivot_wider(id_cols= sample_id,
                      names_from = "taxon",
                      values_from = "error",
                      values_fill = list(error=NaN))%>%    
          column_to_rownames("sample_id") %>%
          as.matrix() 
    
   # Check if matrix is log or linear
   if(is.null(in_scale)){
     curr_nas <- sum(is.na(mat))
     new_nas <- sum(is.na(log(mat)))
     if(curr_nas == new_nas){
       in_scale <- "linear"
       warning("No input scale provided, guessed ", in_scale)
     } else if(!curr_nas == new_nas){
       in_scale <- "log"
       warning("No input scale provided, guessed ", in_scale)
     }
   }

  # Drop missing data
  if (in_scale == "linear"){
    rows_to_keep <- rowSums(mat, na.rm=TRUE) > 0
    cols_to_keep <- colSums(mat, na.rm=TRUE) > 0
    
   } else  if(in_scale=="log"){
    rows_to_keep <- rowSums(is.na(mat)) < ncol(mat)
    cols_to_keep <- colSums(is.na(mat)) < nrow(mat)
  }
   mat <- mat[rows_to_keep, cols_to_keep]
   
   # Transform to log scale
   if (in_scale == "linear"){
      mat <- log(mat)
   }
    
    # log center proj
    K <- ncol(mat)
    mat0 <- mat
    mat0[is.nan(mat0)] <- 0
    
    P_sum <- diag(0, nrow = K)
    v_sum <- rep(0, K)
    weights = rep(1, nrow(mat))
    
    proj_mat <- function(K, M = c()) {
      mat <- diag(nrow = K) - 1/(K - length(M))
      mat[M,] <- 0
      mat[,M] <- 0
      mat
    }
    
    for (i in seq(nrow(mat))) {
        M <- which(is.nan(mat[i,]))
        v <- mat0[i,]
        P <- proj_mat(K, M) * weights[i]
        P_sum <- P_sum + P
        v_sum <- v_sum + P %*% v
    }

    #CLR transform
    clr_center <- (MASS::ginv(P_sum) %*% v_sum) %>% c
    names(clr_center) <- colnames(mat)
    
    out <- clr_center

    if (!denom=="all"){
      out <- out - mean(out[denom])
    }
    if (out_scale == "linear"){
      out <- exp(out)
    }
    out <- tibble::enframe(out, "taxon", ".pred")    
}

## Tests to make sure that the pre transformed errors from earlier are equivalent
## They should be because everything we are looking at is a ratio
tests <- joint %>%
  dplyr::rename(error_rat = error) %>%
  filter(sample_id %in% training(joint_split)$sample_id) %>%
  ungroup()%>%
  pivot_longer(starts_with("error"),
               names_to="error_type",
               values_to="error") %>%
  filter(expected > 0) %>%
  group_by(error_type) %>%
  nest()

# Test that ALR on original errors is equivalent to the pre-transformed ALR error
test1 <- metacal_spec((tests %>% filter(error_type == "error_rat"))$data[[1]],
                      denom="Carpophilus_hemipterus")
test2 <- metacal_spec((tests %>% filter(error_type == "error_alr"))$data[[1]],
                      denom="Carpophilus_hemipterus")
all(round(test1$.pred,4) == round(test2$.pred,4))


#Test CLR on on original erorrs is equivalent to the pre-transformed CLR error
test3 <- metacal_spec((tests %>% filter(error_type == "error_rat"))$data[[1]])
test4 <- metacal_spec((tests %>% filter(error_type == "error_clr"))$data[[1]])
all(round(test3$.pred,4) == round(test4$.pred,4))

# Fit metacal
fit_metacal <- joint_train %>%
  filter(expected > 0) %>%
  group_by(error_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
    filter(expected > 0) %>%
  group_by(error_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  mutate(denom = case_when(
    error_type == "error_alr"  ~ "Carpophilus_hemipterus",
    TRUE ~ "all"
  )) %>%
   mutate(fits = purrr::map(train, metacal_spec, denom=denom))

# Testing isnt working right

# Results
metacal_results_train <-  fit_metacal %>%
  unnest(train) %>%
  left_join(fit_metacal %>% 
              unnest(fits) %>% 
              dplyr::select(error_type,taxon, .pred))%>% #material_type, fcid
  dplyr::filter(expected > 0) %>%
  mutate(
    estimated = .pred,
    predicted = expected.prop * estimated,
    calibrated = observed.prop / estimated
    )  %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted, calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  dplyr::filter(expected > 0)%>% 
    dplyr::select(!where(is.list))

metacal_results_train %>%
  group_by(error_type) %>%
  rmse(truth = observed.prop, estimate = predicted)

# Results test set
metacal_results_test <- fit_metacal%>%
  unnest(test) %>%
  left_join(fit_metacal %>% 
              unnest(fits) %>% 
              dplyr::select(error_type, taxon,  .pred)) %>% #material_type, fcid, 
  dplyr::filter(expected > 0) %>%
  mutate(
    estimated = .pred,
    predicted = expected.prop * estimated,
    calibrated = observed.prop / estimated
    )  %>%
  group_by(sample_id, error_type) %>%
  mutate_at(vars(predicted, calibrated), ~ . / sum(., na.rm=TRUE) ) %>%
  dplyr::filter(expected > 0)%>% 
    dplyr::select(!where(is.list))

metacal_results_test %>%
  group_by(error_type) %>%
  rmse(truth = observed.prop, estimate = predicted)

```


# Evaluate all model fits

Here we compare the accuracy of the bias estimation procedure by looking at the Root Mean Square Error (RMSE) between the observed relative abundances from sequencing, and the predicted relative abundances (Expected * Bias estimate) from each model.

To determine the models predictive ability to new data, we also determine these metrics for a seperate testing set of samples that the model was not trained on.


Add Adist
Add original bias?

```{r evaluate models}
all_fits_train <- do.call("list",mget(grep("results_train",names(.GlobalEnv),value=TRUE))) %>%
  bind_rows(.id="model") %>%
  distinct()

all_fits_test <- do.call("list",  mget(grep("results_test",names(.GlobalEnv),value=TRUE))) %>%
  bind_rows(.id="model") 

fits <- all_fits_train %>%
  mutate(train = "Training set") %>%
  bind_rows(all_fits_test %>%
    mutate(train = "Test set")) %>%
  mutate(model = model %>%
           str_remove("_results.*$") %>%
           str_remove("NA")) %>%
  dplyr::select(model, taxon, material_type, sample_name, sample_id, fcid, expected, expected.prop ,observed, observed.prop, predicted, estimated, train, calibrated,  error_type ,sample_size) 

# Get RMSE
model_rmse <- fits %>%
  group_by(model, error_type,  train) %>%
  rmse(truth = logit(observed.prop), estimate = logit(predicted)) %>%
  dplyr::select(RMSE = .estimate, model, error_type, train)

model_anorm <- fits %>%
  group_by(model, error_type, train) %>%
    summarise(Adist = anorm(observed.prop / expected)) 

# Visualise fits to data
gg.train_preds <- fits %>%
  left_join(model_rmse) %>%
  left_join(model_anorm) %>%
  distinct()%>%
  mutate(model = model %>%
           str_replace("keras", "Neural Network") %>%
           str_replace("rf", "Random Forest") %>%
           str_replace("^lm$", "Linear Reg (Proportions)") %>%
           str_replace("xg", "XGBOOST Tree") %>%
           str_replace("^comp$", "Linear Reg (Ratios)") %>%
           str_replace("compglm", "LASSO Reg (Ratios)")%>%
           str_replace("complm", "Linear Reg (Ratios)")) %>%
  filter(train == "Training set") %>%
  filter(error_type %in% c("error_clr", "error_alr", "error_abs_clr", "error_prop")) %>%
  mutate(model = factor(model),
         model = fct_reorder(model, -RMSE)) %>%
  ggplot(aes(logit(predicted), logit(observed.prop), fill = material_type)) +
  geom_point(alpha = 0.5, shape=21, colour="black") +
  geom_abline(lty = 2, colour = "gray80", size = 1) +
    geom_text(aes(x=-10, y=3, label=paste0("RMSE: ",round(RMSE, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  geom_text(aes(x=-10, y=1, label=paste0("A.dist: ",round(Adist, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  coord_fixed() + 
  facet_grid(error_type~model) +
    base_theme+
  scale_fill_brewer(palette="Set1") +
  theme(panel.grid = element_line(size = rel(1)),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "bottom",
        legend.text = element_text(face="italic")) +
    labs(x = "Bias model prediction (log-odds)", 
        y = "Observed proportions (log-odds)",
        fill = "Taxon", 
        colour= NULL,
        title= "Training set")

gg.train_preds

# Visualise fits to data
gg.test_preds <- fits %>%
  left_join(model_rmse) %>%
  left_join(model_anorm) %>%
  mutate(model = model %>%
           str_replace("keras", "Neural Network") %>%
           str_replace("rf", "Random Forest") %>%
           str_replace("^lm$", "Linear Reg (Proportions)") %>%
           str_replace("xg", "XGBOOST Tree") %>%
           str_replace("^comp$", "Linear Reg (Ratios)") %>%
           str_replace("compglm", "LASSO Reg (Ratios)")%>%
           str_replace("complm", "Linear Reg (Ratios)")) %>%
  filter(train == "Test set") %>%
  filter(error_type %in% c("error_clr", "error_alr", "error_abs_clr", "error_prop")) %>%
  mutate(model = factor(model),
         model = fct_reorder(model, -RMSE)) %>%
  ggplot(aes(logit(predicted), logit(observed.prop), fill = material_type)) +
  geom_point(alpha = 0.5, shape=21, colour="black") +
  geom_abline(lty = 2, colour = "gray80", size = 1) +
    geom_text(aes(x=-10, y=3, label=paste0("RMSE: ",round(RMSE, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  geom_text(aes(x=-10, y=1, label=paste0("A.dist: ",round(Adist, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  coord_fixed() + 
  facet_grid(error_type~model) +
    base_theme+
  scale_fill_brewer(palette="Set1") +
  theme(panel.grid = element_line(size = rel(1)),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "bottom",
        legend.text = element_text(face="italic")) +
    labs(x = "Bias model prediction (log-odds)", 
        y = "Observed proportions (log-odds)",
        fill = "Taxon", 
        colour= NULL,
        title= "Testing set")

gg.test_preds

# Predictions for just CLR across the different material types
  
# Visualise fits to data
gg.material_pred_train <- fits %>%
  left_join(model_rmse) %>%
  left_join(model_anorm) %>%
  distinct()%>%
  mutate(model = model %>%
           str_replace("keras", "Neural Network") %>%
           str_replace("rf", "Random Forest") %>%
           str_replace("^lm$", "Linear Reg (Proportions)") %>%
           str_replace("xg", "XGBOOST Tree") %>%
           str_replace("^comp$", "Linear Reg (Ratios)") %>%
           str_replace("compglm", "LASSO Reg (Ratios)")%>%
           str_replace("complm", "Linear Reg (Ratios)")) %>%
  filter(train == "Training set") %>%
  filter(error_type =="error_clr") %>%
  mutate(model = factor(model),
         model = fct_reorder(model, -RMSE)) %>%
  ggplot(aes(logit(predicted), logit(observed.prop), fill = material_type)) +
  geom_point(alpha = 0.5, shape=21, colour="black") +
  geom_abline(lty = 2, colour = "gray80", size = 1) +
    geom_text(aes(x=-10, y=3, label=paste0("RMSE: ",round(RMSE, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  geom_text(aes(x=-10, y=1, label=paste0("A.dist: ",round(Adist, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  coord_fixed() + 
  facet_grid(material_type~model) +
    base_theme+
  scale_fill_brewer(palette="Set1") +
  theme(panel.grid = element_line(size = rel(1)),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "bottom",
        legend.text = element_text(face="italic")) +
    labs(x = "Bias model prediction (log-odds)", 
        y = "Observed proportions (log-odds)",
        fill = "Taxon", 
        colour= NULL,
        title= "Training set")

# Visualise fits to data
gg.material_pred_test <- fits %>%
  left_join(model_rmse) %>%
  left_join(model_anorm) %>%
  distinct()%>%
  mutate(model = model %>%
           str_replace("keras", "Neural Network") %>%
           str_replace("rf", "Random Forest") %>%
           str_replace("^lm$", "Linear Reg (Proportions)") %>%
           str_replace("xg", "XGBOOST Tree") %>%
           str_replace("^comp$", "Linear Reg (Ratios)") %>%
           str_replace("compglm", "LASSO Reg (Ratios)")%>%
           str_replace("complm", "Linear Reg (Ratios)")) %>%
  filter(train == "Test set") %>%
  filter(error_type =="error_clr") %>%
  mutate(model = factor(model),
         model = fct_reorder(model, -RMSE)) %>%
  ggplot(aes(logit(predicted), logit(observed.prop), fill = material_type)) +
  geom_point(alpha = 0.5, shape=21, colour="black") +
  geom_abline(lty = 2, colour = "gray80", size = 1) +
    geom_text(aes(x=-10, y=3, label=paste0("RMSE: ",round(RMSE, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  geom_text(aes(x=-10, y=1, label=paste0("A.dist: ",round(Adist, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  coord_fixed() + 
  facet_grid(material_type~model) +
    base_theme+
  scale_fill_brewer(palette="Set1") +
  theme(panel.grid = element_line(size = rel(1)),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "bottom",
        legend.text = element_text(face="italic")) +
    labs(x = "Bias model prediction (log-odds)", 
        y = "Observed proportions (log-odds)",
        fill = "Taxon", 
        colour= NULL,
        title= "Testing set")


#Save figure
pdf(file="fig/bias_preds.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.train_preds)
  plot(gg.test_preds)
  plot(gg.material_pred_train)
  plot(gg.material_pred_test)
try(dev.off(), silent=TRUE)
```

## Abs preds

```{r}
all_fits_train <- do.call("list",mget(grep("results_train",names(.GlobalEnv),value=TRUE))) %>%
  bind_rows(.id="model") %>%
  distinct()

all_fits_test <- do.call("list",  mget(grep("results_test",names(.GlobalEnv),value=TRUE))) %>%
  bind_rows(.id="model") 

abs_fits <- all_fits_train %>%
  mutate(train = "Training set") %>%
  bind_rows(all_fits_test %>%
    mutate(train = "Test set")) %>%
  mutate(model = model %>%
           str_remove("_results.*$") %>%
           str_remove("NA")) %>%
  dplyr::select(model, taxon, material_type, sample_name, sample_id, fcid, expected, expected.prop ,observed, observed.prop, predicted, estimated,calibrated, train, error_type ,sample_size) %>%
  mutate(predicted_abs = predicted * sample_size,
         observed_abs = observed.prop * sample_size,
         calibrated_abs = calibrated * sample_size)

# Get RMSE
model_rmse <- abs_fits %>%
  group_by(model, error_type,  train) %>%
  rmse(truth = expected, estimate = calibrated_abs) %>%
  dplyr::select(RMSE = .estimate, model, error_type, train)

model_anorm <- abs_fits %>%
  group_by(model, error_type, train) %>%
    summarise(Adist = anorm(expected / calibrated_abs)) 

# Visualise fits to data
gg.train_abs <- abs_fits %>%
  left_join(model_rmse) %>%
  left_join(model_anorm) %>%
  distinct()%>%
  mutate(model = model %>%
           str_replace("keras", "Neural Network") %>%
           str_replace("rf", "Random Forest") %>%
           str_replace("^lm$", "Linear Reg (Proportions)") %>%
           str_replace("xg", "XGBOOST Tree") %>%
           str_replace("^comp$", "Linear Reg (Ratios)") %>%
           str_replace("compglm", "LASSO Reg (Ratios)")%>%
           str_replace("complm", "Linear Reg (Ratios)")) %>%
  filter(train == "Training set") %>%
  filter(error_type %in% c("error_clr", "error_alr", "error_abs_clr")) %>%
  mutate(model = factor(model),
         model = fct_reorder(model, -RMSE)) %>%
  ggplot(aes(calibrated_abs, expected, fill = material_type)) +
  geom_point(alpha = 0.5, shape=21, colour="black") +
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  geom_text(aes(x=0, y=300, label=paste0("RMSE: ",round(RMSE, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  geom_text(aes(x=0, y=280, label=paste0("A.dist: ",round(Adist, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  coord_fixed() + 
  facet_grid(error_type~model) +
    base_theme+
  scale_fill_brewer(palette="Set1") +
  theme(panel.grid = element_line(size = rel(1)),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "bottom",
        legend.text = element_text(face="italic")) +
    labs(x = "Expected individuals", 
        y = "Calibrated individuals",
        fill = "Taxon", 
        colour= NULL,
        title= "Training set")

gg.train_abs

# Test set absolute
gg.test_abs <- abs_fits %>%
  left_join(model_rmse) %>%
  left_join(model_anorm) %>%
  distinct()%>%
  mutate(model = model %>%
           str_replace("keras", "Neural Network") %>%
           str_replace("rf", "Random Forest") %>%
           str_replace("^lm$", "Linear Reg (Proportions)") %>%
           str_replace("xg", "XGBOOST Tree") %>%
           str_replace("^comp$", "Linear Reg (Ratios)") %>%
           str_replace("compglm", "LASSO Reg (Ratios)")%>%
           str_replace("complm", "Linear Reg (Ratios)")) %>%
  filter(train == "Test set") %>%
  filter(error_type %in% c("error_clr", "error_alr", "error_abs_clr")) %>%
  mutate(model = factor(model),
         model = fct_reorder(model, -RMSE)) %>%
  ggplot(aes(calibrated_abs, expected, fill = material_type)) +
  geom_point(alpha = 0.5, shape=21, colour="black") +
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  geom_text(aes(x=0, y=300, label=paste0("RMSE: ",round(RMSE, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  geom_text(aes(x=0, y=280, label=paste0("A.dist: ",round(Adist, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  coord_fixed() + 
  facet_grid(error_type~model) +
    base_theme+
  scale_fill_brewer(palette="Set1") +
  theme(panel.grid = element_line(size = rel(1)),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "bottom",
        legend.text = element_text(face="italic")) +
    labs(x = "Expected individuals", 
        y = "Calibrated individuals",
        fill = "Taxon", 
        colour= NULL,
        title= "Test set")

gg.test_abs


```

## How well do the estimated bias recover the Relative abundances

The opposite side of the coin to the above comparison is determining how well the estimated bias from each model can be used to calibrate the sequenced samples and thus recover the true composition.

```{r calibration}
cal <- fits %>%
    ungroup() %>%
    dplyr::mutate(calibrated = observed.prop / estimated) %>%
    group_by(sample_id, model, train) %>%
    mutate_at(vars(calibrated), ~ . / sum(., na.rm=TRUE) )  %>%
    ungroup() 

ggplot(cal, aes(x=taxon, y= odds(calibrated) / odds(expected.prop))) +
    geom_hline(yintercept=1, alpha=0.8)+
  geom_jitter(aes(x=taxon, y= odds(observed.prop) / odds(expected.prop)), colour="grey80", alpha=0.7, width = 0.1, height = 0)+
    geom_jitter(aes(colour = taxon),alpha=0.7, width = 0.1, height = 0) +
    #geom_rangeframe(color = "black") + 
    scale_y_log10() + 
    base_theme+
    scale_colour_brewer(palette = "Spectral") +
    facet_grid(material_type ~ model) +
    labs(x = "Taxon", 
        y = "Odds calbirated / expected",
        colour = "Taxon",
        shape = "Primer pair") +
    coord_flip() +
    theme(
        panel.spacing.x = unit(1, "lines"),
        legend.position = "bottom")

```


## How well do the estimated bias recover the true absolute abundances


# Variable importance
```{r Final model}
lm_spec <- 
  linear_reg() %>% 
  set_mode("regression") %>% 
  set_engine("lm")

lm_workflow <- 
  workflow() %>% 
  add_recipe(bias_recipe) %>% 
  add_model(lm_spec) 

set.seed(606)
#boots <- purrr::map(lm_dat, bootstraps, times=1000, apparant=TRUE)

fit_complm <- joint_train %>%
  filter(expected > 0) %>%
  group_by(error_type) %>%
  nest() %>%
  dplyr::rename(train=data)%>%
  left_join(joint_test %>%
  filter(expected > 0) %>%
  group_by(error_type) %>%
  nest() %>%
  dplyr::rename(test=data)) %>%
  mutate(model_obj = purrr::map(train, ~fit(lm_workflow, data=.)),
         pred_train = purrr::map2(model_obj, train, ~safe_predict(.x, .y)),
         pred_test = purrr::map2(model_obj, test,  ~safe_predict(.x, .y))
    )

library(vip)
vip::vip(fit_complm$model_obj[[3]])

# Fit model to bootstraps
boot_models <- boots %>% 
  purrr::map(function(x){ 
    x <- x %>%
      mutate(lm_obj = map(splits, ~lm(center_elts(observed0 / exp_individuals) ~ 0 + taxon, data = .)), #why cant i use lm spec here?
            pred = map2(lm_obj, splits, function(.model, .data) predict(.model, .data)),
            coef_info = map(lm_obj, tidy),
            #aug = map(lm_obj, broom::augment),
            data = map(splits, function(y){
              as.data.frame(y) %>%
                dplyr::select(observed, count, mixture_type, sample_id, taxon, exp_individuals)})
        ) 
    }) 

# Get coefficients
boot_coefs <- boot_models %>% 
  purrr::map(function(x){ 
    x <- x %>%
      unnest(coef_info)
  }) %>%
  bind_rows(.id="name") %>%
  tidyr::separate(name, into=c("mixture_type", "target_subfragment"), sep=";") %>%
  mutate(taxon = str_remove(term, "taxon")) %>%
  mutate(extract_type = case_when(
      mixture_type=="DNEasy" ~ "DNEasy",
      mixture_type=="QuickExtract" ~ "QuickExtract",
      TRUE ~ "NA"
    ))%>%
    dplyr::select(!where(is.list))


#results
boot_results <- boot_models%>% 
  purrr::map(function(x){ 
    x <- x %>%
      unnest(pred, data)
  }) %>%
  bind_rows(.id="name") %>%
  tidyr::separate(name, into=c("mixture_type", "target_subfragment"), sep=";") %>%
  dplyr::filter(exp_individuals > 0)%>% 
  mutate(
    predicted = exp_individuals * pred, 
    estimated = pred
  ) %>%
  group_by(sample_id, id) %>%
  mutate_at(vars(predicted, observed, exp_individuals), ~ . / sum(., na.rm=TRUE) ) %>% #re-close elements
  dplyr::select(!where(is.list))

# Visualise fits of predicted proportions

# Get RMSE
final_rmse <- boot_results %>%
  mutate(mixture_type = factor(mixture_type, levels=c("QuickExtract", "DNEasy", "DNA", "PCR"))) %>%
  group_by(target_subfragment, mixture_type) %>%
  rmse(truth = observed, estimate = predicted) #could also do somethign  else here

final_anorm <- boot_results %>%
   mutate(mixture_type = factor(mixture_type, levels=c("QuickExtract", "DNEasy", "DNA", "PCR"))) %>%
  group_by(target_subfragment, mixture_type, id ) %>%
    summarise(Adist = anorm(observed / predicted))  %>%
  group_by(target_subfragment, mixture_type) %>%
  summarise(Adist = mean(Adist))


# Visualise fits to data
gg.final_fits <- boot_results %>%
  mutate(mixture_type = factor(mixture_type, levels=c("QuickExtract", "DNEasy", "DNA", "PCR"))) %>%
  ggplot(aes(logit(predicted), logit(observed))) +
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  geom_text(data=final_rmse, aes(x=-12, y=1, label=paste0("RMSE: ",round(.estimate, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  geom_text(data=final_anorm, aes(x=-12, y=-1, label=paste0("A.dist: ",round(Adist, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
 stat_density_2d(geom = "polygon", aes(alpha = ..level.., fill = taxon))+
  facet_grid(target_subfragment~mixture_type) +
  scale_fill_manual(values = colours.taxon) +
  scale_colour_manual(values = colours.taxon) +
  base_theme +
  theme(panel.grid = element_line(size = rel(1))) +
  scale_alpha_continuous(range=c(0.3, 0.9))+
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none",
        legend.text = element_text(face="italic")) +
    labs(x = "Bias model prediction (log-odds)", 
        y = "Observed proportions (log-odds)",
        fill = "Taxon", 
        colour= NULL)+
  coord_cartesian(xlim = c(-12,3), ylim = c( -12, 3))

## Visualise errors in unmodelled proportions
prop_rmse <- joint %>%
  mutate(mixture_type = factor(mixture_type, levels=c("QuickExtract", "DNEasy", "DNA", "PCR"))) %>%
  group_by(target_subfragment, mixture_type) %>%
  rmse(truth = expected, estimate = observed) #could also do somethign  else here


prop_anorm <- joint %>%
   mutate(mixture_type = factor(mixture_type, levels=c("QuickExtract", "DNEasy", "DNA", "PCR"))) %>%
  group_by(target_subfragment, mixture_type) %>%
    summarise(Adist = anorm(observed / expected)) 


gg.err_prop <- joint%>%
  mutate(mixture_type = factor(mixture_type, levels=c("QuickExtract", "DNEasy", "DNA", "PCR"))) %>% 
  mutate_at(vars(observed, expected, exp_individuals), logit) %>%
  ggplot(aes(exp_individuals,observed, color = taxon)) + 
  geom_abline(lty = 2, colour = "gray80", size = 1) +
  geom_text(data=prop_rmse, aes(x=-12, y=1, label=paste0("RMSE: ",round(.estimate, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  geom_text(data=prop_anorm, aes(x=-12, y=-1, label=paste0("A.dist: ",round(Adist, 2))),check_overlap = TRUE, inherit.aes = FALSE, hjust = 0)+
  geom_point(alpha=0.5) +
  scale_colour_manual(values = colours.taxon) +
  facet_grid(target_subfragment~mixture_type) +
  labs(x = "Expected proportions (log-odds)", 
       y = "Observed proportions (log-odds)",
       colour = "Taxon")  +
  base_theme +
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none",
        legend.text = element_text(face="italic")) +
    facet_grid(target_subfragment~mixture_type) +
  coord_cartesian(xlim = c(-12,3), ylim = c( -12, 3))

colours.taxon2 <- colours.taxon
names(colours.taxon2) <- names(colours.taxon) %>% str_replace("_", " ")

gg.final_ests <- boot_coefs  %>%
    group_by(taxon, target_subfragment, mixture_type) %>%
    summarise(gm_quantiles(estimate, q = c(0.05, 0.5, 0.95), na_rm=TRUE, wide=TRUE),
              gm_mean = metacal::gm_mean(estimate, na.rm=TRUE),
              gm_se = metacal::gm_sd(estimate, na.rm = TRUE)) %>%
    ungroup %>%
    mutate(mixture_type = factor(mixture_type, levels=c("QuickExtract", "DNEasy", "DNA", "PCR"))) %>%
  mutate(taxon = taxon %>% str_replace("_", " ")) %>%
  ggplot(aes(x=taxon, y=gm_mean, colour=taxon))+
  geom_pointrange(aes(ymin = gm_mean / gm_se^2, ymax = gm_mean * gm_se^2),
        fatten = 3,
        position = position_dodge(width = 0.5)) +
    scale_colour_manual(values = colours.taxon2) +
    geom_hline(yintercept = 1, colour="grey80" )  +
    scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
                  labels = trans_format("log10", math_format(10^.x))) +
    annotation_logticks(sides="l", outside=TRUE) +
    geom_rangeframe(color = "black") +
  base_theme +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "bottom",
        axis.text.x = element_blank(),
        legend.text = element_text(face="italic")) +
    facet_grid(target_subfragment~mixture_type) +
  labs(y = "Efficiency / geometric mean",
       x = "Taxon",
      colour = "Taxon") +
  coord_cartesian(clip = "off")

Fig1 <- gg.err_prop /  gg.final_fits / gg.final_ests  + plot_annotation(tag_levels = "A")  & theme(plot.margin =unit(c(0,0,0,0), "cm"))

Fig1

#Save figure
pdf(file="figs/fig1_bias.pdf", width = 8, height = 9 , paper="a4")
  plot(Fig1)
try(dev.off(), silent=TRUE)

```


# Look at variable importance


Reduction in errors as function of samples used to estiamte?


# Old metacal analyis
```{r metacal2}

#Get predictions and SE
bias.metacal <- joint %>%
    left_join(bias, by = c("pcr_primers", "material_type", "taxon")) %>%
    mutate(
        res_proj = error / est_proj,
        res_gm = error / est_gm,
        res_rss = error / est_rss,
        pred_proj = expected * est_proj, #Remember these predictions are from the EXPECTED
        pred_gm = expected * est_gm,
        pred_rss = expected * est_rss
    ) %>%
  left_join(bootreps %>%
    group_by(pcr_primers, material_type, taxon) %>%
    summarise(gm_mean = gm_mean(bias), gm_se = gm_sd(bias)) %>%
    ungroup, by = c("pcr_primers", "material_type", "taxon") )


#Bootstrapped estimate of bias
bootreps <- joint_train %>%
  dplyr::group_by(pcr_primers, material_type) %>%
    nest() %>%
    mutate(
        bootreps = map(data, function(x){
        err_mat <- x %>%
          dplyr::select(sample_id, taxon, error) %>%
          pivot_wider(id_cols= sample_id,
                      names_from = "taxon",
                      values_from = "error",
                      values_fill = list(error=NaN)) %>%
          column_to_rownames("sample_id") %>%
          as.matrix() 
        rows_to_keep <- rowSums(err_mat, na.rm=TRUE) > 0
        cols_to_keep <- colSums(err_mat, na.rm=TRUE) > 0
        err_mat <- err_mat[rows_to_keep, cols_to_keep]
        bootrep_center(err_mat,
                       R = 1e3,
                       dist="dirichlet",
                       method = "proj")
        
        })) %>%
    unnest(bootreps) %>%
    dplyr::rename(taxon=Taxon,
                  bias = Center)

#Get predictions and SE
bias.metacal <- joint %>%
    left_join(bias, by = c("pcr_primers", "material_type", "taxon")) %>%
    mutate(
        res_proj = error / est_proj,
        res_gm = error / est_gm,
        res_rss = error / est_rss,
        pred_proj = expected * est_proj, #Remember these predictions are from the EXPECTED
        pred_gm = expected * est_gm,
        pred_rss = expected * est_rss
    ) %>%
  left_join(bootreps %>%
    group_by(pcr_primers, material_type, taxon) %>%
    summarise(gm_mean = gm_mean(bias), gm_se = gm_sd(bias)) %>%
    ungroup, by = c("pcr_primers", "material_type", "taxon") )

# Plot bootstraps
library(ggridges)
gg.boot <- ggplot(bootreps, aes(x = bias-1, y = taxon, fill=taxon)) +
    geom_density_ridges(scale = 4) + 
    geom_vline(xintercept = 0, color = "grey80", size=1) +
  facet_grid(material_type~pcr_primers) +
  scale_y_discrete(expand = c(0.01, 0)) +   # will generally have to set the `expand` option
  scale_x_continuous(expand = c(0, 0), limits=c(-1, 4)) + 
  scale_fill_brewer(palette = "Spectral") + 
  labs(x = "Efficiancy / Geometric mean",
       x = "Taxon",
       fill ="Taxon") 

gg.boot

## Calculate SE as control samples increase - just do for the highest number group
err_mat <- joint %>%
    filter(pcr_primers == "fwhF2-fwhR2n", material_type == "CarpMock") %>%
          dplyr::select(sample_id, taxon, error) %>%
          pivot_wider(id_cols= sample_id,
                      names_from = "taxon",
                      values_from = "error") %>%
          column_to_rownames("sample_id") %>%
          as.matrix() 
rows_to_keep <- rowSums(err_mat, na.rm=TRUE) > 0
cols_to_keep <- colSums(err_mat, na.rm=TRUE) > 0
err_mat <- err_mat[rows_to_keep, cols_to_keep]

N <- 1:20
names(N) <- N
reps <- map_dfr(N, ~bootrep_center(err_mat, 
                                   R = 1e3,
                                   dist = "multinomial",
        N = ., method = "proj"),
    .id = "N") %>%
    dplyr::rename(taxon = Taxon,
                  Bhat = Center)

reps.summary <- reps %>%
    group_by(N, taxon) %>%
    summarize(gm_mean = gm_mean(Bhat), gm_se = gm_sd(Bhat))

gg.se <- ggplot(reps.summary, aes(x= as.numeric(N), y=gm_se, color = taxon)) +
    geom_line(aes(group = taxon), size=1) +
    geom_point() +
    scale_color_brewer(palette="Spectral") +
    labs(x = "Number of controls", y = "Geometric standard error", 
        title = "Standard error vs. number of control samples", 
        color = "Taxon")
gg.se
```




## Bootstrapped seperate regression models

Fit a bootstrapped linear model on both proportions and CLR transformed counts

```{r bootstrapped}
lm_dat <- joint %>%
  filter(expected > 0) %>%
  group_by(sample_name) %>%
  mutate(clr_observed = clr(observed0),
         clr_expected = clr(expected)) %>%
  ungroup() %>%
  group_by(taxon, pcr_primers, material_type)

group_name <- group_keys(lm_dat) %>%
  unite(col="name", everything(), sep=";") %>%
  pull(name)
lm_dat <- lm_dat %>%
  group_split() %>%
  set_names(group_name)

set.seed(606)
boots <- purrr::map(lm_dat, bootstraps, times=100, apparant=TRUE)

# Fit model to bootstraps
boot_models <- boots %>% 
  purrr::map(function(x){ 
    x <- x %>%
      mutate(
        fit_clr = map(splits,~lm(clr_observed ~ 0 + expected, data = .)),
        fit_lm = map(splits, ~  lm(observed ~ 0 + expected, data = .)),
        coef_clr = map(fit_clr, tidy),
        coef_lm = map(fit_lm, tidy),
        aug_clr = map(fit_clr, augment),
        aug_lm = map(fit_lm, augment)
        )
    
    }) 

# Get coefficients
boot_coefs <- boot_models %>% 
  purrr::map(function(x){ 
    x <- x %>%
   pivot_longer(c("coef_clr","coef_lm"), 
          names_to="model",
          values_to = "coef_info")%>%
      unnest(coef_info)
  }) %>%
  bind_rows(.id="name") %>%
  tidyr::separate(name, into=c("taxon", "pcr_primers", "material_type"), sep=";")


# Calculate CIs using percentile method
bias.lmboot <- boot_models %>%
  purrr::map(function(x){
    bind_rows(int_pctl(x, coef_clr) %>% mutate(model = "clrboot"),
              int_pctl(x, coef_lm) %>% mutate(model = "lmboot"))
              }) %>%
  bind_rows(.id="name") %>%
  tidyr::separate(name, into=c("taxon", "pcr_primers", "material_type"), sep=";") %>%
  mutate(se = (.upper - .lower) / 3.92)  #3,92 for 95% CIs

bias.lmboot 
ggplot(boot_coefs, aes(x=estimate, fill=taxon, group=taxon)) +
  geom_histogram(binwidth = 0.1, alpha=0.5) +
  facet_grid(pcr_primers ~ material_type, scales = "free") +
  #geom_vline(aes(xintercept = .estimate), data = bias.lmboot, col = "red") +
  #geom_vline(aes(xintercept = .lower), data = bias.lmboot, col = "blue") +
  #geom_vline(aes(xintercept = .upper), data = bias.lmboot, col = "blue") +
  labs(x = "Estimate",
       y = "Bootstraps",
       fill="Taxon")

# Plot fits
boot_aug <- boot_models %>% 
  purrr::map(function(x){ 
    x %>%
   pivot_longer(c("aug_clr","aug_lm"), 
          names_to="model",
          values_to = "augmented")%>%
      unnest(augmented)
    }) %>%
  bind_rows(.id="name") %>%
  tidyr::separate(name, into=c("taxon", "pcr_primers", "material_type" ), sep=";") 

ggplot(boot_aug %>% filter(model == "aug_lm"), aes(x=expected, y=observed, colour=taxon)) +
  geom_line(aes(y = .fitted, group = id), alpha = .2) +
  geom_point() +
  #geom_line(data=bias.clrboot, aes(y=.estimate),col= "black", inherit.aes = FALSE) +
  facet_grid(pcr_primers ~taxon, scales = "free") +
  theme(legend.position = "none")

ggplot(boot_aug %>% filter(model == "aug_clr"), aes(x=clr_expected, y=clr_observed, colour=taxon)) +
  geom_line(aes(y = .fitted, group = id), alpha = .2) +
  geom_point() +
  #geom_line(data=bias.clrboot, aes(y=.estimate),col= "black", inherit.aes = FALSE) +
  facet_grid(pcr_primers ~taxon, scales = "free") +
  theme(legend.position = "none")

```
